{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Getting Started with Patra Toolkit\n",
    "\n",
    "This notebook serves as a quickstart guide to help you learn how to:\n",
    "\n",
    "- Load and preprocess an example image\n",
    "- Perform image classification with a pretrained **ResNet50** model from PyTorch\n",
    "- Generate a comprehensive Model Card using the **Patra Toolkit**\n",
    "\n",
    "By the end of this tutorial, you'll have a Model Card (in JSON format) that captures key metadata about your model and its prediction.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Environment Setup\n",
    "\n",
    "### 1.1 Install Required Packages\n",
    "Run the following cell to install the required packages:\n",
    "- `torch` and `torchvision` for the model and image processing\n",
    "- `patra_toolkit` for creating the Model Card\n",
    "- `Pillow` for image handling\n",
    "- `scikit-learn` (if needed) for additional utilities\n",
    "\n",
    "---\n"
   ],
   "id": "a1106a2d67b43cd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T18:55:36.583608Z",
     "start_time": "2025-03-13T18:55:36.575170Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install torch torchvision patra_toolkit Pillow scikit-learn",
   "id": "b125ea15282c07e0",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.2 Import Dependencies\n",
    "\n",
    "Below, we import the necessary libraries. We also add the repository root to `sys.path` so that the latest local version of `patra_toolkit` is imported (if needed).\n",
    "\n",
    "---"
   ],
   "id": "606c8bdd5fb8fbac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T18:55:37.348017Z",
     "start_time": "2025-03-13T18:55:37.345142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import io\n",
    "import json\n",
    "import logging\n",
    "import tempfile\n",
    "import requests\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Import Patra Toolkit components\n",
    "from patra_toolkit import ModelCard, AIModel\n",
    "\n",
    "# Set logging level\n",
    "logging.basicConfig(level=logging.INFO)"
   ],
   "id": "7650ae0f61ab8434",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2. Load and Preprocess an Example Image\n",
    "\n",
    "We'll download an example image from a URL. Then, we'll apply the same preprocessing as required by ResNet50:\n",
    "- Resize to 256 pixels on the smaller side\n",
    "- Center-crop to 224Ã—224\n",
    "- Convert to a tensor and normalize using the ImageNet statistics\n",
    "\n",
    "---\n"
   ],
   "id": "ec80886749709316"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T18:55:38.503172Z",
     "start_time": "2025-03-13T18:55:38.284988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# URL of an example image (you can choose any valid image URL)\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/9/9a/Pug_600.jpg\"  # example: a picture of a pug\n",
    "response = requests.get(image_url)\n",
    "\n",
    "# Open the image with PIL\n",
    "image = Image.open(io.BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "# Define the transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    # Normalization parameters from ImageNet\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "input_tensor = preprocess(image)\n",
    "# Create a mini-batch as expected by the model\n",
    "input_batch = input_tensor.unsqueeze(0)"
   ],
   "id": "af3a58fa90925977",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 3. Image Prediction with Pretrained ResNet50\n",
    "\n",
    "We load the pretrained ResNet50 model and perform inference on the preprocessed image. We'll then decode the top prediction using the default weights.\n",
    "\n",
    "---\n"
   ],
   "id": "c9ff12dc72138de9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T18:55:40.869078Z",
     "start_time": "2025-03-13T18:55:40.294540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import certifi\n",
    "\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()\n",
    "\n",
    "# Load pretrained ResNet50 model\n",
    "# torchvision.models.ResNet50_Weights.DEFAULT is available in newer torchvision releases\n",
    "weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "model = torchvision.models.resnet50(weights=weights)\n",
    "model.eval()  # set to evaluation mode\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "# Get probabilities using softmax\n",
    "probabilities = F.softmax(output[0], dim=0)\n",
    "\n",
    "# Get the top 5 predictions\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "\n",
    "# Use the weights metadata to map category IDs to labels\n",
    "categories = weights.meta[\"categories\"]"
   ],
   "id": "aafa2802bc26a67e",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Model Card Generation with Patra Toolkit\n",
    "\n",
    "Next, we'll create a Model Card capturing key metadata about the model.\n",
    "Since we're using a pretrained ResNet50, we'll record its details and top prediction.\n"
   ],
   "id": "9f3716e9b40850ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T18:55:41.908875Z",
     "start_time": "2025-03-13T18:55:41.904384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a ModelCard instance\n",
    "mc = ModelCard(\n",
    "    name=\"ResNet50\",\n",
    "    version=\"0.1\",\n",
    "    short_description=\"A pretrained ResNet50 image classifier\",\n",
    "    full_description=\"This model card demonstrates using a pretrained ResNet50 model from PyTorch\",\n",
    "    keywords=\"resnet50, pytorch, image classification, patra, pretrained\",\n",
    "    author=\"neelk\",\n",
    "    input_type=\"Image\",\n",
    "    category=\"classification\",\n",
    "    foundational_model=\"None\",\n",
    "    citation=\"https://doi.org/10.48550/arXiv.1512.03385\"\n",
    ")\n",
    "\n",
    "# For demonstration, we set input_data as the example image URL\n",
    "mc.input_data = image_url\n"
   ],
   "id": "7a8632f1c190f585",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4.1 Create an AIModel Instance\n",
    "\n",
    "We attach an AIModel instance to the ModelCard with details about the model.\n",
    "\n",
    "---"
   ],
   "id": "32a667fffe41a1b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T18:14:21.187083Z",
     "start_time": "2025-03-13T18:14:21.183130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ai_model = AIModel(\n",
    "    name=\"ResNet50\",\n",
    "    version=\"0.1\",\n",
    "    description=\"Pretrained ResNet50 model from torchvision for image classification.\",\n",
    "    owner=\"Neelesh Karthikeyan\",\n",
    "    location=\"\",  # will be updated after model submission\n",
    "    license=\"BSD-3 Clause\",\n",
    "    framework=\"pytorch\",\n",
    "    model_type=\"cnn\",\n",
    "    test_accuracy=0.75\n",
    ")\n",
    "\n",
    "# Attach the AIModel to the ModelCard\n",
    "mc.ai_model = ai_model\n",
    "mc.populate_requirements()"
   ],
   "id": "6768768217d7f55d",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 6. Submit the Model and Artifact to the Model Store"
   ],
   "id": "bb2fffdebfcdcdff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T18:14:24.614442Z",
     "start_time": "2025-03-13T18:14:23.589772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mc.submit_model(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\",\n",
    "    model=model,\n",
    "    file_format=\"pt\",\n",
    "    model_store=\"huggingface\",\n",
    "    inference_label=\"/Users/neeleshkarthikeyan/d2i/patra-toolkit/examples/notebooks/labels.txt\"\n",
    ")"
   ],
   "id": "2078753c2f740d43",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: neelk-resnet50-0.1\n",
      "INFO:root:Repository credentials stored.\n",
      "INFO:root:Model serialized successfully.\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "INFO:root:Model uploaded at: https://huggingface.co/nkarthikeyan/neelk-resnet50-0.1/blob/main/neelk-resnet50-0.1.pt\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "INFO:root:Inference label uploaded at: https://huggingface.co/nkarthikeyan/neelk-resnet50-0.1/blob/main/labels.txt\n",
      "INFO:root:ModelCard submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Model card already exists', 'model_card_id': 'neelk-resnet50-0.1'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T18:15:03.213020Z",
     "start_time": "2025-03-13T18:15:02.953783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mc.submit_artifact(\n",
    "    artifact_path=\"/Users/neeleshkarthikeyan/d2i/patra-toolkit/examples/notebooks/data/camera_trap_img.JPG\"\n",
    ")"
   ],
   "id": "7a6fb036e46cdda",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "INFO:root:Artifact stored at: https://huggingface.co/nkarthikeyan/neelk-resnet50-0.1/blob/main/camera_trap_img.JPG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'artifact_location': 'https://huggingface.co/nkarthikeyan/neelk-resnet50-0.1/blob/main/camera_trap_img.JPG'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T18:19:16.416152Z",
     "start_time": "2025-03-13T18:19:15.911340Z"
    }
   },
   "cell_type": "code",
   "source": "mc.submit_artifact(\"/Users/neeleshkarthikeyan/d2i/patra-toolkit/examples/model_cards/README.json\")",
   "id": "2b5a8ebda17a59e5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Artifact stored at: https://huggingface.co/nkarthikeyan/neelk-resnet50-0.1/blob/main/README.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'artifact_location': 'https://huggingface.co/nkarthikeyan/neelk-resnet50-0.1/blob/main/README.json'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "71d50d220e6a81b3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
