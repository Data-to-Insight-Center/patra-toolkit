{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Getting Started with Patra Toolkit\n",
    "\n",
    "This notebook serves as a quickstart guide to help you learn how to:\n",
    "\n",
    "- Load and preprocess an example image\n",
    "- Perform image classification with a pretrained **ResNet50** model from PyTorch\n",
    "- Generate a comprehensive Model Card using the **Patra Toolkit**\n",
    "\n",
    "By the end of this tutorial, you'll have a Model Card (in JSON format) that captures key metadata about your model and its prediction.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Environment Setup\n",
    "\n",
    "### 1.1 Install Required Packages\n",
    "Run the following cell to install the required packages:\n",
    "- `torch` and `torchvision` for the model and image processing\n",
    "- `patra_toolkit` for creating the Model Card\n",
    "- `Pillow` for image handling\n",
    "- `scikit-learn` (if needed) for additional utilities\n",
    "\n",
    "---\n"
   ],
   "id": "a1106a2d67b43cd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T20:59:39.933453Z",
     "start_time": "2025-03-07T20:59:38.279037Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install torch torchvision patra_toolkit Pillow scikit-learn",
   "id": "b125ea15282c07e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (2.6.0)\r\n",
      "Requirement already satisfied: torchvision in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (0.21.0)\r\n",
      "Requirement already satisfied: patra_toolkit in /Users/neeleshkarthikeyan/d2i/patra-toolkit (0.1.2)\r\n",
      "Requirement already satisfied: Pillow in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (11.1.0)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (1.5.2)\r\n",
      "Requirement already satisfied: filelock in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from torch) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from torch) (3.1.5)\r\n",
      "Requirement already satisfied: fsspec in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from torch) (2025.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: numpy in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from torchvision) (1.26.4)\r\n",
      "Requirement already satisfied: jsonschema>4.18.5 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (4.18.6)\r\n",
      "Requirement already satisfied: fairlearn~=0.11.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (0.11.0)\r\n",
      "Requirement already satisfied: shap~=0.46.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (0.46.0)\r\n",
      "Requirement already satisfied: pandas>=2.0.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (2.2.3)\r\n",
      "Requirement already satisfied: requests>2.32.2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from scikit-learn) (1.13.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (23.1.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (2024.10.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (0.36.2)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (0.22.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from pandas>=2.0.0->patra_toolkit) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from pandas>=2.0.0->patra_toolkit) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from pandas>=2.0.0->patra_toolkit) (2025.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests>2.32.2->patra_toolkit) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests>2.32.2->patra_toolkit) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests>2.32.2->patra_toolkit) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests>2.32.2->patra_toolkit) (2025.1.31)\r\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (4.67.1)\r\n",
      "Requirement already satisfied: packaging>20.9 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (24.2)\r\n",
      "Requirement already satisfied: slicer==0.0.8 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (0.0.8)\r\n",
      "Requirement already satisfied: numba in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (0.61.0)\r\n",
      "Requirement already satisfied: cloudpickle in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (3.1.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->patra_toolkit) (1.17.0)\r\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from numba->shap~=0.46.0->patra_toolkit) (0.44.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.2 Import Dependencies\n",
    "\n",
    "Below, we import the necessary libraries. We also add the repository root to `sys.path` so that the latest local version of `patra_toolkit` is imported (if needed).\n",
    "\n",
    "---"
   ],
   "id": "606c8bdd5fb8fbac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T20:59:39.943400Z",
     "start_time": "2025-03-07T20:59:39.938387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import io\n",
    "import json\n",
    "import logging\n",
    "import tempfile\n",
    "import requests\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Import Patra Toolkit components\n",
    "from patra_toolkit import ModelCard, AIModel\n",
    "\n",
    "# Set logging level\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Optionally, add repo root to sys.path if working with a local patra_toolkit repo\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)"
   ],
   "id": "7650ae0f61ab8434",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2. Load and Preprocess an Example Image\n",
    "\n",
    "We'll download an example image from a URL. Then, we'll apply the same preprocessing as required by ResNet50:\n",
    "- Resize to 256 pixels on the smaller side\n",
    "- Center-crop to 224×224\n",
    "- Convert to a tensor and normalize using the ImageNet statistics\n",
    "\n",
    "---\n"
   ],
   "id": "ec80886749709316"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T20:59:40.169470Z",
     "start_time": "2025-03-07T20:59:39.992256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# URL of an example image (you can choose any valid image URL)\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/9/9a/Pug_600.jpg\"  # example: a picture of a pug\n",
    "\n",
    "# Download the image\n",
    "response = requests.get(image_url)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Open the image with PIL\n",
    "image = Image.open(io.BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "# Define the transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    # Normalization parameters from ImageNet\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "input_tensor = preprocess(image)\n",
    "# Create a mini-batch as expected by the model\n",
    "input_batch = input_tensor.unsqueeze(0)"
   ],
   "id": "af3a58fa90925977",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 3. Image Prediction with Pretrained ResNet50\n",
    "\n",
    "We load the pretrained ResNet50 model and perform inference on the preprocessed image. We'll then decode the top prediction using the default weights.\n",
    "\n",
    "---\n"
   ],
   "id": "c9ff12dc72138de9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T20:59:40.722785Z",
     "start_time": "2025-03-07T20:59:40.185772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import certifi\n",
    "\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()\n",
    "\n",
    "# Load pretrained ResNet50 model\n",
    "# torchvision.models.ResNet50_Weights.DEFAULT is available in newer torchvision releases\n",
    "weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "model = torchvision.models.resnet50(weights=weights)\n",
    "model.eval()  # set to evaluation mode\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "# Get probabilities using softmax\n",
    "probabilities = F.softmax(output[0], dim=0)\n",
    "\n",
    "# Get the top 5 predictions\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "\n",
    "# Use the weights metadata to map category IDs to labels\n",
    "categories = weights.meta[\"categories\"]"
   ],
   "id": "aafa2802bc26a67e",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Model Card Generation with Patra Toolkit\n",
    "\n",
    "Next, we'll create a Model Card capturing key metadata about the model.\n",
    "Since we're using a pretrained ResNet50, we'll record its details and top prediction.\n"
   ],
   "id": "9f3716e9b40850ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T20:59:40.741113Z",
     "start_time": "2025-03-07T20:59:40.738498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a ModelCard instance\n",
    "mc = ModelCard(\n",
    "    name=\"ResNet50\",\n",
    "    version=\"0.1\",\n",
    "    short_description=\"A pretrained ResNet50 image classifier\",\n",
    "    full_description=\"This model card demonstrates using a pretrained ResNet50 model from PyTorch\",\n",
    "    keywords=\"resnet50, pytorch, image classification, patra, pretrained\",\n",
    "    author=\"neelk\",\n",
    "    input_type=\"Image\",\n",
    "    category=\"classification\",\n",
    "    foundational_model=\"None\"\n",
    ")\n",
    "\n",
    "# For demonstration, we set input_data as the example image URL\n",
    "mc.input_data = image_url\n"
   ],
   "id": "7a8632f1c190f585",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4.1 Create an AIModel Instance\n",
    "\n",
    "We attach an AIModel instance to the ModelCard with details about the model.\n",
    "\n",
    "---"
   ],
   "id": "32a667fffe41a1b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T20:59:40.761165Z",
     "start_time": "2025-03-07T20:59:40.758641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ai_model = AIModel(\n",
    "    name=\"ResNet50\",\n",
    "    version=\"0.1\",\n",
    "    description=\"Pretrained ResNet50 model from torchvision for image classification.\",\n",
    "    owner=\"Neelesh Karthikeyan\",\n",
    "    location=\"\",  # will be updated after model submission\n",
    "    license=\"BSD-3 Clause\",\n",
    "    framework=\"pytorch\",\n",
    "    model_type=\"cnn\",\n",
    "    test_accuracy=0.0  # As we're not training, we leave this as 0.0\n",
    ")\n",
    "\n",
    "# Attach the AIModel to the ModelCard\n",
    "mc.ai_model = ai_model\n"
   ],
   "id": "6768768217d7f55d",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4.2 Automatically Capture Environment Requirements\n",
    "\n",
    "This function parses the environment to capture installed packages.\n",
    "\n",
    "---"
   ],
   "id": "d619d57457a5c7f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T20:59:40.800934Z",
     "start_time": "2025-03-07T20:59:40.798382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mc.populate_requirements()\n",
    "print(\"Requirements captured:\")\n",
    "print(mc.model_requirements[:5])  # print the first five requirements"
   ],
   "id": "27aac4cf48e876ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirements captured:\n",
      "['absl-py==2.1.0', 'aiohappyeyeballs==2.5.0', 'aiohttp==3.11.13', 'aiosignal==1.3.2', 'annotated-types==0.7.0']\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 5. Validate and Save the Model Card\n",
    "\n",
    "We now validate the Model Card against the default schema. If valid, we save it locally as a JSON file.\n",
    "\n",
    "---"
   ],
   "id": "11b44f042f8a7db7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T20:59:40.842722Z",
     "start_time": "2025-03-07T20:59:40.835651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if mc.validate():\n",
    "    mc.save(\"imagenet_mc.json\")\n",
    "    print(\"Model Card validated successfully and saved as 'imagenet_mc.json'.\")\n",
    "else:\n",
    "    print(\"Model Card validation failed.\")\n"
   ],
   "id": "80e2ae95bdc421c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model card saved to imagenet_mc.json.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Card validated successfully and saved as 'imagenet_mc.json'.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 6. Submit the Model and Artifact to the Patra Server and Model Store\n",
    "\n",
    "For demonstration purposes, we assume the Patra server is running locally at `http://127.0.0.1:5002`\n",
    "and that the model store (e.g., Hugging Face) is configured accordingly.\n",
    "\n",
    "**Note:**\n",
    "- When submitting a model, we need to serialize it.\n",
    "- For PyTorch, common serialization formats include `\"pt\"` (using `state_dict()`) or `\"onnx\"`.\n",
    "- In this example, we use `\"pt\"`.\n",
    "- Similarly, we can submit an artifact (for example, the input image file).\n",
    "\n",
    "---"
   ],
   "id": "bb2fffdebfcdcdff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T20:59:53.336422Z",
     "start_time": "2025-03-07T20:59:40.864874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Submit the model to the Patra server\n",
    "mc.submit_model(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\",\n",
    "    model=model,\n",
    "    file_format=\"pt\",\n",
    "    model_store=\"github\"\n",
    ")"
   ],
   "id": "2078753c2f740d43",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:PID generated: neelk-resnet50-0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'neelk-resnet50-0.1' created successfully.\n",
      "Initialized empty Git repository in /private/var/folders/d7/zwq9fkgs65xdfbrv7v00g8dc0000gn/T/neelk-resnet50-0.1rm1ihed5/.git/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: warning: See https://gh.io/lfs for more information.        \n",
      "remote: warning: File neelk-resnet50-0.1.pt is 97.79 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB        \n",
      "remote: warning: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.        \n",
      "To https://github.com/nee1k/neelk-resnet50-0.1.git\n",
      " * [new branch]      main -> main\n",
      "INFO:root:Model stored at: https://github.com/nee1k/neelk-resnet50-0.1/blob/main/neelk-resnet50-0.1.pt\n",
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Successfully uploaded the model card',\n",
       " 'model_card_id': 'neelk-resnet50-0.1'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T21:00:01.863371Z",
     "start_time": "2025-03-07T20:59:53.368674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mc.submit_artifact(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\",\n",
    "    artifact_path=\"labels.txt\",\n",
    "    model_store=\"github\"\n",
    ")"
   ],
   "id": "7a6fb036e46cdda",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:PID generated: neelk-resnet50-0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'neelk-resnet50-0.1' already exists. Using existing repository.\n",
      "Initialized empty Git repository in /private/var/folders/d7/zwq9fkgs65xdfbrv7v00g8dc0000gn/T/neelk-resnet50-0.13db_y19k/.git/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/nee1k/neelk-resnet50-0.1\n",
      " * branch            main       -> FETCH_HEAD\n",
      " * [new branch]      main       -> origin/main\n",
      "To https://github.com/nee1k/neelk-resnet50-0.1.git\n",
      "   3f8a409..52cf2df  main -> main\n",
      "INFO:root:Artifact stored at: https://github.com/nee1k/neelk-resnet50-0.1/blob/main/labels.txt\n",
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Model card already exists', 'model_card_id': 'neelk-resnet50-0.1'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 7. Conclusion\n",
    "\n",
    "In this notebook, we have:\n",
    "- Loaded and preprocessed an example image.\n",
    "- Performed image prediction using a pretrained ResNet50 model from PyTorch.\n",
    "- Created and populated a Model Card using the Patra Toolkit.\n",
    "- Validated and saved the Model Card.\n",
    "- Submitted the model and an artifact to the Patra server (assuming the server is running).\n",
    "\n",
    "This serves as a foundation for creating more transparent and accountable AI solutions with detailed metadata tracking using the Patra Toolkit."
   ],
   "id": "e7ba2bdcbdd46238"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
