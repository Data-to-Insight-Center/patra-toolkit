{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Getting Started with Patra Toolkit\n",
    "\n",
    "This Colab Notebook is a quickstart guide that helps you:\n",
    "- Load and preprocess an example image (from an online URL)\n",
    "- Perform image classification with a pretrained ResNet50 model from PyTorch\n",
    "- Generate a comprehensive Model Card using the Patra Toolkit\n",
    "\n",
    "By the end of this tutorial, you will have a Model Card (in JSON format) that captures key metadata about your model and its predictions."
   ],
   "id": "a1106a2d67b43cd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T15:50:55.731118Z",
     "start_time": "2025-03-19T15:50:53.678373Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install torch torchvision patra_toolkit Pillow scikit-learn",
   "id": "b125ea15282c07e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (2.6.0)\r\n",
      "Requirement already satisfied: torchvision in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (0.21.0)\r\n",
      "Requirement already satisfied: patra_toolkit in /Users/neeleshkarthikeyan/d2i/patra-toolkit (0.1.2)\r\n",
      "Requirement already satisfied: Pillow in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (11.1.0)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (1.5.2)\r\n",
      "Requirement already satisfied: filelock in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from torch) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from torch) (3.1.5)\r\n",
      "Requirement already satisfied: fsspec in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from torch) (2025.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: numpy in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from torchvision) (1.26.4)\r\n",
      "Requirement already satisfied: jsonschema>4.18.5 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (4.18.6)\r\n",
      "Requirement already satisfied: fairlearn~=0.11.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (0.11.0)\r\n",
      "Requirement already satisfied: shap~=0.46.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (0.46.0)\r\n",
      "Requirement already satisfied: pandas>=2.0.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (2.2.3)\r\n",
      "Requirement already satisfied: requests>2.32.2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from scikit-learn) (1.13.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (23.1.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (2024.10.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (0.36.2)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (0.22.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from pandas>=2.0.0->patra_toolkit) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from pandas>=2.0.0->patra_toolkit) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from pandas>=2.0.0->patra_toolkit) (2025.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests>2.32.2->patra_toolkit) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests>2.32.2->patra_toolkit) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests>2.32.2->patra_toolkit) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests>2.32.2->patra_toolkit) (2025.1.31)\r\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (4.67.1)\r\n",
      "Requirement already satisfied: packaging>20.9 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (24.2)\r\n",
      "Requirement already satisfied: slicer==0.0.8 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (0.0.8)\r\n",
      "Requirement already satisfied: numba in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (0.61.0)\r\n",
      "Requirement already satisfied: cloudpickle in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (3.1.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->patra_toolkit) (1.17.0)\r\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from numba->shap~=0.46.0->patra_toolkit) (0.44.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.2 Import Dependencies\n",
    "\n",
    "Below, we import the necessary libraries. We also add the repository root to `sys.path` so that the latest local version of `patra_toolkit` is imported (if needed).\n",
    "\n",
    "---"
   ],
   "id": "606c8bdd5fb8fbac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T15:51:00.504506Z",
     "start_time": "2025-03-19T15:50:55.736165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import io\n",
    "import logging\n",
    "import requests\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Import Patra Toolkit components\n",
    "from patra_toolkit import ModelCard, AIModel\n",
    "\n",
    "# Set logging level\n",
    "logging.basicConfig(level=logging.INFO)"
   ],
   "id": "7650ae0f61ab8434",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2. Load and Preprocess an Example Image\n",
    "\n",
    "We'll download an example image from a URL. Then, we'll apply the same preprocessing as required by ResNet50:\n",
    "- Resize to 256 pixels on the smaller side\n",
    "- Center-crop to 224×224\n",
    "- Convert to a tensor and normalize using the ImageNet statistics\n",
    "\n",
    "---\n"
   ],
   "id": "ec80886749709316"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T15:51:00.591401Z",
     "start_time": "2025-03-19T15:51:00.518217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# URL of an example image (you can choose any valid image URL)\n",
    "image_path = \"/Users/neeleshkarthikeyan/d2i/patra-toolkit/examples/notebooks/data/camera_trap_img.JPG\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# Define the transformations\n",
    "from torchvision import transforms\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    # Normalization parameters from ImageNet\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "input_tensor = preprocess(image)\n",
    "# Create a mini-batch as expected by the model\n",
    "input_batch = input_tensor.unsqueeze(0)"
   ],
   "id": "af3a58fa90925977",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 3. Image Prediction with Pretrained ResNet50\n",
    "\n",
    "We load the pretrained ResNet50 model and perform inference on the preprocessed image. We'll then decode the top prediction using the default weights.\n",
    "\n",
    "---\n"
   ],
   "id": "c9ff12dc72138de9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T15:51:01.193837Z",
     "start_time": "2025-03-19T15:51:00.595628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Load pretrained ResNet50 model\n",
    "weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "model = torchvision.models.resnet50(weights=weights)\n",
    "model.eval()  # set to evaluation mode\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "# Get probabilities using softmax\n",
    "probabilities = F.softmax(output[0], dim=0)\n",
    "\n",
    "# Get the top 5 predictions\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "\n",
    "# Use the weights metadata to map category IDs to labels\n",
    "categories = weights.meta[\"categories\"]"
   ],
   "id": "aafa2802bc26a67e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Model Card Generation with Patra Toolkit\n",
    "\n",
    "Next, we'll create a Model Card capturing key metadata about the model.\n",
    "Since we're using a pretrained ResNet50, we'll record its details and top prediction.\n"
   ],
   "id": "9f3716e9b40850ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T15:51:01.214800Z",
     "start_time": "2025-03-19T15:51:01.211634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a ModelCard instance\n",
    "mc = ModelCard(\n",
    "    name=\"ResNet50\",\n",
    "    version=\"0.2\",\n",
    "    short_description=\"A pretrained ResNet50 image classifier\",\n",
    "    full_description=\"This model card demonstrates using a pretrained ResNet50 model from PyTorch\",\n",
    "    keywords=\"resnet50, pytorch, image classification, patra, pretrained\",\n",
    "    author=\"neelk\",\n",
    "    input_type=\"Image\",\n",
    "    category=\"classification\",\n",
    "    foundational_model=\"None\",\n",
    "    citation=\"https://doi.org/10.48550/arXiv.1512.03385\"\n",
    ")\n",
    "\n",
    "# Set the input data (image URL)\n",
    "mc.input_data = \"\"\n"
   ],
   "id": "7a8632f1c190f585",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4.1 Create an AIModel Instance\n",
    "\n",
    "We attach an AIModel instance to the ModelCard with details about the model.\n",
    "\n",
    "---"
   ],
   "id": "32a667fffe41a1b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T15:51:01.249721Z",
     "start_time": "2025-03-19T15:51:01.246621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ai_model = AIModel(\n",
    "    name=\"ResNet50\",\n",
    "    version=\"0.1\",\n",
    "    description=\"Pretrained ResNet50 model from torchvision for image classification.\",\n",
    "    owner=\"Neelesh Karthikeyan\",\n",
    "    location=\"\",  # will be updated after model submission\n",
    "    license=\"BSD-3 Clause\",\n",
    "    framework=\"pytorch\",\n",
    "    model_type=\"cnn\",\n",
    "    test_accuracy=0.75\n",
    ")\n",
    "\n",
    "# Attach the AIModel to the ModelCard\n",
    "mc.ai_model = ai_model\n",
    "mc.populate_requirements()"
   ],
   "id": "6768768217d7f55d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 6. Submit the Model and Artifact to the Model Store"
   ],
   "id": "bb2fffdebfcdcdff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T15:51:14.625137Z",
     "start_time": "2025-03-19T15:51:01.279736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mc.submit(patra_server_url=\"http://127.0.0.1:5002\",\n",
    "          model=model,\n",
    "          file_format=\"h5\",\n",
    "          model_store=\"huggingface\",\n",
    "          inference_label=\"data/labels.txt\",\n",
    "          artifacts=[\"data/adult/adult.data\",\n",
    "                     \"data/adult/adult.names\",\n",
    "                     \"data/adult/adult.test\"]\n",
    "          )"
   ],
   "id": "59e434882f6b8486",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: neelk-resnet50-0.2\n",
      "INFO:root:Saved PyTorch model as /var/folders/d7/zwq9fkgs65xdfbrv7v00g8dc0000gn/T/neelk-resnet50-0.2.h5\n",
      "INFO:root:Model serialized successfully.\n",
      "neelk-resnet50-0.2.h5: 100%|██████████| 103M/103M [00:02<00:00, 38.3MB/s] \n",
      "INFO:root:Model uploaded at: https://huggingface.co/patra-iu/neelk-resnet50-0.2/blob/main/neelk-resnet50-0.2.h5\n",
      "INFO:root:Inference label uploaded at: https://huggingface.co/patra-iu/neelk-resnet50-0.2/blob/main/labels.txt\n",
      "INFO:root:Artifact 'data/adult/adult.data' uploaded at: https://huggingface.co/patra-iu/neelk-resnet50-0.2/blob/main/adult.data\n",
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/neelk-resnet50-0.2/blob/main/adult.names\n",
      "INFO:root:Artifact 'data/adult/adult.test' uploaded at: https://huggingface.co/patra-iu/neelk-resnet50-0.2/blob/main/adult.test\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T15:51:14.672325Z",
     "start_time": "2025-03-19T15:51:14.670325Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "deb86c8b8b68fa70",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
