{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# Getting Started with Patra Model Card Toolkit\n",
    "\n",
    "</div>\n",
    "\n",
    "The Patra Toolkit is a component of the Patra ModelCards framework designed to simplify the process of creating and documenting AI/ML models. It provides a structured schema that guides users in providing essential information about their models, including details about the model's purpose, development process, and performance. The toolkit also includes features for semi-automating the capture of key information, such as fairness and explainability metrics, through integrated analysis tools. By reducing the manual effort involved in creating model cards, the Patra Toolkit encourages researchers and developers to adopt best practices for documenting their models, ultimately contributing to greater transparency and accountability in AI/ML development.\n",
    "\n",
    "---\n",
    "\n",
    "## Features\n",
    "\n",
    "1. **Encourages Accountability**\n",
    "   - Incorporate essential model information (metadata, dataset details, fairness, explainability) at training time, ensuring AI models remain transparent from development to deployment.\n",
    "\n",
    "2. **Semi-Automated Capture**\n",
    "   - Automated *Fairness* and *Explainability* scanners compute demographic parity, equal odds, SHAP-based feature importances, etc., for easy integration into Model Cards.\n",
    "\n",
    "3. **Machine-Actionable Model Cards**\n",
    "   - Produce a structured JSON representation for ingestion into the Patra Knowledge Base. Ideal for advanced queries on model selection, provenance, versioning, or auditing.\n",
    "\n",
    "4. **Flexible Repository Support**\n",
    "   - Pluggable backends for storing models/artifacts on **Hugging Face** or **GitHub**, unifying the model publishing workflow.\n",
    "\n",
    "5. **Versioning & Model Relationship Tracking**\n",
    "   - Maintain multiple versions of a model with recognized edges (e.g., `revisionOf`, `alternateOf`) using embedding-based similarity. This ensures clear lineages and easy forward/backward provenance.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Loading & Preprocessing** the UCI Adult Dataset  \n",
    "2. **Training** a simple TensorFlow model  \n",
    "3. **Creating a Model Card** with optional Fairness and XAI scans  \n",
    "4. **Submitting** the Model Card (and optionally the model, inference label, and artifacts) to:\n",
    "   - **Patra server** (for model card storage)  \n",
    "   - **Backend** (Hugging Face or GitHub) for model storage\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!pip install patra_toolkit"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!pip install tensorflow"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"absl\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"PyGithub\").setLevel(logging.ERROR)\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import requests, io\n",
    "\n",
    "from patra_toolkit import ModelCard, AIModel"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Pre-process the Data\n",
    "\n",
    "We'll use the **UCI Adult Dataset**, which predicts whether an individual's income is above or below $50K based on demographics. This dataset is a common benchmark for exploring model fairness."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T00:04:11.161119Z",
     "start_time": "2025-03-21T00:04:10.094676Z"
    }
   },
   "source": [
    "resp = requests.get(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\")\n",
    "resp.raise_for_status()\n",
    "\n",
    "cols = [\n",
    "    \"age\",\"workclass\",\"fnlwgt\",\"education\",\"education_num\",\n",
    "    \"marital_status\",\"occupation\",\"relationship\",\"race\",\n",
    "    \"sex\",\"capital_gain\",\"capital_loss\",\"hours_per_week\",\n",
    "    \"native_country\",\"income\"\n",
    "]\n",
    "df = pd.read_csv(io.StringIO(resp.text), names=cols, header=None)\n",
    "\n",
    "# Encode target\n",
    "df[\"income\"] = LabelEncoder().fit_transform(df[\"income\"])  # 1 if >50K, else 0\n",
    "\n",
    "# One-hot encode everything except the target\n",
    "df = pd.get_dummies(df, drop_first=True, dtype=float)\n",
    "\n",
    "# Split into features/labels\n",
    "X = df.drop(\"income\", axis=1).astype(\"float32\").values\n",
    "y = df[\"income\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (26048, 100) Test shape: (6513, 100)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train a Simple TensorFlow Model\n",
    "\n",
    "Below is a straightforward neural network: two hidden layers plus a final sigmoid for binary classification. We'll train for a few epochs to demonstrate end-to-end usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:40.325759Z",
     "start_time": "2025-03-19T18:20:38.677897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m407/407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.6514 - loss: 425.1485\n",
      "Epoch 2/5\n",
      "\u001B[1m407/407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.6807 - loss: 45.0486\n",
      "Epoch 3/5\n",
      "\u001B[1m407/407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 811us/step - accuracy: 0.6847 - loss: 55.8134\n",
      "Epoch 4/5\n",
      "\u001B[1m407/407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 798us/step - accuracy: 0.6852 - loss: 31.7177\n",
      "Epoch 5/5\n",
      "\u001B[1m407/407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 767us/step - accuracy: 0.6801 - loss: 45.6668\n",
      "Test Loss: 12.5695, Test Accuracy: 0.7857\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building a Patra Model Card\n",
    "\n",
    "### 4.1 Basic Model Card Setup\n",
    "We start with essential metadata like name, version, short description, and so on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:40.337383Z",
     "start_time": "2025-03-19T18:20:40.334625Z"
    }
   },
   "outputs": [],
   "source": [
    "mc = ModelCard(\n",
    "    name=\"UCI_Adult_Model\",\n",
    "    version=\"1.0\",\n",
    "    short_description=\"Predicting whether an individual's income is above $50K using TensorFlow.\",\n",
    "    full_description=(\n",
    "        \"This is a feed-forward neural network trained on the UCI Adult Dataset. \"\n",
    "        \"It demonstrates how Patra Toolkit can store model details, fairness scans, \"\n",
    "        \"and basic explainability data in a comprehensive Model Card.\"\n",
    "    ),\n",
    "    keywords=\"uci, adult, patra, fairness, xai, tensorflow\",\n",
    "    author=\"neelk\",\n",
    "    input_type=\"Tabular\",\n",
    "    category=\"classification\",\n",
    "    citation=\"Becker, B. & Kohavi, R. (1996). Adult [Dataset]. UCI.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Attach AI Model Information\n",
    "Here we describe the model's ownership, license, performance metrics, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:40.349649Z",
     "start_time": "2025-03-19T18:20:40.346860Z"
    }
   },
   "outputs": [],
   "source": [
    "ai_model = AIModel(\n",
    "    name=\"AdultTFModel\",\n",
    "    version=\"1.0\",\n",
    "    description=\"DNN on UCI Adult dataset for income prediction\",\n",
    "    owner=\"username\",\n",
    "    location=\"\", \n",
    "    license=\"BSD-3-Clause\",\n",
    "    framework=\"tensorflow\",\n",
    "    model_type=\"dnn\",\n",
    "    test_accuracy=accuracy\n",
    ")\n",
    "\n",
    "# Add additional performance or training metrics\n",
    "ai_model.add_metric(\"Epochs\", 5)\n",
    "ai_model.add_metric(\"BatchSize\", 64)\n",
    "ai_model.add_metric(\"Optimizer\", \"Adam\")\n",
    "\n",
    "mc.ai_model = ai_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fairness & Explainability\n",
    "\n",
    "### 5.1 Bias (Fairness) Analysis\n",
    "Patra Toolkit has a built-in `populate_bias` method to measure metrics like **demographic parity** or **equalized odds**. We'll focus on the protected attribute \"sex\" in the data.\n",
    "\n",
    "**Why check bias?** Real-world models often inadvertently penalize certain groups. By calling `mc.populate_bias(...)`, you get a quick sense of whether the model is systematically advantaging or disadvantaging certain subpopulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:40.553767Z",
     "start_time": "2025-03-19T18:20:40.363888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m204/204\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 308us/step\n",
      "Bias Analysis:\n",
      " {'demographic_parity_diff': 0.08162253952657954, 'equal_odds_difference': 0.08368136415250488}\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred >= 0.5).flatten()\n",
    "\n",
    "mc.populate_bias(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    \"gender\",           # Name you want displayed in the report\n",
    "    X_test[:, 58],      # The slice of data that corresponds to gender\n",
    "    model\n",
    ")\n",
    "\n",
    "print(\"Bias Analysis:\\n\", mc.bias_analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Explainability (XAI)\n",
    "\n",
    "If we want to understand model decisions, we can generate interpretability metrics (like feature importance) using Patra’s internal SHAP-based approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:43.668417Z",
     "start_time": "2025-03-19T18:20:40.564575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explainability Analysis:\n",
      " {'capital_gain': 0.4196902715030088, 'fnlwgt': 0.0010686394701219777, 'relationship__Wife': 0.0004169165563382081, 'occupation__Exec_managerial': 0.00037468428402272127, 'hours_per_week': 0.00030803950899628693, 'age': 0.0002882660328522926, 'education__HS_grad': 0.00017709857654685587, 'education__Masters': 0.00015673624516589788, 'occupation__Prof_specialty': 0.00012275671500096725, 'marital_status__Married_civ_spouse': 0.00010901905207295246}\n"
     ]
    }
   ],
   "source": [
    "# Rebuild the list of columns used in training\n",
    "x_columns = df.columns.tolist()\n",
    "x_columns.remove('income')  # Remove the target\n",
    "\n",
    "mc.populate_xai(\n",
    "    X_test[:10],\n",
    "    x_columns,\n",
    "    model\n",
    ")\n",
    "\n",
    "print(\"Explainability Analysis:\\n\", mc.xai_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Add Requirements and Validate\n",
    "We let Patra auto-detect Python package dependencies to ensure reproducibility and then validate the card for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:43.686195Z",
     "start_time": "2025-03-19T18:20:43.678194Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Card is valid and ready to submit!\n"
     ]
    }
   ],
   "source": [
    "mc.populate_requirements()\n",
    "if mc.validate():\n",
    "    print(\"Model Card is valid and ready to submit!\")\n",
    "else:\n",
    "    print(\"Validation failed. See logs for details.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Submission Options\n",
    "\n",
    "The `mc.submit(...)` method can do one or more of the following:\n",
    "1. **Submit only the card** (no model, no artifacts).\n",
    "2. **Include the trained model** (uploading to Hugging Face or GitHub).\n",
    "3. **Add artifacts** (like data files, inference labels, or any additional resources).\n",
    "\n",
    "Below, we demonstrate multiple usage patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Submit **Only** the Model Card\n",
    "\n",
    "No model, no inference label, no artifacts. Just the card is posted to your Patra server for cataloging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:43.758444Z",
     "start_time": "2025-03-19T18:20:43.700918Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: neelk-uci_adult_model-1.0\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.submit(patra_server_url=\"http://127.0.0.1:5002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Submit Model Card and Model\n",
    "\n",
    "We can specify `\"huggingface\"` or `\"github\"` for `model_store`. This will attempt to upload our trained model, while the card is posted to the Patra server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:43.788493Z",
     "start_time": "2025-03-19T18:20:43.772095Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "ERROR:root:Model submission failed during model ID creation: Model ID already exists. Please update the model version.\n"
     ]
    }
   ],
   "source": [
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\",  \n",
    "    model=model,                \n",
    "    file_format=\"h5\",\n",
    "    model_store=\"huggingface\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:43.877874Z",
     "start_time": "2025-03-19T18:20:43.862020Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: neelk-uci_adult_model-1.1\n",
      "INFO:root:Model serialized successfully.\n",
      "INFO:root:Package 'huggingface_hub' not found. Installing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n",
      "neelk-uci_adult_model-1.1.h5: 100%|██████████| 130k/130k [00:00<00:00, 432kB/s]\n",
      "INFO:root:Model uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.1/blob/main/neelk-uci_adult_model-1.1.h5\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.version = \"1.1\"\n",
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\",  \n",
    "    model=model,                \n",
    "    file_format=\"h5\",\n",
    "    model_store=\"huggingface\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Submit Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:45.574591Z",
     "start_time": "2025-03-19T18:20:43.979182Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "WARNING:root:Model ID exists, but no model is being uploaded; continuing with existing ID.\n",
      "INFO:root:Model ID retrieved: neelk-uci_adult_model-1.1\n",
      "INFO:root:Artifact 'data/adult/adult.data' uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.1/blob/main/adult.data\n",
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.1/blob/main/adult.names\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.1/blob/main/adult.names\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\", \n",
    "    model_store=\"huggingface\",\n",
    "    artifacts=[\"data/adult/adult.data\", \n",
    "               \"data/adult/adult.names\",\n",
    "               \"data/adult/adult.names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Submit Model Card, Model, and Artifacts\n",
    "\n",
    "This scenario might include a special label file plus multiple dataset artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:45.658798Z",
     "start_time": "2025-03-19T18:20:45.631065Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "ERROR:root:Model submission failed during model ID creation: Model ID already exists. Please update the model version.\n"
     ]
    }
   ],
   "source": [
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\", \n",
    "    model=model,\n",
    "    file_format=\"h5\",\n",
    "    model_store=\"huggingface\",\n",
    "    inference_labels=\"data/labels.txt\",\n",
    "    artifacts=[\"data/adult/adult.data\", \n",
    "               \"data/adult/adult.names\",\n",
    "               \"data/adult/adult.names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:49.901423Z",
     "start_time": "2025-03-19T18:20:45.675690Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: neelk-uci_adult_model-1.2\n",
      "INFO:root:Model serialized successfully.\n",
      "neelk-uci_adult_model-1.2.h5: 100%|██████████| 130k/130k [00:00<00:00, 1.08MB/s]\n",
      "INFO:root:Model uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.2/blob/main/neelk-uci_adult_model-1.2.h5\n",
      "INFO:root:Inference label uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.2/blob/main/labels.txt\n",
      "INFO:root:Artifact 'data/adult/adult.data' uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.2/blob/main/adult.data\n",
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.2/blob/main/adult.names\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.2/blob/main/adult.names\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.version = \"1.2\"\n",
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\", \n",
    "    model=model,\n",
    "    file_format=\"h5\",\n",
    "    model_store=\"huggingface\",\n",
    "    inference_labels=\"data/labels.txt\",\n",
    "    artifacts=[\"data/adult/adult.data\", \n",
    "               \"data/adult/adult.names\",\n",
    "               \"data/adult/adult.names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Pushing to GitHub\n",
    "\n",
    "By switching `\"huggingface\"` to `\"github\"`, you can store your model in a GitHub repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:21:01.263306Z",
     "start_time": "2025-03-19T18:20:49.919833Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: neelk-uci_adult_model-1.3\n",
      "INFO:root:Model serialized successfully.\n",
      "INFO:root:Package 'PyGithub' not found. Installing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'neelk-uci_adult_model-1.3' already exists. Using existing repository.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model uploaded at: https://github.com/nee1k/neelk-uci_adult_model-1.3/blob/main/neelk-uci_adult_model-1.3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'neelk-uci_adult_model-1.3' already exists. Using existing repository.\n",
      "No changes to commit, skipping commit step.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Inference label uploaded at: https://github.com/nee1k/neelk-uci_adult_model-1.3/blob/main/labels.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'neelk-uci_adult_model-1.3' already exists. Using existing repository.\n",
      "No changes to commit, skipping commit step.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Artifact 'data/adult/adult.data' uploaded at: https://github.com/nee1k/neelk-uci_adult_model-1.3/blob/main/adult.data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'neelk-uci_adult_model-1.3' already exists. Using existing repository.\n",
      "No changes to commit, skipping commit step.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://github.com/nee1k/neelk-uci_adult_model-1.3/blob/main/adult.names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'neelk-uci_adult_model-1.3' already exists. Using existing repository.\n",
      "No changes to commit, skipping commit step.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://github.com/nee1k/neelk-uci_adult_model-1.3/blob/main/adult.names\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.version = \"1.3\"\n",
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\", \n",
    "    model=model,\n",
    "    file_format=\"h5\",\n",
    "    model_store=\"github\",\n",
    "    inference_labels=\"data/labels.txt\",\n",
    "    artifacts=[\"data/adult/adult.data\", \n",
    "               \"data/adult/adult.names\",\n",
    "               \"data/adult/adult.names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following this notebook, you have:\n",
    "1. Loaded and preprocessed the UCI Adult Dataset\n",
    "2. Trained a TensorFlow model to predict income\n",
    "3. Built a Patra Model Card describing the model’s purpose, performance, and environment\n",
    "4. Scanned for fairness and explainability metrics\n",
    "5. Submitted the card to a Patra server along with the model or artifacts to a chosen store (Hugging Face or GitHub)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
