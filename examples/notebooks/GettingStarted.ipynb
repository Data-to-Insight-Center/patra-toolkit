{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTDtPAC3t26L"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "# Getting Started with Patra Model Card Toolkit\n",
        "\n",
        "</div>\n",
        "\n",
        "The Patra Toolkit is a component of the Patra ModelCards framework designed to simplify the process of creating and documenting AI/ML models. It provides a structured schema that guides users in providing essential information about their models, including details about the model's purpose, development process, and performance. The toolkit also includes features for semi-automating the capture of key information, such as fairness and explainability metrics, through integrated analysis tools. By reducing the manual effort involved in creating model cards, the Patra Toolkit encourages researchers and developers to adopt best practices for documenting their models, ultimately contributing to greater transparency and accountability in AI/ML development.\n",
        "\n",
        "---\n",
        "\n",
        "## Features\n",
        "\n",
        "1. **Encourages Accountability**\n",
        "   - Incorporate essential model information (metadata, dataset details, fairness, explainability) at training time, ensuring AI models remain transparent from development to deployment.\n",
        "\n",
        "2. **Semi-Automated Capture**\n",
        "   - Automated *Fairness* and *Explainability* scanners compute demographic parity, equal odds, SHAP-based feature importances, etc., for easy integration into Model Cards.\n",
        "\n",
        "3. **Machine-Actionable Model Cards**\n",
        "   - Produce a structured JSON representation for ingestion into the Patra Knowledge Base. Ideal for advanced queries on model selection, provenance, versioning, or auditing.\n",
        "\n",
        "4. **Flexible Repository Support**\n",
        "   - Pluggable backends for storing models/artifacts on **Hugging Face** or **GitHub**, unifying the model publishing workflow.\n",
        "\n",
        "5. **Versioning & Model Relationship Tracking**\n",
        "   - Maintain multiple versions of a model with recognized edges (e.g., `revisionOf`, `alternateOf`) using embedding-based similarity. This ensures clear lineages and easy forward/backward provenance.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "This notebook demonstrates:\n",
        "\n",
        "1. **Loading & Preprocessing** the UCI Adult Dataset  \n",
        "2. **Training** a simple TensorFlow model  \n",
        "3. **Creating a Model Card** with optional Fairness and XAI scans  \n",
        "4. **Submitting** the Model Card (and optionally the model, inference label, and artifacts) to:\n",
        "   - **Patra server** (for model card storage)  \n",
        "   - **Backend** (Hugging Face or GitHub) for model storage\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "AF4REySnt26M"
      },
      "source": [
        "!pip install git+https://github.com/Data-to-Insight-Center/patra-toolkit"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pandas tensorflow scikit-learn"
      ],
      "metadata": {
        "id": "w3hH-s-1WueZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DKW3R7Pt26N"
      },
      "source": [
        "import logging\n",
        "# logging.basicConfig(level=logging.INFO)\n",
        "logging.getLogger(\"absl\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"PyGithub\").setLevel(logging.ERROR)\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from patra_toolkit import ModelCard, AIModel"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv1JQLnet26N"
      },
      "source": [
        "## 2. Load and Pre-process the Data\n",
        "\n",
        "We'll use the **UCI Adult Dataset**, which predicts whether an individual's income is above or below $50K based on demographics. This dataset is a common benchmark for exploring model fairness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-21T00:04:11.161119Z",
          "start_time": "2025-03-21T00:04:10.094676Z"
        },
        "id": "shP7K7tst26N"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/Data-to-Insight-Center/patra-toolkit/main/examples/notebooks/data/adult/adult.data\"\n",
        "cols = [\n",
        "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
        "    \"marital_status\", \"occupation\", \"relationship\", \"race\",\n",
        "    \"sex\", \"capital_gain\", \"capital_loss\", \"hours_per_week\",\n",
        "    \"native_country\", \"income\"\n",
        "]\n",
        "df = pd.read_csv(url, names=cols, header=None)\n",
        "\n",
        "# Encode target\n",
        "df[\"income\"] = LabelEncoder().fit_transform(df[\"income\"])  # 1 if >50K, else 0\n",
        "\n",
        "# One-hot encode everything except the target\n",
        "df = pd.get_dummies(df, drop_first=True, dtype=float)\n",
        "\n",
        "# Split into features/labels\n",
        "X = df.drop(\"income\", axis=1).astype(\"float32\").values\n",
        "y = df[\"income\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2KTI91Ct26O"
      },
      "source": [
        "## 3. Train a Simple TensorFlow Model\n",
        "\n",
        "Below is a straightforward neural network: two hidden layers plus a final sigmoid for binary classification. We'll train for a few epochs to demonstrate end-to-end usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-19T18:20:40.325759Z",
          "start_time": "2025-03-19T18:20:38.677897Z"
        },
        "id": "7qXO-rRGt26O"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=1)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XUvWIIkt26O"
      },
      "source": [
        "## 4. Building a Patra Model Card\n",
        "\n",
        "### 4.1 Basic Model Card Setup\n",
        "We start with essential metadata like name, version, short description, and so on.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-19T18:20:40.337383Z",
          "start_time": "2025-03-19T18:20:40.334625Z"
        },
        "id": "dkhDTjzit26P"
      },
      "outputs": [],
      "source": [
        "mc = ModelCard(\n",
        "    name=\"UCI_Adult_Model\",\n",
        "    version=\"1.0\",\n",
        "    short_description=\"Predicting whether an individual's income is above $50K using TensorFlow.\",\n",
        "    full_description=(\n",
        "        \"This is a feed-forward neural network trained on the UCI Adult Dataset. \"\n",
        "        \"It demonstrates how Patra Toolkit can store model details, fairness scans, \"\n",
        "        \"and basic explainability data in a comprehensive Model Card.\"\n",
        "    ),\n",
        "    keywords=\"uci, adult, patra, fairness, xai, tensorflow\",\n",
        "    author=\"neelk\",\n",
        "    input_type=\"Tabular\",\n",
        "    category=\"classification\",\n",
        "    citation=\"Becker, B. & Kohavi, R. (1996). Adult [Dataset]. UCI.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8gikzSdt26P"
      },
      "source": [
        "### 4.2 Attach AI Model Information\n",
        "Here we describe the model's ownership, license, performance metrics, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-19T18:20:40.349649Z",
          "start_time": "2025-03-19T18:20:40.346860Z"
        },
        "id": "9u_K5vhjt26P"
      },
      "outputs": [],
      "source": [
        "ai_model = AIModel(\n",
        "    name=\"AdultTFModel\",\n",
        "    version=\"1.0\",\n",
        "    description=\"DNN on UCI Adult dataset for income prediction\",\n",
        "    owner=\"username\",\n",
        "    location=\"\",\n",
        "    license=\"BSD-3-Clause\",\n",
        "    framework=\"tensorflow\",\n",
        "    model_type=\"dnn\",\n",
        "    test_accuracy=accuracy\n",
        ")\n",
        "\n",
        "# Add additional performance or training metrics\n",
        "ai_model.add_metric(\"Epochs\", 5)\n",
        "ai_model.add_metric(\"BatchSize\", 64)\n",
        "ai_model.add_metric(\"Optimizer\", \"Adam\")\n",
        "\n",
        "mc.ai_model = ai_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BAHFlzNt26P"
      },
      "source": [
        "## 5. Fairness & Explainability\n",
        "\n",
        "### 5.1 Bias (Fairness) Analysis\n",
        "Patra Toolkit has a built-in `populate_bias` method to measure metrics like **demographic parity** or **equalized odds**. We'll focus on the protected attribute \"sex\" in the data.\n",
        "\n",
        "**Why check bias?** Real-world models often inadvertently penalize certain groups. By calling `mc.populate_bias(...)`, you get a quick sense of whether the model is systematically advantaging or disadvantaging certain subpopulations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-19T18:20:40.553767Z",
          "start_time": "2025-03-19T18:20:40.363888Z"
        },
        "id": "viTyQc0lt26P"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred >= 0.5).flatten()\n",
        "\n",
        "mc.populate_bias(\n",
        "    X_test,\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    \"gender\",\n",
        "    X_test[:, 58],\n",
        "    model\n",
        ")\n",
        "\n",
        "print(\"Bias Analysis:\\n\", mc.bias_analysis)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyNKlxwtt26P"
      },
      "source": [
        "### 5.2 Explainability (XAI)\n",
        "\n",
        "If we want to understand model decisions, we can generate interpretability metrics (like feature importance) using Patra’s internal SHAP-based approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-19T18:20:43.668417Z",
          "start_time": "2025-03-19T18:20:40.564575Z"
        },
        "id": "-jF9c6OBt26P"
      },
      "outputs": [],
      "source": [
        "# Rebuild the list of columns used in training\n",
        "x_columns = df.columns.tolist()\n",
        "x_columns.remove('income')\n",
        "\n",
        "mc.populate_xai(\n",
        "    X_test[:10],\n",
        "    x_columns,\n",
        "    model\n",
        ")\n",
        "\n",
        "print(\"Explainability Analysis:\\n\", mc.xai_analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUlIE1a0t26Q"
      },
      "source": [
        "## 6. Add Requirements and Validate\n",
        "We let Patra auto-detect Python package dependencies to ensure reproducibility and then validate the card for completeness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-19T18:20:43.686195Z",
          "start_time": "2025-03-19T18:20:43.678194Z"
        },
        "id": "sHXlakOCt26Q"
      },
      "outputs": [],
      "source": [
        "mc.populate_requirements()\n",
        "if mc.validate():\n",
        "    print(\"Model Card is valid and ready to submit!\")\n",
        "else:\n",
        "    print(\"Validation failed. See logs for details.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpvGY-1zt26Q"
      },
      "source": [
        "## 7. Submission Options\n",
        "\n",
        "The `mc.submit(...)` method can do one or more of the following:\n",
        "1. **Submit only the card** (no model, no artifacts).\n",
        "2. **Include the trained model** (uploading to Hugging Face or GitHub).\n",
        "3. **Add artifacts** (like data files, inference labels, or any additional resources).\n",
        "\n",
        "Below, we demonstrate multiple usage patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4qTtbMvt26Q"
      },
      "source": [
        "### 7.1 Submit **Only** the Model Card\n",
        "\n",
        "No model, no inference label, no artifacts. Just the card is posted to your Patra server for cataloging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-19T18:20:43.758444Z",
          "start_time": "2025-03-19T18:20:43.700918Z"
        },
        "id": "uH1WeTSzt26Q"
      },
      "outputs": [],
      "source": [
        "patra_server_url = \"http://149.165.172.217:5002\"\n",
        "mc.version = \"1.0\"\n",
        "\n",
        "mc.submit(patra_server_url=patra_server_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puIdk-Lgt26Q"
      },
      "source": [
        "### 7.2 Submit Model Card and Model\n",
        "\n",
        "We can specify `\"huggingface\"` or `\"github\"` for `model_store`. This will attempt to upload our trained model, while the card is posted to the Patra server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-19T18:20:43.788493Z",
          "start_time": "2025-03-19T18:20:43.772095Z"
        },
        "id": "KEuqWkPFt26Q"
      },
      "outputs": [],
      "source": [
        "mc.submit(\n",
        "    patra_server_url=patra_server_url,\n",
        "    model=model,\n",
        "    file_format=\"h5\",\n",
        "    model_store=\"huggingface\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-19T18:20:43.877874Z",
          "start_time": "2025-03-19T18:20:43.862020Z"
        },
        "id": "lUK8H1a8t26Q"
      },
      "outputs": [],
      "source": [
        "mc.version = \"1.1\"\n",
        "mc.submit(\n",
        "    patra_server_url=patra_server_url,\n",
        "    model=model,\n",
        "    file_format=\"h5\",\n",
        "    model_store=\"huggingface\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nRhesNqt26Q"
      },
      "source": [
        "### 7.3 Submit Artifacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-19T18:20:45.574591Z",
          "start_time": "2025-03-19T18:20:43.979182Z"
        },
        "id": "BZxUbbbGt26Q"
      },
      "outputs": [],
      "source": [
        "mc.submit(\n",
        "    patra_server_url=patra_server_url,\n",
        "    model_store=\"huggingface\",\n",
        "    artifacts=[\"data/adult/adult.data\",\n",
        "               \"data/adult/adult.names\",\n",
        "               \"data/adult/adult.names\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM94gyaUt26Q"
      },
      "source": [
        "### 7.4 Submit Model Card, Model, and Artifacts\n",
        "\n",
        "This scenario might include a special label file plus multiple dataset artifacts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-19T18:20:45.658798Z",
          "start_time": "2025-03-19T18:20:45.631065Z"
        },
        "id": "RT1wByiet26Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wget\n",
        "\n",
        "# Download artifacts to upload\n",
        "wget.download(\"https://raw.githubusercontent.com/Data-to-Insight-Center/patra-toolkit/main/examples/notebooks/data/adult/adult.data\", \"adult.data\")\n",
        "wget.download(\"https://raw.githubusercontent.com/Data-to-Insight-Center/patra-toolkit/main/examples/notebooks/data/adult/adult.names\", \"adult.names\")\n",
        "\n",
        "with open(\"labels.txt\", \"w\") as f:\n",
        "    f.write(\"Label 1\\n\")\n",
        "    f.write(\"Label 2\\n\")\n",
        "\n",
        "\n",
        "mc.submit(\n",
        "    patra_server_url=patra_server_url,\n",
        "    model=model,\n",
        "    file_format=\"h5\",\n",
        "    model_store=\"huggingface\",\n",
        "    inference_labels=\"labels.txt\",\n",
        "    artifacts=[\"adult.data\", \"adult.names\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-19T18:20:49.901423Z",
          "start_time": "2025-03-19T18:20:45.675690Z"
        },
        "id": "2lVg1xHwt26Q"
      },
      "outputs": [],
      "source": [
        "mc.version = \"1.2\"\n",
        "mc.submit(\n",
        "    patra_server_url=patra_server_url,\n",
        "    model=model,\n",
        "    file_format=\"h5\",\n",
        "    model_store=\"huggingface\",\n",
        "    inference_labels=\"labels.txt\",\n",
        "    artifacts=[\"adult.data\", \"adult.names\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkNMFKNZt26Q"
      },
      "source": [
        "### 7.4 Pushing to GitHub\n",
        "\n",
        "By switching `\"huggingface\"` to `\"github\"`, you can store your model in a GitHub repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-19T18:21:01.263306Z",
          "start_time": "2025-03-19T18:20:49.919833Z"
        },
        "id": "MvLQife_t26Q"
      },
      "outputs": [],
      "source": [
        "mc.version = \"1.3\"\n",
        "mc.submit(\n",
        "    patra_server_url=patra_server_url,\n",
        "    model=model,\n",
        "    file_format=\"h5\",\n",
        "    model_store=\"github\",\n",
        "    artifacts=[\"adult.data\", \"adult.names\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBv0f39St26Q"
      },
      "source": [
        "By following this notebook, you have:\n",
        "1. Loaded and preprocessed the UCI Adult Dataset\n",
        "2. Trained a TensorFlow model to predict income\n",
        "3. Built a Patra Model Card describing the model’s purpose, performance, and environment\n",
        "4. Scanned for fairness and explainability metrics\n",
        "5. Submitted the card to a Patra server along with the model or artifacts to a chosen store (Hugging Face or GitHub)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}