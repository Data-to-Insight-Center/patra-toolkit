{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTDtPAC3t26L"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "# Getting Started with Patra Model Card Toolkit\n",
        "\n",
        "</div>\n",
        "\n",
        "The Patra Toolkit is a component of the Patra ModelCards framework designed to simplify the process of creating and documenting AI/ML models. It provides a structured schema that guides users in providing essential information about their models, including details about the model's purpose, development process, and performance. The toolkit also includes features for semi-automating the capture of key information, such as fairness and explainability metrics, through integrated analysis tools. By reducing the manual effort involved in creating model cards, the Patra Toolkit encourages researchers and developers to adopt best practices for documenting their models, ultimately contributing to greater transparency and accountability in AI/ML development.\n",
        "\n",
        "The Patra Toolkit embeds transparency and governance directly into the training workflow. Integrated scanners collect essential metadata—data sources, fairness metrics, and explainability insights—during model training and then generate a machine‑actionable JSON model card. These cards plug into the Patra Knowledge Base for rich queries on provenance, version history, and auditing. Flexible back‑ends publish models and artifacts to repositories such as Hugging Face or GitHub, automatically recording lineage links to trace every model’s evolution.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "This notebook demonstrates:\n",
        "\n",
        "1. **Loading & Preprocessing** the UCI Adult Dataset  \n",
        "2. **Training** a simple TensorFlow model  \n",
        "3. **Creating a Model Card** with optional Fairness and XAI scans  \n",
        "4. **Submitting** the Model Card (and optionally the model, inference label, and artifacts) to:\n",
        "   - **Patra server** (for model card storage)  \n",
        "   - **Backend** (Hugging Face or GitHub) for model storage\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF4REySnt26M",
        "scrolled": true,
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:42.753151Z",
          "start_time": "2025-06-07T19:04:40.865368Z"
        },
        "outputId": "a8cc022e-8d31-4679-a94d-b904ec5444ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install git+https://github.com/Data-to-Insight-Center/patra-toolkit"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/Data-to-Insight-Center/patra-toolkit\n",
            "  Cloning https://github.com/Data-to-Insight-Center/patra-toolkit to /tmp/pip-req-build-8ykkeu7v\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Data-to-Insight-Center/patra-toolkit /tmp/pip-req-build-8ykkeu7v\n",
            "  Resolved https://github.com/Data-to-Insight-Center/patra-toolkit to commit ecddb90890a0eeb479fb9899ffd7c24a0c2fb734\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jsonschema>4.18.5 in /usr/local/lib/python3.12/dist-packages (from patra-toolkit==0.1.2) (4.25.1)\n",
            "Requirement already satisfied: fairlearn~=0.11.0 in /usr/local/lib/python3.12/dist-packages (from patra-toolkit==0.1.2) (0.11.0)\n",
            "Requirement already satisfied: shap~=0.46.0 in /usr/local/lib/python3.12/dist-packages (from patra-toolkit==0.1.2) (0.46.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from patra-toolkit==0.1.2) (2.2.2)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.12/dist-packages (from patra-toolkit==0.1.2) (1.26.4)\n",
            "Requirement already satisfied: requests>2.32.2 in /usr/local/lib/python3.12/dist-packages (from patra-toolkit==0.1.2) (2.32.4)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from fairlearn~=0.11.0->patra-toolkit==0.1.2) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.12/dist-packages (from fairlearn~=0.11.0->patra-toolkit==0.1.2) (1.16.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>4.18.5->patra-toolkit==0.1.2) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>4.18.5->patra-toolkit==0.1.2) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>4.18.5->patra-toolkit==0.1.2) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>4.18.5->patra-toolkit==0.1.2) (0.27.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->patra-toolkit==0.1.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->patra-toolkit==0.1.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->patra-toolkit==0.1.2) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>2.32.2->patra-toolkit==0.1.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>2.32.2->patra-toolkit==0.1.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>2.32.2->patra-toolkit==0.1.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>2.32.2->patra-toolkit==0.1.2) (2025.8.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap~=0.46.0->patra-toolkit==0.1.2) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap~=0.46.0->patra-toolkit==0.1.2) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap~=0.46.0->patra-toolkit==0.1.2) (0.0.8)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from shap~=0.46.0->patra-toolkit==0.1.2) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap~=0.46.0->patra-toolkit==0.1.2) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->patra-toolkit==0.1.2) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing>=0.28.4->jsonschema>4.18.5->patra-toolkit==0.1.2) (4.15.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2.1->fairlearn~=0.11.0->patra-toolkit==0.1.2) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2.1->fairlearn~=0.11.0->patra-toolkit==0.1.2) (3.6.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->shap~=0.46.0->patra-toolkit==0.1.2) (0.43.0)\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3hH-s-1WueZ",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:43.371705Z",
          "start_time": "2025-06-07T19:04:42.777702Z"
        },
        "outputId": "3d8265e6-9bf6-47eb-a4c9-8b6f9a41c052",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install numpy pandas tensorflow scikit-learn"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DKW3R7Pt26N",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:43.396762Z",
          "start_time": "2025-06-07T19:04:43.393071Z"
        }
      },
      "source": [
        "import logging\n",
        "\n",
        "# logging.basicConfig(level=logging.INFO)\n",
        "logging.getLogger(\"absl\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"PyGithub\").setLevel(logging.ERROR)\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from patra_toolkit import ModelCard, AIModel"
      ],
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv1JQLnet26N"
      },
      "source": [
        "## 2. Load and Pre-process the Data\n",
        "\n",
        "We'll use the **UCI Adult Dataset**, which predicts whether an individual's income is above or below $50K based on demographics. This dataset is a common benchmark for exploring model fairness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shP7K7tst26N",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:43.515235Z",
          "start_time": "2025-06-07T19:04:43.426462Z"
        },
        "outputId": "9e23a015-86f6-46f3-e455-c8bd88b7a17e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "df = pd.read_csv(\"data/adult/adult.data\", names=[\n",
        "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
        "    \"marital_status\", \"occupation\", \"relationship\", \"race\",\n",
        "    \"sex\", \"capital_gain\", \"capital_loss\", \"hours_per_week\",\n",
        "    \"native_country\", \"income\"\n",
        "], header=None)\n",
        "\n",
        "# Encode target\n",
        "df[\"income\"] = LabelEncoder().fit_transform(df[\"income\"])  # 1 if >50K, else 0\n",
        "\n",
        "# One-hot encode everything except the target\n",
        "df = pd.get_dummies(df, drop_first=True, dtype=float)\n",
        "\n",
        "# Split into features/labels\n",
        "X = df.drop(\"income\", axis=1).astype(\"float32\").values\n",
        "y = df[\"income\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/adult/adult.data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1808548672.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df = pd.read_csv(\"data/adult/adult.data\", names=[\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"age\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"workclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fnlwgt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"education\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"education_num\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"marital_status\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"occupation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"relationship\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"race\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"sex\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"capital_gain\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"capital_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hours_per_week\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"native_country\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"income\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/adult/adult.data'"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2KTI91Ct26O"
      },
      "source": [
        "## 3. Train a Simple TensorFlow Model\n",
        "\n",
        "Below is a straightforward neural network: two hidden layers plus a final sigmoid for binary classification. We'll train for a few epochs to demonstrate end-to-end usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qXO-rRGt26O",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:45.096018Z",
          "start_time": "2025-06-07T19:04:43.522750Z"
        },
        "outputId": "5387e80e-a750-47a0-a0df-84ed3aae64df"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=1)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503us/step - accuracy: 0.6744 - loss: 486.2711\n",
            "Epoch 2/5\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.6826 - loss: 178.2516\n",
            "Epoch 3/5\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.6781 - loss: 124.6441\n",
            "Epoch 4/5\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.6718 - loss: 165.5854\n",
            "Epoch 5/5\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.6766 - loss: 162.6309\n",
            "Test Loss: 91.7749, Test Accuracy: 0.7846\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XUvWIIkt26O"
      },
      "source": [
        "## 4. Building a Patra Model Card\n",
        "\n",
        "### 4.1 Basic Model Card Setup\n",
        "We start with essential metadata like name, version, short description, and so on.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkhDTjzit26P",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:45.117785Z",
          "start_time": "2025-06-07T19:04:45.115132Z"
        }
      },
      "source": [
        "mc = ModelCard(\n",
        "    name=\"UCI_Adult_Model\",\n",
        "    version=\"1.0\",\n",
        "    short_description=\"Predicting whether an individual's income is above $50K using TensorFlow.\",\n",
        "    full_description=(\n",
        "        \"This is a feed-forward neural network trained on the UCI Adult Dataset. \"\n",
        "        \"It demonstrates how Patra Toolkit can store model details, fairness scans, \"\n",
        "        \"and basic explainability data in a comprehensive Model Card.\"\n",
        "    ),\n",
        "    keywords=\"uci, adult, patra, fairness, xai, tensorflow\",\n",
        "    author=\"0009-0009-9817-7042\",\n",
        "    input_type=\"Tabular\",\n",
        "    category=\"classification\",\n",
        "    citation=\"Becker, B. & Kohavi, R. (1996). Adult [Dataset]. UCI.\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8gikzSdt26P"
      },
      "source": [
        "### 4.2 Attach AI Model Information\n",
        "Here we describe the model's ownership, license, performance metrics, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u_K5vhjt26P",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:45.141628Z",
          "start_time": "2025-06-07T19:04:45.137390Z"
        }
      },
      "source": [
        "ai_model = AIModel(\n",
        "    name=\"AdultTFModel\",\n",
        "    version=\"1.0\",\n",
        "    description=\"DNN on UCI Adult dataset for income prediction\",\n",
        "    owner=\"0009-0009-9817-7042\",\n",
        "    location=\"\",\n",
        "    license=\"BSD-3-Clause\",\n",
        "    framework=\"tensorflow\",\n",
        "    model_type=\"dnn\",\n",
        "    test_accuracy=accuracy\n",
        ")\n",
        "\n",
        "# Add additional performance or training metrics\n",
        "ai_model.add_metric(\"Epochs\", 5)\n",
        "ai_model.add_metric(\"BatchSize\", 64)\n",
        "ai_model.add_metric(\"Optimizer\", \"Adam\")\n",
        "\n",
        "mc.ai_model = ai_model"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BAHFlzNt26P"
      },
      "source": [
        "## 5. Fairness & Explainability\n",
        "\n",
        "### 5.1 Bias (Fairness) Analysis\n",
        "Patra Toolkit has a built-in `populate_bias` method to measure metrics like **demographic parity** or **equalized odds**. We'll focus on the protected attribute \"sex\" in the data.\n",
        "\n",
        "**Why check bias?** Real-world models often inadvertently penalize certain groups. By calling `mc.populate_bias(...)`, you get a quick sense of whether the model is systematically advantaging or disadvantaging certain subpopulations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viTyQc0lt26P",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:46.224155Z",
          "start_time": "2025-06-07T19:04:46.039587Z"
        },
        "outputId": "4b3d156b-207d-4559-e10a-8ef030c82837"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred >= 0.5).flatten()\n",
        "\n",
        "mc.populate_bias(\n",
        "    X_test,\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    \"gender\",\n",
        "    X_test[:, 58],\n",
        "    model\n",
        ")\n",
        "\n",
        "print(\"Bias Analysis:\\n\", mc.bias_analysis)\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step\n",
            "Bias Analysis:\n",
            " {'demographic_parity_diff': 0.027755077271190153, 'equal_odds_difference': 0.01045054754710445}\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyNKlxwtt26P"
      },
      "source": [
        "### 5.2 Explainability (XAI)\n",
        "\n",
        "If we want to understand model decisions, we can generate interpretability metrics (like feature importance) using Patra’s internal SHAP-based approach."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jF9c6OBt26P",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:46.778306Z",
          "start_time": "2025-06-07T19:04:46.639099Z"
        },
        "outputId": "a3ad799e-2a8b-49d2-c3d7-a17e343fa7e0"
      },
      "source": [
        "# Rebuild the list of columns used in training\n",
        "x_columns = df.columns.tolist()\n",
        "x_columns.remove('income')\n",
        "\n",
        "mc.populate_xai(\n",
        "    X_test[:10],\n",
        "    x_columns,\n",
        "    model\n",
        ")\n",
        "\n",
        "print(\"Explainability Analysis:\\n\", mc.xai_analysis)"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Explainability Analysis:\n",
            " {'capital_gain': 0.16949643871376632, 'fnlwgt': 0.020965424022244834, 'relationship__Wife': 0.0004385939623132787, 'hours_per_week': 0.0004380628896687581, 'marital_status__Married_civ_spouse': 0.00032194736676886924, 'relationship__Not_in_family': 0.00029494278761253446, 'age': 0.00024148987977653082, 'occupation__Exec_managerial': 0.00022575377802829818, 'education__HS_grad': 0.00020299190165049078, 'education__Some_college': 0.00019940693248733584}\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUlIE1a0t26Q"
      },
      "source": [
        "## 6. Add Requirements\n",
        "We let Patra auto-detect Python package dependencies to ensure reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHXlakOCt26Q",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:47.186646Z",
          "start_time": "2025-06-07T19:04:47.182840Z"
        }
      },
      "source": [
        "mc.populate_requirements()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpvGY-1zt26Q"
      },
      "source": [
        "## 7. Submission\n",
        "\n",
        "**[Optional] Tapis Authentication:**  \n",
        "Before submitting, ensure you have obtained a valid Tapis token using your TACC credentials. If you do not already have a TACC account, you can create one at [https://accounts.tacc.utexas.edu/begin](https://accounts.tacc.utexas.edu/begin). You can use the `authenticate()` method provided by the toolkit (or any other method) to obtain the token. When calling the submission methods, pass the token as the `tapis_token` parameter so that your request is authenticated by the Patra server. If Tapis authentication isn’t required for your scenario, you can set `tapis_token` to `None`.\n",
        "\n",
        "The `mc.submit(...)` method can do one or more of the following:\n",
        "1. **Submit only the card** (no model, no artifacts).\n",
        "2. **Include the trained model** (uploading to Hugging Face or GitHub).\n",
        "3. **Add artifacts** (such as data files, inference labels, or any additional resources).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlbDtsu_12A4",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:49.819997Z",
          "start_time": "2025-06-07T19:04:47.912852Z"
        },
        "outputId": "bfdcdb38-6643-4815-d6c4-ad1e7e695560"
      },
      "source": [
        "tapis_token = mc.authenticate(username=\"neelk\", password=\"****\")"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authentication successful.\n",
            "X-Tapis-Token: eyJhbGciOiJSUzI1NiIsImtpZCI6IlBiZU5IU3lJVGtZRHctOWtnbjRZU21VSnk2ZVRYZTNEYWFMRDNBZnl0SDQiLCJ0eXAiOiJKV1QifQ.eyJqdGkiOiJjMmY0NTkzZC03NGY5LTRiZWItYjc2Ny0xNTMzMGY0ZGIxODgiLCJpc3MiOiJodHRwczovL2ljaWNsZWFpLnRhcGlzLmlvL3YzL3Rva2VucyIsInN1YiI6Im5lZWxrQGljaWNsZWFpIiwidGFwaXMvdGVuYW50X2lkIjoiaWNpY2xlYWkiLCJ0YXBpcy90b2tlbl90eXBlIjoiYWNjZXNzIiwidGFwaXMvZGVsZWdhdGlvbiI6ZmFsc2UsInRhcGlzL2RlbGVnYXRpb25fc3ViIjpudWxsLCJ0YXBpcy91c2VybmFtZSI6Im5lZWxrIiwidGFwaXMvYWNjb3VudF90eXBlIjoidXNlciIsImV4cCI6MTc0OTMzNzQ4OSwidGFwaXMvY2xpZW50X2lkIjpudWxsLCJ0YXBpcy9ncmFudF90eXBlIjoicGFzc3dvcmQifQ.q21bM-0g92AT81AD2y64rTdgtcKJenWuncTI89L2uJI8Qefqichi1FRh53YlIkOXLGWjmmvsFMycwLAQ9gL7Uah735NYG-2UmOdMqfcqYRR9JlEg_B-YY2bQ9knPKm-nM2n7OvmawnC2v-VsUvQLgOKYOsT9tUYV6IU4kazITA41SLGAoT51nDK9rhvbOgwuqdne_kSKHjGHXzQLthd7s0VMO-pLbf9wpcS1sTMB8HLe4Dci2SRkgv-3tXYc1oHRwoJLhcvNEj733qtYSVCZmyFCXjHYPwg9UEUExzmJyu4u3rmquUXV6Y_gQMREpJTFUhZsvQF0G-jXk8yi_AI82g\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4qTtbMvt26Q"
      },
      "source": [
        "### 7.1 Submit Model Card\n",
        "\n",
        "If you don't have a tapis_token, set the parameter to `None`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH1WeTSzt26Q",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:51.426636Z",
          "start_time": "2025-06-07T19:04:49.918512Z"
        },
        "outputId": "f77e1e6b-8623-422b-a899-7bda6ab5da0c"
      },
      "source": [
        "patra_server_url = \"http://127.0.0.1:5002\"\n",
        "mc.submit(patra_server_url=patra_server_url) # , token=tapis_token)"
      ],
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Model card validation successful.\n",
            "INFO:root:PID created: 0009-0009-9817-7042-uci_adult_model-1.0\n",
            "INFO:root:Model Card submitted successfully.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'success'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puIdk-Lgt26Q"
      },
      "source": [
        "### 7.2 Submit AI/ML Model\n",
        "\n",
        "We can specify `\"huggingface\"` or `\"github\"` for `model_store`. This will attempt to upload our trained model, while the card is posted to the Patra server."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUK8H1a8t26Q",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:05:48.936239Z",
          "start_time": "2025-06-07T19:05:45.903386Z"
        },
        "outputId": "8a501e45-e3d4-4d3c-b7d0-4b4dc6eef983"
      },
      "source": [
        "mc.version= \"1.1\"\n",
        "mc.submit(patra_server_url=patra_server_url, model=model, file_format=\"h5\", model_store=\"huggingface\") # token=tapis_token,"
      ],
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Model card validation successful.\n",
            "INFO:root:PID created: 0009-0009-9817-7042-uci_adult_model-1.1\n",
            "INFO:root:Model serialized successfully.\n",
            "0009-0009-9817-7042-uci_adult_model-1.1.h5: 100%|██████████| 130k/130k [00:00<00:00, 570kB/s]\n",
            "INFO:root:Model uploaded at: https://huggingface.co/patra-iu/0009-0009-9817-7042-uci_adult_model-1.1/blob/main/0009-0009-9817-7042-uci_adult_model-1.1.h5\n",
            "INFO:root:Model Card submitted successfully.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'success'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nRhesNqt26Q"
      },
      "source": [
        "### 7.3 Submit Artifacts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZxUbbbGt26Q",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:06:22.513276Z",
          "start_time": "2025-06-07T19:06:20.850124Z"
        },
        "outputId": "ac443fb2-eae9-40e5-9277-d5155907ef70"
      },
      "source": [
        "mc.submit(patra_server_url=patra_server_url,\n",
        "          # token=tapis_token,\n",
        "          model_store=\"huggingface\",\n",
        "          artifacts=[\"data/adult/adult.data\", \"data/adult/adult.names\"])"
      ],
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Model card validation successful.\n",
            "WARNING:root:Model ID exists, but no model is being uploaded; continuing with existing ID.\n",
            "INFO:root:PID created: 0009-0009-9817-7042-uci_adult_model-1.1\n",
            "INFO:root:Artifact 'data/adult/adult.data' uploaded at: https://huggingface.co/patra-iu/0009-0009-9817-7042-uci_adult_model-1.1/blob/main/adult.data\n",
            "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/0009-0009-9817-7042-uci_adult_model-1.1/blob/main/adult.names\n",
            "INFO:root:Model Card submitted successfully.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'success'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM94gyaUt26Q"
      },
      "source": [
        "### 7.4 Submit Model Card, Model, and Artifacts\n",
        "\n",
        "This scenario might include a special label file plus multiple dataset artifacts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT1wByiet26Q",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:07:10.547630Z",
          "start_time": "2025-06-07T19:07:07.732271Z"
        },
        "outputId": "27bc4615-78f4-43cd-d502-6f647e0fc347"
      },
      "source": [
        "mc.version = \"1.2\"\n",
        "with open(\"labels.txt\", \"w\") as f:\n",
        "    f.write(\"Label 1\\n\")\n",
        "    f.write(\"Label 2\\n\")\n",
        "\n",
        "mc.submit(patra_server_url=patra_server_url, model=model, file_format=\"h5\", model_store=\"huggingface\",\n",
        "          inference_labels=\"labels.txt\", artifacts=[\"data/adult/adult.data\", \"data/adult/adult.names\"]) # token=tapis_token,"
      ],
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Model card validation successful.\n",
            "INFO:root:PID created: 0009-0009-9817-7042-uci_adult_model-1.2\n",
            "INFO:root:Model serialized successfully.\n",
            "0009-0009-9817-7042-uci_adult_model-1.2.h5: 100%|██████████| 130k/130k [00:00<00:00, 805kB/s]\n",
            "INFO:root:Model uploaded at: https://huggingface.co/patra-iu/0009-0009-9817-7042-uci_adult_model-1.2/blob/main/0009-0009-9817-7042-uci_adult_model-1.2.h5\n",
            "INFO:root:Inference labels uploaded at: https://huggingface.co/patra-iu/0009-0009-9817-7042-uci_adult_model-1.2/blob/main/labels.txt\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "INFO:root:Artifact 'data/adult/adult.data' uploaded at: https://huggingface.co/patra-iu/0009-0009-9817-7042-uci_adult_model-1.2/blob/main/adult.data\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/0009-0009-9817-7042-uci_adult_model-1.2/blob/main/adult.names\n",
            "INFO:root:Model Card submitted successfully.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'success'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkNMFKNZt26Q"
      },
      "source": [
        "### 7.4 Pushing to GitHub\n",
        "\n",
        "By switching `\"huggingface\"` to `\"github\"`, you can store your model in a GitHub repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvLQife_t26Q",
        "ExecuteTime": {
          "end_time": "2025-06-07T18:32:35.721824Z",
          "start_time": "2025-06-07T18:32:35.700090Z"
        },
        "outputId": "acb05426-7556-4d84-f29a-b242c777900f"
      },
      "source": [
        "mc.version = \"1.3\"\n",
        "mc.submit(patra_server_url=patra_server_url, model=model, file_format=\"h5\", model_store=\"github\",\n",
        "          artifacts=[\"adult.data\", \"adult.names\"])"
      ],
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Model card validation successful.\n",
            "INFO:root:PID created: 0009-0009-9817-7042-uci_adult_model-1.3\n",
            "ERROR:root:Model submission failed during credential retrieval: 400 Client Error: BAD REQUEST for url: http://127.0.0.1:5002/get_github_credentials\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBv0f39St26Q"
      },
      "source": [
        "By following this notebook, you have:\n",
        "1. Loaded and preprocessed the UCI Adult Dataset\n",
        "2. Trained a TensorFlow model to predict income\n",
        "3. Built a Patra Model Card describing the model’s purpose, performance, and environment\n",
        "4. Scanned for fairness and explainability metrics\n",
        "5. Submitted the card to a Patra server along with the model or artifacts to a chosen store (Hugging Face or GitHub)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j3yUdtQ12A5",
        "ExecuteTime": {
          "end_time": "2025-06-07T18:32:35.740743Z",
          "start_time": "2025-06-07T18:32:35.737160Z"
        },
        "outputId": "07a931cb-d2cc-4e86-8daf-fb4f6458887c"
      },
      "source": [
        "mc.save(\"model_card.json\")"
      ],
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Model card saved to model_card.json.\n"
          ]
        }
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}