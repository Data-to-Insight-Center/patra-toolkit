{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTDtPAC3t26L"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "# Getting Started with Patra Model Card Toolkit\n",
        "\n",
        "</div>\n",
        "\n",
        "The Patra Toolkit is a component of the Patra ModelCards framework designed to simplify the process of creating and documenting AI/ML models. It provides a structured schema that guides users in providing essential information about their models, including details about the model's purpose, development process, and performance. The toolkit also includes features for semi-automating the capture of key information, such as fairness and explainability metrics, through integrated analysis tools. By reducing the manual effort involved in creating model cards, the Patra Toolkit encourages researchers and developers to adopt best practices for documenting their models, ultimately contributing to greater transparency and accountability in AI/ML development.\n",
        "\n",
        "The Patra Toolkit embeds transparency and governance directly into the training workflow. Integrated scanners collect essential metadata—data sources, fairness metrics, and explainability insights—during model training and then generate a machine‑actionable JSON model card. These cards plug into the Patra Knowledge Base for rich queries on provenance, version history, and auditing. Flexible back‑ends publish models and artifacts to repositories such as Hugging Face or GitHub, automatically recording lineage links to trace every model’s evolution.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "This notebook demonstrates:\n",
        "\n",
        "1. **Loading & Preprocessing** the UCI Adult Dataset  \n",
        "2. **Training** a simple TensorFlow model  \n",
        "3. **Creating a Model Card** with optional Fairness and XAI scans  \n",
        "4. **Submitting** the Model Card (and optionally the model, inference label, and artifacts) to:\n",
        "   - **Patra server** (for model card storage)  \n",
        "   - **Backend** (Hugging Face or GitHub) for model storage\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF4REySnt26M",
        "scrolled": true,
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:42.753151Z",
          "start_time": "2025-06-07T19:04:40.865368Z"
        }
      },
      "source": [
        "!pip install patra-toolkit"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3hH-s-1WueZ",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:43.371705Z",
          "start_time": "2025-06-07T19:04:42.777702Z"
        }
      },
      "source": [
        "!pip install numpy pandas tensorflow scikit-learn"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DKW3R7Pt26N",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:43.396762Z",
          "start_time": "2025-06-07T19:04:43.393071Z"
        }
      },
      "source": [
        "import logging\n",
        "\n",
        "# logging.basicConfig(level=logging.INFO)\n",
        "logging.getLogger(\"absl\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"PyGithub\").setLevel(logging.ERROR)\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from patra_toolkit import ModelCard, AIModel"
      ],
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv1JQLnet26N"
      },
      "source": [
        "## 2. Load and Pre-process the Data\n",
        "\n",
        "We'll use the **UCI Adult Dataset**, which predicts whether an individual's income is above or below $50K based on demographics. This dataset is a common benchmark for exploring model fairness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shP7K7tst26N",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:43.515235Z",
          "start_time": "2025-06-07T19:04:43.426462Z"
        },
        "outputId": "523d4cd1-591d-4390-9f35-e485e430a3f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Download UCI Adult dataset\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Download the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "\n",
        "df = pd.read_csv(url, names=[\n",
        "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
        "    \"marital_status\", \"occupation\", \"relationship\", \"race\",\n",
        "    \"sex\", \"capital_gain\", \"capital_loss\", \"hours_per_week\",\n",
        "    \"native_country\", \"income\"\n",
        "], header=None)\n",
        "\n",
        "# Encode target\n",
        "df[\"income\"] = LabelEncoder().fit_transform(df[\"income\"])  # 1 if >50K, else 0\n",
        "\n",
        "# One-hot encode everything except the target\n",
        "df = pd.get_dummies(df, drop_first=True, dtype=float)\n",
        "\n",
        "# Split into features/labels\n",
        "X = df.drop(\"income\", axis=1).astype(\"float32\").values\n",
        "y = df[\"income\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (26048, 100) Test shape: (6513, 100)\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2KTI91Ct26O"
      },
      "source": [
        "## 3. Train a Simple TensorFlow Model\n",
        "\n",
        "Below is a straightforward neural network: two hidden layers plus a final sigmoid for binary classification. We'll train for a few epochs to demonstrate end-to-end usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qXO-rRGt26O",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:45.096018Z",
          "start_time": "2025-06-07T19:04:43.522750Z"
        },
        "outputId": "e8238eae-9be3-415c-e7ff-7da05f1707e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=1)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6701 - loss: 246.6357\n",
            "Epoch 2/5\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6842 - loss: 124.0436\n",
            "Epoch 3/5\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6769 - loss: 99.2685\n",
            "Epoch 4/5\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6950 - loss: 76.7355\n",
            "Epoch 5/5\n",
            "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6728 - loss: 71.4908\n",
            "Test Loss: 28.8533, Test Accuracy: 0.7938\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XUvWIIkt26O"
      },
      "source": [
        "## 4. Building a Patra Model Card\n",
        "\n",
        "### 4.1 Basic Model Card Setup\n",
        "We start with essential metadata like name, version, short description, and so on.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkhDTjzit26P",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:45.117785Z",
          "start_time": "2025-06-07T19:04:45.115132Z"
        }
      },
      "source": [
        "mc = ModelCard(\n",
        "    name=\"UCI_Adult_Model\",\n",
        "    version=\"1.0\",\n",
        "    short_description=\"Predicting whether an individual's income is above $50K using TensorFlow.\",\n",
        "    full_description=(\n",
        "        \"This is a feed-forward neural network trained on the UCI Adult Dataset. \"\n",
        "        \"It demonstrates how Patra Toolkit can store model details, fairness scans, \"\n",
        "        \"and basic explainability data in a comprehensive Model Card.\"\n",
        "    ),\n",
        "    keywords=\"uci, adult, patra, fairness, xai, tensorflow\",\n",
        "    author=\"0009-0009-9817-7042\",\n",
        "    input_type=\"Tabular\",\n",
        "    category=\"classification\",\n",
        "    citation=\"Becker, B. & Kohavi, R. (1996). Adult [Dataset]. UCI.\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8gikzSdt26P"
      },
      "source": [
        "### 4.2 Attach AI Model Information\n",
        "Here we describe the model's ownership, license, performance metrics, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u_K5vhjt26P",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:45.141628Z",
          "start_time": "2025-06-07T19:04:45.137390Z"
        }
      },
      "source": [
        "ai_model = AIModel(\n",
        "    name=\"AdultTFModel\",\n",
        "    version=\"1.0\",\n",
        "    description=\"DNN on UCI Adult dataset for income prediction\",\n",
        "    owner=\"0009-0009-9817-7042\",\n",
        "    location=\"\",\n",
        "    license=\"BSD-3-Clause\",\n",
        "    framework=\"tensorflow\",\n",
        "    model_type=\"dnn\",\n",
        "    test_accuracy=accuracy\n",
        ")\n",
        "\n",
        "# Add additional performance or training metrics\n",
        "ai_model.add_metric(\"Epochs\", 5)\n",
        "ai_model.add_metric(\"BatchSize\", 64)\n",
        "ai_model.add_metric(\"Optimizer\", \"Adam\")\n",
        "\n",
        "mc.ai_model = ai_model"
      ],
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BAHFlzNt26P"
      },
      "source": [
        "## 5. Fairness & Explainability\n",
        "\n",
        "### 5.1 Bias (Fairness) Analysis\n",
        "Patra Toolkit has a built-in `populate_bias` method to measure metrics like **demographic parity** or **equalized odds**. We'll focus on the protected attribute \"sex\" in the data.\n",
        "\n",
        "**Why check bias?** Real-world models often inadvertently penalize certain groups. By calling `mc.populate_bias(...)`, you get a quick sense of whether the model is systematically advantaging or disadvantaging certain subpopulations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install patra-toolkit[fairness]"
      ],
      "metadata": {
        "id": "1Y_Bz7z1CyLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viTyQc0lt26P",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:46.224155Z",
          "start_time": "2025-06-07T19:04:46.039587Z"
        },
        "outputId": "17dc2d2d-548b-49f6-a240-20264e28b33d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred >= 0.5).flatten()\n",
        "\n",
        "mc.populate_bias(X_test, y_test, y_pred, \"gender\", X_test[:, 58], model)\n",
        "\n",
        "print(\"Bias Analysis:\\n\", mc.bias_analysis)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Bias Analysis:\n",
            " {'demographic_parity_diff': 0.06947995456515349, 'equal_odds_difference': 0.05451092848848774}\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyNKlxwtt26P"
      },
      "source": [
        "### 5.2 Explainability (XAI)\n",
        "\n",
        "If we want to understand model decisions, we can generate interpretability metrics (like feature importance) using Patra’s internal SHAP-based approach."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jF9c6OBt26P",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:46.778306Z",
          "start_time": "2025-06-07T19:04:46.639099Z"
        },
        "outputId": "30cb92a4-5bb2-4875-e98b-58c488586c51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Rebuild the list of columns used in training\n",
        "x_columns = df.columns.tolist()\n",
        "x_columns.remove('income')\n",
        "\n",
        "mc.populate_xai(\n",
        "    X_test[:10],\n",
        "    x_columns,\n",
        "    model\n",
        ")\n",
        "\n",
        "print(\"Explainability Analysis:\\n\", mc.xai_analysis)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explainability Analysis:\n",
            " {'capital_gain': 0.31000005628282834, 'fnlwgt': 0.06999979992822919, 'age': 1.705593005436899e-07, 'relationship__Not_in_family': 5.965964893200187e-08, 'hours_per_week': 5.797235556609132e-08, 'education__Some_college': 4.142203483086612e-08, 'education__Bachelors': 3.9261994221532834e-08, 'occupation__Craft_repair': 3.35786523575418e-08, 'marital_status__Married_civ_spouse': 3.317405762907801e-08, 'occupation__Adm_clerical': 3.209302177860775e-08}\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUlIE1a0t26Q"
      },
      "source": [
        "## 6. Add Requirements\n",
        "We let Patra auto-detect Python package dependencies to ensure reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHXlakOCt26Q",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:47.186646Z",
          "start_time": "2025-06-07T19:04:47.182840Z"
        }
      },
      "source": [
        "mc.populate_requirements()"
      ],
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpvGY-1zt26Q"
      },
      "source": [
        "## 7. Submission\n",
        "\n",
        "**[Optional] Tapis Authentication:**  \n",
        "Before submitting, ensure you have obtained a valid Tapis token using your TACC credentials. If you do not already have a TACC account, you can create one at [https://accounts.tacc.utexas.edu/begin](https://accounts.tacc.utexas.edu/begin). You can use the `authenticate()` method provided by the toolkit (or any other method) to obtain the token. When calling the submission methods, pass the token as the `tapis_token` parameter so that your request is authenticated by the Patra server. If Tapis authentication isn’t required for your scenario, you can set `tapis_token` to `None`.\n",
        "\n",
        "The `mc.submit(...)` method can do one or more of the following:\n",
        "1. **Submit only the card** (no model, no artifacts).\n",
        "2. **Include the trained model** (uploading to Hugging Face or GitHub).\n",
        "3. **Add artifacts** (such as data files, inference labels, or any additional resources).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlbDtsu_12A4",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:49.819997Z",
          "start_time": "2025-06-07T19:04:47.912852Z"
        },
        "outputId": "bfdcdb38-6643-4815-d6c4-ad1e7e695560"
      },
      "source": [
        "tapis_token = mc.authenticate(username=\"neelk\", password=\"****\")"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authentication successful.\n",
            "X-Tapis-Token: eyJhbGciOiJSUzI1NiIsImtpZCI6IlBiZU5IU3lJVGtZRHctOWtnbjRZU21VSnk2ZVRYZTNEYWFMRDNBZnl0SDQiLCJ0eXAiOiJKV1QifQ.eyJqdGkiOiJjMmY0NTkzZC03NGY5LTRiZWItYjc2Ny0xNTMzMGY0ZGIxODgiLCJpc3MiOiJodHRwczovL2ljaWNsZWFpLnRhcGlzLmlvL3YzL3Rva2VucyIsInN1YiI6Im5lZWxrQGljaWNsZWFpIiwidGFwaXMvdGVuYW50X2lkIjoiaWNpY2xlYWkiLCJ0YXBpcy90b2tlbl90eXBlIjoiYWNjZXNzIiwidGFwaXMvZGVsZWdhdGlvbiI6ZmFsc2UsInRhcGlzL2RlbGVnYXRpb25fc3ViIjpudWxsLCJ0YXBpcy91c2VybmFtZSI6Im5lZWxrIiwidGFwaXMvYWNjb3VudF90eXBlIjoidXNlciIsImV4cCI6MTc0OTMzNzQ4OSwidGFwaXMvY2xpZW50X2lkIjpudWxsLCJ0YXBpcy9ncmFudF90eXBlIjoicGFzc3dvcmQifQ.q21bM-0g92AT81AD2y64rTdgtcKJenWuncTI89L2uJI8Qefqichi1FRh53YlIkOXLGWjmmvsFMycwLAQ9gL7Uah735NYG-2UmOdMqfcqYRR9JlEg_B-YY2bQ9knPKm-nM2n7OvmawnC2v-VsUvQLgOKYOsT9tUYV6IU4kazITA41SLGAoT51nDK9rhvbOgwuqdne_kSKHjGHXzQLthd7s0VMO-pLbf9wpcS1sTMB8HLe4Dci2SRkgv-3tXYc1oHRwoJLhcvNEj733qtYSVCZmyFCXjHYPwg9UEUExzmJyu4u3rmquUXV6Y_gQMREpJTFUhZsvQF0G-jXk8yi_AI82g\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4qTtbMvt26Q"
      },
      "source": [
        "### 7.1 Submit Model Card\n",
        "\n",
        "If you don't have a tapis_token, set the parameter to `None`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH1WeTSzt26Q",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:04:51.426636Z",
          "start_time": "2025-06-07T19:04:49.918512Z"
        },
        "outputId": "f77e1e6b-8623-422b-a899-7bda6ab5da0c"
      },
      "source": [
        "patra_server_url = \"http://127.0.0.1:5002\"\n",
        "mc.submit(patra_server_url=patra_server_url) # , token=tapis_token)"
      ],
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Model card validation successful.\n",
            "INFO:root:PID created: 0009-0009-9817-7042-uci_adult_model-1.0\n",
            "INFO:root:Model Card submitted successfully.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'success'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puIdk-Lgt26Q"
      },
      "source": [
        "### 7.2 Submit AI/ML Model\n",
        "\n",
        "We can specify `\"huggingface\"` or `\"github\"` for `model_store`. This will attempt to upload our trained model, while the card is posted to the Patra server."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUK8H1a8t26Q",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:05:48.936239Z",
          "start_time": "2025-06-07T19:05:45.903386Z"
        },
        "outputId": "8a501e45-e3d4-4d3c-b7d0-4b4dc6eef983"
      },
      "source": [
        "mc.version= \"1.1\"\n",
        "mc.submit(patra_server_url=patra_server_url, model=model, file_format=\"h5\", model_store=\"huggingface\") # token=tapis_token,"
      ],
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Model card validation successful.\n",
            "INFO:root:PID created: 0009-0009-9817-7042-uci_adult_model-1.1\n",
            "INFO:root:Model serialized successfully.\n",
            "0009-0009-9817-7042-uci_adult_model-1.1.h5: 100%|██████████| 130k/130k [00:00<00:00, 570kB/s]\n",
            "INFO:root:Model uploaded at: https://huggingface.co/patra-iu/0009-0009-9817-7042-uci_adult_model-1.1/blob/main/0009-0009-9817-7042-uci_adult_model-1.1.h5\n",
            "INFO:root:Model Card submitted successfully.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'success'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nRhesNqt26Q"
      },
      "source": [
        "### 7.3 Submit Artifacts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZxUbbbGt26Q",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:06:22.513276Z",
          "start_time": "2025-06-07T19:06:20.850124Z"
        },
        "outputId": "ac443fb2-eae9-40e5-9277-d5155907ef70"
      },
      "source": [
        "mc.submit(patra_server_url=patra_server_url,\n",
        "          # token=tapis_token,\n",
        "          model_store=\"huggingface\",\n",
        "          artifacts=[\"data/adult/adult.data\", \"data/adult/adult.names\"])"
      ],
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Model card validation successful.\n",
            "WARNING:root:Model ID exists, but no model is being uploaded; continuing with existing ID.\n",
            "INFO:root:PID created: 0009-0009-9817-7042-uci_adult_model-1.1\n",
            "INFO:root:Artifact 'data/adult/adult.data' uploaded at: https://huggingface.co/patra-iu/0009-0009-9817-7042-uci_adult_model-1.1/blob/main/adult.data\n",
            "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/0009-0009-9817-7042-uci_adult_model-1.1/blob/main/adult.names\n",
            "INFO:root:Model Card submitted successfully.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'success'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM94gyaUt26Q"
      },
      "source": [
        "### 7.4 Submit Model Card, Model, and Artifacts\n",
        "\n",
        "This scenario might include a special label file plus multiple dataset artifacts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT1wByiet26Q",
        "ExecuteTime": {
          "end_time": "2025-06-07T19:07:10.547630Z",
          "start_time": "2025-06-07T19:07:07.732271Z"
        },
        "outputId": "27bc4615-78f4-43cd-d502-6f647e0fc347"
      },
      "source": [
        "mc.version = \"1.2\"\n",
        "with open(\"labels.txt\", \"w\") as f:\n",
        "    f.write(\"Label 1\\n\")\n",
        "    f.write(\"Label 2\\n\")\n",
        "\n",
        "mc.submit(patra_server_url=patra_server_url, model=model, file_format=\"h5\", model_store=\"huggingface\",\n",
        "          inference_labels=\"labels.txt\", artifacts=[\"data/adult/adult.data\", \"data/adult/adult.names\"]) # token=tapis_token,"
      ],
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Model card validation successful.\n",
            "INFO:root:PID created: 0009-0009-9817-7042-uci_adult_model-1.2\n",
            "INFO:root:Model serialized successfully.\n",
            "0009-0009-9817-7042-uci_adult_model-1.2.h5: 100%|██████████| 130k/130k [00:00<00:00, 805kB/s]\n",
            "INFO:root:Model uploaded at: https://huggingface.co/patra-iu/0009-0009-9817-7042-uci_adult_model-1.2/blob/main/0009-0009-9817-7042-uci_adult_model-1.2.h5\n",
            "INFO:root:Inference labels uploaded at: https://huggingface.co/patra-iu/0009-0009-9817-7042-uci_adult_model-1.2/blob/main/labels.txt\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "INFO:root:Artifact 'data/adult/adult.data' uploaded at: https://huggingface.co/patra-iu/0009-0009-9817-7042-uci_adult_model-1.2/blob/main/adult.data\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/0009-0009-9817-7042-uci_adult_model-1.2/blob/main/adult.names\n",
            "INFO:root:Model Card submitted successfully.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'success'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkNMFKNZt26Q"
      },
      "source": [
        "### 7.4 Pushing to GitHub\n",
        "\n",
        "By switching `\"huggingface\"` to `\"github\"`, you can store your model in a GitHub repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvLQife_t26Q",
        "ExecuteTime": {
          "end_time": "2025-06-07T18:32:35.721824Z",
          "start_time": "2025-06-07T18:32:35.700090Z"
        },
        "outputId": "acb05426-7556-4d84-f29a-b242c777900f"
      },
      "source": [
        "mc.version = \"1.3\"\n",
        "mc.submit(patra_server_url=patra_server_url, model=model, file_format=\"h5\", model_store=\"github\",\n",
        "          artifacts=[\"adult.data\", \"adult.names\"])"
      ],
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Model card validation successful.\n",
            "INFO:root:PID created: 0009-0009-9817-7042-uci_adult_model-1.3\n",
            "ERROR:root:Model submission failed during credential retrieval: 400 Client Error: BAD REQUEST for url: http://127.0.0.1:5002/get_github_credentials\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBv0f39St26Q"
      },
      "source": [
        "By following this notebook, you have:\n",
        "1. Loaded and preprocessed the UCI Adult Dataset\n",
        "2. Trained a TensorFlow model to predict income\n",
        "3. Built a Patra Model Card describing the model’s purpose, performance, and environment\n",
        "4. Scanned for fairness and explainability metrics\n",
        "5. Submitted the card to a Patra server along with the model or artifacts to a chosen store (Hugging Face or GitHub)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j3yUdtQ12A5",
        "ExecuteTime": {
          "end_time": "2025-06-07T18:32:35.740743Z",
          "start_time": "2025-06-07T18:32:35.737160Z"
        },
        "outputId": "07a931cb-d2cc-4e86-8daf-fb4f6458887c"
      },
      "source": [
        "mc.save(\"model_card.json\")"
      ],
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Model card saved to model_card.json.\n"
          ]
        }
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}