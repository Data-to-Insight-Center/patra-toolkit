{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Getting Started with Patra Toolkit\n",
    "\n",
    "This notebook serves as a quickstart guide to help you learn how to:\n",
    "\n",
    "- Load and preprocess the UCI Adult Dataset  \n",
    "- Build and train a neural network in TensorFlow  \n",
    "- Generate a comprehensive Model Card using the **Patra Toolkit**  \n",
    "\n",
    "By the end of this tutorial, you’ll have a validated Model Card (in JSON format) that captures key information about your model, including fairness and explainability metrics.  \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Environment Setup\n",
    "\n",
    "### 1.1 Install Required Packages\n"
   ],
   "metadata": {
    "id": "hV88jvhGAzQr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install tensorflow scikit-learn pandas patra_toolkit"
   ],
   "metadata": {
    "collapsed": true,
    "id": "wCQu17lZA6Z7",
    "outputId": "ff46feeb-5bbe-41a8-d08e-510692a16892",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-03-19T15:53:31.328145Z",
     "start_time": "2025-03-19T15:53:28.973323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (2.18.0)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (1.5.2)\r\n",
      "Requirement already satisfied: pandas in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (2.2.3)\r\n",
      "Requirement already satisfied: patra_toolkit in /Users/neeleshkarthikeyan/d2i/patra-toolkit (0.1.2)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (2.1.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (25.2.10)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (18.1.1)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (24.2)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (5.29.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (75.4.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (1.17.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (2.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (1.17.2)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (1.70.0)\r\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (2.18.0)\r\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (3.9.0)\r\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (1.26.4)\r\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (3.13.0)\r\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (0.4.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (0.37.1)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from scikit-learn) (1.13.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from pandas) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from pandas) (2025.1)\r\n",
      "Requirement already satisfied: jsonschema>4.18.5 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (4.18.6)\r\n",
      "Requirement already satisfied: fairlearn~=0.11.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (0.11.0)\r\n",
      "Requirement already satisfied: shap~=0.46.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (0.46.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (23.1.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (2024.10.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (0.36.2)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (0.22.3)\r\n",
      "Requirement already satisfied: rich in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\r\n",
      "Requirement already satisfied: namex in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\r\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (4.67.1)\r\n",
      "Requirement already satisfied: slicer==0.0.8 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (0.0.8)\r\n",
      "Requirement already satisfied: numba in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (0.61.0)\r\n",
      "Requirement already satisfied: cloudpickle in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (3.1.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\r\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from numba->shap~=0.46.0->patra_toolkit) (0.44.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Import Dependencies"
   ],
   "metadata": {
    "id": "sFW_WWeOA9JD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from patra_toolkit import ModelCard, AIModel\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "keLCGTap47oM",
    "ExecuteTime": {
     "end_time": "2025-03-19T15:53:39.861879Z",
     "start_time": "2025-03-19T15:53:31.335376Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 2. Load and Inspect the Data\n",
    "\n",
    "We’ll use the **UCI Adult Dataset**, a commonly used dataset to predict whether a person's income exceeds a certain threshold based on demographic factors. Download the data from:\n",
    "[https://archive.ics.uci.edu/ml/datasets/adult](https://archive.ics.uci.edu/ml/datasets/adult).\n",
    "\n",
    "For convenience, we assume the file is saved locally at `data/adult/adult.data`.\n"
   ],
   "metadata": {
    "id": "EaPVq7YfBTyb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "cert_path = __import__(\"certifi\").where()\n",
    "data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "\n",
    "# Download the data with certificate verification\n",
    "response = requests.get(data_url, verify=cert_path)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Use io.StringIO to load the text content into pandas\n",
    "data = pd.read_csv(io.StringIO(response.text),\n",
    "                   names=[\n",
    "                       \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
    "                       \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
    "                       \"hours-per-week\", \"native-country\", \"income\"\n",
    "                   ],\n",
    "                   header=None)\n",
    "data.head()\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "eOj6rOP647oM",
    "outputId": "bad4414d-a9b6-4dbb-b05c-7346cf44e378",
    "ExecuteTime": {
     "end_time": "2025-03-19T15:53:40.726131Z",
     "start_time": "2025-03-19T15:53:39.924434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 3. Preprocessing\n",
    "\n",
    "### 3.1 Encode Target Variable\n",
    "We’ll encode the **income** column using `LabelEncoder`, transforming the categorical values (e.g., `>50K` and `<=50K`) into numerical labels."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "b4dLoECp47oN"
   }
  },
  {
   "metadata": {
    "id": "KLNNiXZu47oN",
    "ExecuteTime": {
     "end_time": "2025-03-19T15:53:40.968839Z",
     "start_time": "2025-03-19T15:53:40.959806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data['income'] = label_encoder.fit_transform(data['income'])"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 One-Hot Encode Categorical Features\n",
    "We’ll convert other categorical variables into **one-hot encoding**. We use the parameter `drop_first=True` to avoid dummy variable traps."
   ],
   "metadata": {
    "id": "Khw2nEREB0wg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data = pd.get_dummies(data, drop_first=True, dtype=float)\n",
    "data.head()"
   ],
   "metadata": {
    "id": "3weryO26B10b",
    "outputId": "d0a524e4-f890-49a5-8fd3-36c15715ba6f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "ExecuteTime": {
     "end_time": "2025-03-19T15:53:41.090464Z",
     "start_time": "2025-03-19T15:53:41.031838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   39   77516             13          2174             0              40   \n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "   income  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "0       0                     0.0                   0.0   \n",
       "1       0                     0.0                   0.0   \n",
       "2       0                     0.0                   0.0   \n",
       "3       0                     0.0                   0.0   \n",
       "4       0                     0.0                   0.0   \n",
       "\n",
       "   workclass_ Never-worked  ...  native-country_ Portugal  \\\n",
       "0                      0.0  ...                       0.0   \n",
       "1                      0.0  ...                       0.0   \n",
       "2                      0.0  ...                       0.0   \n",
       "3                      0.0  ...                       0.0   \n",
       "4                      0.0  ...                       0.0   \n",
       "\n",
       "   native-country_ Puerto-Rico  native-country_ Scotland  \\\n",
       "0                          0.0                       0.0   \n",
       "1                          0.0                       0.0   \n",
       "2                          0.0                       0.0   \n",
       "3                          0.0                       0.0   \n",
       "4                          0.0                       0.0   \n",
       "\n",
       "   native-country_ South  native-country_ Taiwan  native-country_ Thailand  \\\n",
       "0                    0.0                     0.0                       0.0   \n",
       "1                    0.0                     0.0                       0.0   \n",
       "2                    0.0                     0.0                       0.0   \n",
       "3                    0.0                     0.0                       0.0   \n",
       "4                    0.0                     0.0                       0.0   \n",
       "\n",
       "   native-country_ Trinadad&Tobago  native-country_ United-States  \\\n",
       "0                              0.0                            1.0   \n",
       "1                              0.0                            1.0   \n",
       "2                              0.0                            1.0   \n",
       "3                              0.0                            1.0   \n",
       "4                              0.0                            0.0   \n",
       "\n",
       "   native-country_ Vietnam  native-country_ Yugoslavia  \n",
       "0                      0.0                         0.0  \n",
       "1                      0.0                         0.0  \n",
       "2                      0.0                         0.0  \n",
       "3                      0.0                         0.0  \n",
       "4                      0.0                         0.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Never-worked</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Portugal</th>\n",
       "      <th>native-country_ Puerto-Rico</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Train-Test Split\n",
    "Next, we separate features (**X**) from the target (**y**) and then split into training and testing sets."
   ],
   "metadata": {
    "id": "gSV_GV5qB7KB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X = data.drop('income', axis=1).values\n",
    "y = data['income'].values\n",
    "\n",
    "print(\"List of columns after one-hot encoding:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlfBN79947oN",
    "outputId": "f609e433-41fd-442e-b35d-bdf9ef57f796",
    "ExecuteTime": {
     "end_time": "2025-03-19T15:53:41.323458Z",
     "start_time": "2025-03-19T15:53:41.216115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of columns after one-hot encoding:\n",
      "['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week', 'income', 'workclass_ Federal-gov', 'workclass_ Local-gov', 'workclass_ Never-worked', 'workclass_ Private', 'workclass_ Self-emp-inc', 'workclass_ Self-emp-not-inc', 'workclass_ State-gov', 'workclass_ Without-pay', 'education_ 11th', 'education_ 12th', 'education_ 1st-4th', 'education_ 5th-6th', 'education_ 7th-8th', 'education_ 9th', 'education_ Assoc-acdm', 'education_ Assoc-voc', 'education_ Bachelors', 'education_ Doctorate', 'education_ HS-grad', 'education_ Masters', 'education_ Preschool', 'education_ Prof-school', 'education_ Some-college', 'marital-status_ Married-AF-spouse', 'marital-status_ Married-civ-spouse', 'marital-status_ Married-spouse-absent', 'marital-status_ Never-married', 'marital-status_ Separated', 'marital-status_ Widowed', 'occupation_ Adm-clerical', 'occupation_ Armed-Forces', 'occupation_ Craft-repair', 'occupation_ Exec-managerial', 'occupation_ Farming-fishing', 'occupation_ Handlers-cleaners', 'occupation_ Machine-op-inspct', 'occupation_ Other-service', 'occupation_ Priv-house-serv', 'occupation_ Prof-specialty', 'occupation_ Protective-serv', 'occupation_ Sales', 'occupation_ Tech-support', 'occupation_ Transport-moving', 'relationship_ Not-in-family', 'relationship_ Other-relative', 'relationship_ Own-child', 'relationship_ Unmarried', 'relationship_ Wife', 'race_ Asian-Pac-Islander', 'race_ Black', 'race_ Other', 'race_ White', 'sex_ Male', 'native-country_ Cambodia', 'native-country_ Canada', 'native-country_ China', 'native-country_ Columbia', 'native-country_ Cuba', 'native-country_ Dominican-Republic', 'native-country_ Ecuador', 'native-country_ El-Salvador', 'native-country_ England', 'native-country_ France', 'native-country_ Germany', 'native-country_ Greece', 'native-country_ Guatemala', 'native-country_ Haiti', 'native-country_ Holand-Netherlands', 'native-country_ Honduras', 'native-country_ Hong', 'native-country_ Hungary', 'native-country_ India', 'native-country_ Iran', 'native-country_ Ireland', 'native-country_ Italy', 'native-country_ Jamaica', 'native-country_ Japan', 'native-country_ Laos', 'native-country_ Mexico', 'native-country_ Nicaragua', 'native-country_ Outlying-US(Guam-USVI-etc)', 'native-country_ Peru', 'native-country_ Philippines', 'native-country_ Poland', 'native-country_ Portugal', 'native-country_ Puerto-Rico', 'native-country_ Scotland', 'native-country_ South', 'native-country_ Taiwan', 'native-country_ Thailand', 'native-country_ Trinadad&Tobago', 'native-country_ United-States', 'native-country_ Vietnam', 'native-country_ Yugoslavia']\n",
      "Training set shape: (26048, 100)\n",
      "Testing set shape: (6513, 100)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 4. Model Training\n",
    "\n",
    "We define a simple feed-forward neural network in TensorFlow, compile it with an **Adam** optimizer, and fit it on our training set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "ptQzbe3U47oN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AnaVyRq_47oN",
    "outputId": "ea7d57d3-99dd-4c6a-f8a8-24769ca1474c",
    "ExecuteTime": {
     "end_time": "2025-03-19T15:53:59.154447Z",
     "start_time": "2025-03-19T15:53:41.471324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m733/733\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.6626 - loss: 406.3564 - val_accuracy: 0.7923 - val_loss: 13.8974\n",
      "Epoch 2/100\n",
      "\u001B[1m733/733\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.6857 - loss: 68.2941 - val_accuracy: 0.7958 - val_loss: 51.4647\n",
      "Epoch 3/100\n",
      "\u001B[1m733/733\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6832 - loss: 40.6141 - val_accuracy: 0.2365 - val_loss: 5.5042\n",
      "Epoch 4/100\n",
      "\u001B[1m733/733\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.6842 - loss: 11.0809 - val_accuracy: 0.8061 - val_loss: 5.4783\n",
      "Epoch 5/100\n",
      "\u001B[1m733/733\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.6848 - loss: 7.3378 - val_accuracy: 0.7923 - val_loss: 9.5232\n",
      "Epoch 6/100\n",
      "\u001B[1m733/733\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.6904 - loss: 4.2902 - val_accuracy: 0.2488 - val_loss: 1.3127\n",
      "Epoch 7/100\n",
      "\u001B[1m733/733\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 992us/step - accuracy: 0.6968 - loss: 2.4617 - val_accuracy: 0.7777 - val_loss: 2.4134\n",
      "Epoch 8/100\n",
      "\u001B[1m733/733\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 786us/step - accuracy: 0.6934 - loss: 2.6811 - val_accuracy: 0.8073 - val_loss: 0.7755\n",
      "Epoch 9/100\n",
      "\u001B[1m733/733\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 819us/step - accuracy: 0.7390 - loss: 0.8681 - val_accuracy: 0.8050 - val_loss: 0.5689\n",
      "Epoch 10/100\n",
      "\u001B[1m733/733\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 825us/step - accuracy: 0.7701 - loss: 0.6858 - val_accuracy: 0.5251 - val_loss: 0.7140\n",
      "Epoch 11/100\n",
      "\u001B[1m733/733\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 829us/step - accuracy: 0.7790 - loss: 0.5666 - val_accuracy: 0.7754 - val_loss: 0.6107\n",
      "Epoch 12/100\n",
      "\u001B[1m733/733\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 787us/step - accuracy: 0.7654 - loss: 0.5645 - val_accuracy: 0.7651 - val_loss: 1.7699\n",
      "Epoch 13/100\n",
      "\u001B[1m733/733\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 870us/step - accuracy: 0.7725 - loss: 0.5812 - val_accuracy: 0.7731 - val_loss: 0.5333\n",
      "Epoch 14/100\n",
      "\u001B[1m733/733\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 837us/step - accuracy: 0.7606 - loss: 0.5501 - val_accuracy: 0.7739 - val_loss: 0.5326\n",
      "Epoch 15/100\n",
      "\u001B[1m733/733\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.7673 - loss: 0.5420 - val_accuracy: 0.7727 - val_loss: 0.5337\n",
      "Epoch 16/100\n",
      "\u001B[1m733/733\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7654 - loss: 0.5928 - val_accuracy: 0.7785 - val_loss: 14.9352\n",
      "Epoch 17/100\n",
      "\u001B[1m733/733\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.6893 - loss: 2.2476 - val_accuracy: 0.7739 - val_loss: 0.5287\n",
      "\u001B[1m204/204\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - accuracy: 0.7606 - loss: 0.5425\n",
      "Test Loss: 0.5361, Test Accuracy: 0.7666\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 5. Model Card Generation with Patra Toolkit\n",
    "\n",
    "Now that we have a trained model, let’s create a **Model Card** to capture essential metadata.\n",
    "\n",
    "1. **ModelCard** object contains high-level information about the model (description, use-cases, etc.).  \n",
    "2. **AIModel** object contains details about the model architecture, performance metrics, ownership, and location.  \n",
    "\n",
    "Afterward, we’ll demonstrate how to automatically populate the following fields:  \n",
    "- **Requirements** (packages and versions)  \n",
    "- **Fairness/Bias Analysis**  \n",
    "- **Explainability/XAI Analysis**  \n",
    "\n",
    "---\n",
    "### 5.1 Create a Model Card\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "782peCr647oO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "mc = ModelCard(\n",
    "    name=\"UCI_Model\",\n",
    "    version=\"0.1\",\n",
    "    short_description=\"UCI Adult Data analysis using Tensorflow for demonstration of Patra Model Cards.\",\n",
    "    full_description=(\n",
    "        \"We have trained a ML model using the tensorflow framework to predict income \"\n",
    "        \"for the UCI Adult Dataset. We leverage this data to run the Patra model cards \"\n",
    "        \"to capture metadata about the model as well as fairness and explainability metrics.\"\n",
    "    ),\n",
    "    keywords=\"uci adult, tensorflow, explainability, fairness, patra\",\n",
    "    author=\"neelk\",\n",
    "    input_type=\"Tabular\",\n",
    "    category=\"classification\",\n",
    "    foundational_model=\"None\",\n",
    "    citation=\"Becker, B. & Kohavi, R. (1996). Adult [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C5XW20.\"\n",
    ")\n",
    "\n",
    "mc.input_data = \"https://archive.ics.uci.edu/ml/datasets/adult\"\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "44EMLknQ47oO",
    "ExecuteTime": {
     "end_time": "2025-03-19T15:53:59.667076Z",
     "start_time": "2025-03-19T15:53:59.660414Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2 Create an AIModel Instance\n",
    "\n",
    "This object describes the **model** itself, capturing details like the model’s location, license, framework, and metrics.\n"
   ],
   "metadata": {
    "id": "gh_rG7hACbce"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ai_model = AIModel(\n",
    "    name=\"Tensorflow Model\",\n",
    "    version=\"0.1\",\n",
    "    description=\"Census classification problem using TensorFlow Neural Network using the UCI Adult Dataset\",\n",
    "    owner=\"Neelesh Karthikeyan\",\n",
    "    location=\"\",\n",
    "    license=\"BSD-3 Clause\",\n",
    "    framework=\"tensorflow\",\n",
    "    model_type=\"dnn\",\n",
    "    test_accuracy=accuracy\n",
    ")\n",
    "\n",
    "# ai_model.inference_label = \"\"\n",
    "\n",
    "# Populate the model's architecture details\n",
    "ai_model.populate_model_structure(model)\n",
    "\n",
    "# Add extra metrics\n",
    "ai_model.add_metric(\"Test loss\", loss)\n",
    "ai_model.add_metric(\"Epochs\", 100)\n",
    "ai_model.add_metric(\"Batch Size\", 32)\n",
    "ai_model.add_metric(\"Optimizer\", \"Adam\")\n",
    "ai_model.add_metric(\"Learning Rate\", 0.001)\n",
    "ai_model.add_metric(\"Input Shape\", str(X_train.shape))\n",
    "\n",
    "# Attach the AIModel object to the ModelCard\n",
    "mc.ai_model = ai_model\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "qblKvqVf47oO",
    "ExecuteTime": {
     "end_time": "2025-03-19T15:53:59.712257Z",
     "start_time": "2025-03-19T15:53:59.704089Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.3 Automatically Capture Requirements\n",
    "\n",
    "`populate_requirements()` will parse your environment to identify installed packages and capture them under **environment/requirements** in the Model Card.\n"
   ],
   "metadata": {
    "id": "ApiCoGhJChsy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "mc.populate_requirements()"
   ],
   "metadata": {
    "id": "KkFVd-SlCjrI",
    "ExecuteTime": {
     "end_time": "2025-03-19T15:53:59.728787Z",
     "start_time": "2025-03-19T15:53:59.725739Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.4 Bias (Fairness) Analysis\n",
    "\n",
    "Below, we show how to call the `populate_bias()` method, which takes the test dataset, predicted labels, and the feature on which you want to measure bias. For demonstration, we assume the “gender” feature is at index 58 in **X_test** (as determined after one-hot encoding).\n",
    "\n",
    "- `feature_name`: \"gender\"  \n",
    "- `protected_feature_data`: The specific column from your **X_test** that corresponds to \"gender\"  \n",
    "- `model`: The trained TensorFlow model (not strictly needed to compute bias, but used in some advanced checks)\n"
   ],
   "metadata": {
    "id": "GMTlU4igCmJI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred >= 0.5).flatten()\n",
    "\n",
    "mc.populate_bias(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    \"gender\",           # Name you want displayed in the report\n",
    "    X_test[:, 58],      # The slice of data that corresponds to gender\n",
    "    model\n",
    ")\n",
    "\n",
    "print(\"Bias Analysis:\\n\", mc.bias_analysis)\n"
   ],
   "metadata": {
    "id": "lCsIT6mSCoHb",
    "outputId": "47635ca8-1794-4657-a8d1-dc7b09682403",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-03-19T15:54:00.046291Z",
     "start_time": "2025-03-19T15:53:59.743008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m204/204\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 658us/step\n",
      "Bias Analysis:\n",
      " {'demographic_parity_diff': 0.008133690985145756, 'equal_odds_difference': 0.012920443683160438}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.5 Explainability (XAI) Analysis\n",
    "\n",
    "Similarly, we can generate some basic SHAP-based interpretability metrics or feature attribution for a sample of inputs.\n",
    "- `num_samples_to_explain`: 10 in our case  \n",
    "- We provide `X_test[:10]` along with the actual column names from the dataset (minus the target column)."
   ],
   "metadata": {
    "id": "AdItgq9UCuLy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Rebuild the list of columns used in training\n",
    "x_columns = data.columns.tolist()\n",
    "x_columns.remove('income')  # Remove the target\n",
    "\n",
    "mc.populate_xai(\n",
    "    X_test[:10],\n",
    "    x_columns,\n",
    "    model\n",
    ")\n",
    "\n",
    "print(\"Explainability Analysis:\\n\", mc.xai_analysis)\n"
   ],
   "metadata": {
    "id": "22Guxy37CvuO",
    "outputId": "faf0d5cc-b59f-4754-8988-3664eae5fa71",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-03-19T15:54:05.966901Z",
     "start_time": "2025-03-19T15:54:00.059918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explainability Analysis:\n",
      " {'fnlwgt': 0.021305733588006758, 'capital_gain': 0.019451196516553564, 'marital_status__Married_civ_spouse': 6.972711947229145e-05, 'relationship__Not_in_family': 5.517875982655416e-05, 'education_num': 5.018817053900846e-05, 'occupation__Exec_managerial': 4.8212773270077546e-05, 'marital_status__Never_married': 4.55575767490597e-05, 'education__HS_grad': 3.9373561739921815e-05, 'education__Bachelors': 3.0500673585467154e-05, 'occupation__Adm_clerical': 2.858169376850042e-05}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 6. Validate and Save the Model Card\n",
    "\n",
    "Before saving, let’s ensure our card follows Patra’s default schema by calling `mc.validate()`. If all checks pass, you can save it locally as a JSON file and later upload it to the **Patra Knowledge Base**."
   ],
   "metadata": {
    "id": "dSCdsUsuC4TL"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Submit the Model, Artifacts, and Model Card to the Patra Server and Model Store"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T15:54:16.499813Z",
     "start_time": "2025-03-19T15:54:05.982998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mc.submit(patra_server_url=\"http://127.0.0.1:5002\",\n",
    "          model=model,\n",
    "          file_format=\"h5\",\n",
    "          model_store=\"huggingface\",\n",
    "          inference_label=\"data/labels.txt\",\n",
    "          artifacts=[\"data/adult/adult.data\",\n",
    "                     \"data/adult/adult.names\",\n",
    "                     \"data/adult/adult.test\"]\n",
    "          )"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: neelk-uci_model-0.1\n",
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "INFO:root:Model serialized successfully.\n",
      "neelk-uci_model-0.1.h5: 100%|██████████| 314k/314k [00:00<00:00, 1.18MB/s]\n",
      "INFO:root:Model uploaded at: https://huggingface.co/patra-iu/neelk-uci_model-0.1/blob/main/neelk-uci_model-0.1.h5\n",
      "INFO:root:Inference label uploaded at: https://huggingface.co/patra-iu/neelk-uci_model-0.1/blob/main/labels.txt\n",
      "INFO:root:Artifact 'data/adult/adult.data' uploaded at: https://huggingface.co/patra-iu/neelk-uci_model-0.1/blob/main/adult.data\n",
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/neelk-uci_model-0.1/blob/main/adult.names\n",
      "INFO:root:Artifact 'data/adult/adult.test' uploaded at: https://huggingface.co/patra-iu/neelk-uci_model-0.1/blob/main/adult.test\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Conclusion\n",
    "\n",
    "Congratulations! You have successfully:\n",
    "\n",
    "1. Trained a neural network on the UCI Adult Dataset using TensorFlow.  \n",
    "2. Created a **Patra Model Card** capturing essential metadata.  \n",
    "3. Automatically analyzed bias and generated basic explainability metrics.  \n",
    "4. Validated and saved the Model Card in JSON format.\n",
    "\n",
    "This process is a foundation for more advanced use-cases, such as:\n",
    "- Uploading the Model Card to the **Patra Knowledge Base** for search and provenance tracking.\n",
    "- Performing deeper fairness analysis (e.g., multiple protected attributes).\n",
    "- Integrating advanced interpretability approaches.\n",
    "\n",
    "By consistently generating and maintaining Model Cards, you’ll be on your way to creating **more transparent** and **accountable** AI solutions.\n"
   ],
   "metadata": {
    "id": "QLi0tXOaDEqr"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
