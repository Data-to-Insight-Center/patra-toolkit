{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# Getting Started with Patra Model Card Toolkit\n",
    "\n",
    "</div>\n",
    "\n",
    "The **Patra Toolkit** simplifies creating and documenting AI/ML models for enhanced transparency. It captures essential metadata, development process, performance metrics, fairness, and explainability analyses—and packages them into **Model Cards** that can be integrated into the [Patra Knowledge Base](https://github.com/Data-to-Insight-Center/patra-kg).\n",
    "\n",
    "## Features\n",
    "- **Structured Schema** – Helps provide critical model information, including usage, development, and performance.\n",
    "- **Semi-Automated Descriptive Fields** – Automated scanners capture fairness, explainability, and environment dependencies:\n",
    "  - *Fairness Scanner* – Evaluates predictions across different groups.  \n",
    "  - *Explainability Scanner* – Provides interpretability metrics.  \n",
    "  - *Model Requirements Scanner* – Records Python packages and versions.\n",
    "- **Validation and JSON Generation** – Ensures completeness and correctness before generating the Model Card as JSON.\n",
    "- **Backend Storage Support** – Pluggable backend repositories enable uploading and retrieving models/ artifacts from *Hugging Face* and *GitHub*\n",
    "- **Integration with Patra Knowledge Base:** The Model Cards created using the Patra Toolkit are designed to be added to the [Patra Knowledge Base](https://github.com/Data-to-Insight-Center/patra-kg), which is a graph database that stores and manages these cards.\n",
    "\n",
    "The Patra Toolkit plays a crucial role in promoting transparency and accountability in AI/ML development by making it easier for developers to create comprehensive and informative Model Cards. By automating certain aspects of the documentation process and providing a structured schema, the Toolkit reduces the barriers to entry for creating high-quality model documentation.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Loading & Preprocessing** the UCI Adult Dataset  \n",
    "2. **Training** a simple TensorFlow model  \n",
    "3. **Creating a Model Card** with optional Fairness and XAI scans  \n",
    "4. **Submitting** the Model Card (and optionally the model, inference label, and artifacts) to:\n",
    "   - **Patra server** (for model card storage)  \n",
    "   - **Backend** (Hugging Face or GitHub) for model storage\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-21T00:03:01.297873Z",
     "start_time": "2025-03-21T00:02:48.719847Z"
    }
   },
   "source": [
    "!pip install patra_toolkit"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: patra_toolkit in /Users/neeleshkarthikeyan/d2i/patra-toolkit (0.1.2)\r\n",
      "Requirement already satisfied: jsonschema>4.18.5 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (4.18.6)\r\n",
      "Requirement already satisfied: fairlearn~=0.11.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (0.11.0)\r\n",
      "Requirement already satisfied: shap~=0.46.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (0.46.0)\r\n",
      "Requirement already satisfied: pandas>=2.0.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (2.2.3)\r\n",
      "Collecting numpy<2.0.0,>=1.23.5 (from patra_toolkit)\r\n",
      "  Obtaining dependency information for numpy<2.0.0,>=1.23.5 from https://files.pythonhosted.org/packages/1a/2e/151484f49fd03944c4a3ad9c418ed193cfd02724e138ac8a9505d056c582/numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\r\n",
      "Requirement already satisfied: requests>2.32.2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (2.32.3)\r\n",
      "Requirement already satisfied: scikit-learn>=1.2.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from fairlearn~=0.11.0->patra_toolkit) (1.5.2)\r\n",
      "Requirement already satisfied: scipy>=1.9.3 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from fairlearn~=0.11.0->patra_toolkit) (1.13.1)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (23.1.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (2024.10.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (0.36.2)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (0.23.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from pandas>=2.0.0->patra_toolkit) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from pandas>=2.0.0->patra_toolkit) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from pandas>=2.0.0->patra_toolkit) (2025.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests>2.32.2->patra_toolkit) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests>2.32.2->patra_toolkit) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests>2.32.2->patra_toolkit) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests>2.32.2->patra_toolkit) (2025.1.31)\r\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (4.67.1)\r\n",
      "Requirement already satisfied: packaging>20.9 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (24.2)\r\n",
      "Requirement already satisfied: slicer==0.0.8 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (0.0.8)\r\n",
      "Requirement already satisfied: numba in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (0.61.0)\r\n",
      "Requirement already satisfied: cloudpickle in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (3.1.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->patra_toolkit) (1.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from referencing>=0.28.4->jsonschema>4.18.5->patra_toolkit) (4.12.2)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from scikit-learn>=1.2.1->fairlearn~=0.11.0->patra_toolkit) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from scikit-learn>=1.2.1->fairlearn~=0.11.0->patra_toolkit) (3.6.0)\r\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from numba->shap~=0.46.0->patra_toolkit) (0.44.0)\r\n",
      "Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\r\n",
      "Installing collected packages: numpy\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 2.1.3\r\n",
      "    Uninstalling numpy-2.1.3:\r\n",
      "      Successfully uninstalled numpy-2.1.3\r\n",
      "Successfully installed numpy-1.26.4\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-21T00:03:29.601236Z",
     "start_time": "2025-03-21T00:03:01.490526Z"
    }
   },
   "source": [
    "!pip install tensorflow"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\r\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/20/cf/55b68d5896e58e25f41e5bc826c96678073b512be8ca2b1f4b101e0f195c/tensorflow-2.19.0-cp311-cp311-macosx_12_0_arm64.whl.metadata\r\n",
      "  Using cached tensorflow-2.19.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.0 kB)\r\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\r\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/2f/7a/874c46ad2d14998bc2eedac1133c5299e12fe728d2ce91b4d64f2fcc5089/absl_py-2.2.0-py3-none-any.whl.metadata\r\n",
      "  Downloading absl_py-2.2.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\r\n",
      "  Obtaining dependency information for astunparse>=1.6.0 from https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl.metadata\r\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\r\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\r\n",
      "  Obtaining dependency information for flatbuffers>=24.3.25 from https://files.pythonhosted.org/packages/b8/25/155f9f080d5e4bc0082edfda032ea2bc2b8fab3f4d25d46c1e9dd22a1a89/flatbuffers-25.2.10-py2.py3-none-any.whl.metadata\r\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\r\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\r\n",
      "  Obtaining dependency information for gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 from https://files.pythonhosted.org/packages/a3/61/8001b38461d751cd1a0c3a6ae84346796a5758123f3ed97a1b121dfbf4f3/gast-0.6.0-py3-none-any.whl.metadata\r\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\r\n",
      "  Obtaining dependency information for google-pasta>=0.1.1 from https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl.metadata\r\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\r\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\r\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/4b/49/f5e3e7e1419872b69f6f5e82ba56e33955a74bd537d8a1f5f1eff2f3668a/libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\r\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\r\n",
      "  Obtaining dependency information for opt-einsum>=2.3.2 from https://files.pythonhosted.org/packages/23/cd/066e86230ae37ed0be70aae89aabf03ca8d9f39c8aea0dec8029455b5540/opt_einsum-3.4.0-py3-none-any.whl.metadata\r\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Requirement already satisfied: packaging in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (24.2)\r\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\r\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/46/de/7c126bbb06aa0f8a7b38aaf8bd746c514d70e6a2a3f6dd460b3b7aad7aae/protobuf-5.29.4-cp38-abi3-macosx_10_9_universal2.whl.metadata\r\n",
      "  Downloading protobuf-5.29.4-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (75.4.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (1.17.0)\r\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\r\n",
      "  Obtaining dependency information for termcolor>=1.1.0 from https://files.pythonhosted.org/packages/7f/be/df630c387a0a054815d60be6a97eb4e8f17385d5d6fe660e1c02750062b4/termcolor-2.5.0-py3-none-any.whl.metadata\r\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (4.12.2)\r\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\r\n",
      "  Obtaining dependency information for wrapt>=1.11.0 from https://files.pythonhosted.org/packages/65/46/5a917ce85b5c3b490d35c02bf71aedaa9f2f63f2d15d9949cc4ba56e8ba9/wrapt-1.17.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached wrapt-1.17.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\r\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\r\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/b4/d5/0bc53ed33ba458de95020970e2c22aa8027b26cc84f98bea7fcad5d695d1/grpcio-1.71.0-cp311-cp311-macosx_10_14_universal2.whl.metadata\r\n",
      "  Using cached grpcio-1.71.0-cp311-cp311-macosx_10_14_universal2.whl.metadata (3.8 kB)\r\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\r\n",
      "  Obtaining dependency information for tensorboard~=2.19.0 from https://files.pythonhosted.org/packages/5d/12/4f70e8e2ba0dbe72ea978429d8530b0333f0ed2140cc571a48802878ef99/tensorboard-2.19.0-py3-none-any.whl.metadata\r\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "Collecting keras>=3.5.0 (from tensorflow)\r\n",
      "  Obtaining dependency information for keras>=3.5.0 from https://files.pythonhosted.org/packages/2b/98/e81c6b2cb522f0eadcc8e16f3cabaccd5462bff6cf52194acfed4a031d3f/keras-3.9.0-py3-none-any.whl.metadata\r\n",
      "  Using cached keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from tensorflow) (1.26.4)\r\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\r\n",
      "  Obtaining dependency information for h5py>=3.11.0 from https://files.pythonhosted.org/packages/94/59/36d87a559cab9c59b59088d52e86008d27a9602ce3afc9d3b51823014bf3/h5py-3.13.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached h5py-3.13.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.5 kB)\r\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\r\n",
      "  Obtaining dependency information for ml-dtypes<1.0.0,>=0.5.1 from https://files.pythonhosted.org/packages/c9/fd/691335926126bb9beeb030b61a28f462773dcf16b8e8a2253b599013a303/ml_dtypes-0.5.1-cp311-cp311-macosx_10_9_universal2.whl.metadata\r\n",
      "  Using cached ml_dtypes-0.5.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (21 kB)\r\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\r\n",
      "  Obtaining dependency information for tensorflow-io-gcs-filesystem>=0.23.1 from https://files.pythonhosted.org/packages/5b/cc/16634e76f3647fbec18187258da3ba11184a6232dcf9073dc44579076d36/tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl.metadata\r\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\r\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\r\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/19/71/39c7c0d87f8d4e6c020a393182060eaefeeae6c01dab6a84ec346f2567df/rich-13.9.4-py3-none-any.whl.metadata\r\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\r\n",
      "  Obtaining dependency information for namex from https://files.pythonhosted.org/packages/73/59/7854fbfb59f8ae35483ce93493708be5942ebb6328cd85b3a609df629736/namex-0.0.8-py3-none-any.whl.metadata\r\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\r\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\r\n",
      "  Obtaining dependency information for optree from https://files.pythonhosted.org/packages/eb/e8/f4d63cf25f1b46d9fc9b005aff28e613b2cf347e6bf41110cc4b77a98a00/optree-0.14.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\r\n",
      "  Using cached optree-0.14.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (49 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\r\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\r\n",
      "  Obtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/3f/08/83871f3c50fc983b88547c196d11cf8c3340e37c32d2e9d6152abe2c61f7/Markdown-3.7-py3-none-any.whl.metadata\r\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\r\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\r\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\r\n",
      "  Obtaining dependency information for werkzeug>=1.0.1 from https://files.pythonhosted.org/packages/52/24/ab44c871b0f07f491e5d2ad12c9bd7358e527510618cb1b803a88e986db1/werkzeug-3.1.3-py3-none-any.whl.metadata\r\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\r\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\r\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\r\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\r\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\r\n",
      "  Obtaining dependency information for mdurl~=0.1 from https://files.pythonhosted.org/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl.metadata\r\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Using cached tensorflow-2.19.0-cp311-cp311-macosx_12_0_arm64.whl (252.6 MB)\r\n",
      "Downloading absl_py-2.2.0-py3-none-any.whl (276 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m277.0/277.0 kB\u001B[0m \u001B[31m5.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\r\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\r\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\r\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\r\n",
      "Using cached grpcio-1.71.0-cp311-cp311-macosx_10_14_universal2.whl (11.3 MB)\r\n",
      "Using cached h5py-3.13.0-cp311-cp311-macosx_11_0_arm64.whl (2.9 MB)\r\n",
      "Using cached keras-3.9.0-py3-none-any.whl (1.3 MB)\r\n",
      "Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\r\n",
      "Using cached ml_dtypes-0.5.1-cp311-cp311-macosx_10_9_universal2.whl (671 kB)\r\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\r\n",
      "Downloading protobuf-5.29.4-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m417.8/417.8 kB\u001B[0m \u001B[31m16.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hUsing cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\r\n",
      "Using cached tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl (3.5 MB)\r\n",
      "Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\r\n",
      "Using cached wrapt-1.17.2-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\r\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\r\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\r\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\r\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\r\n",
      "Using cached optree-0.14.1-cp311-cp311-macosx_11_0_arm64.whl (335 kB)\r\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\r\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\r\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\r\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, markdown, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, markdown-it-py, rich, keras, tensorflow\r\n",
      "Successfully installed absl-py-2.2.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 keras-3.9.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.14.1 protobuf-5.29.4 rich-13.9.4 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 werkzeug-3.1.3 wrapt-1.17.2\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T00:04:10.078841Z",
     "start_time": "2025-03-21T00:03:29.675790Z"
    }
   },
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"absl\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"PyGithub\").setLevel(logging.ERROR)\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import requests, io\n",
    "\n",
    "from patra_toolkit import ModelCard, AIModel"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Pre-process the Data\n",
    "\n",
    "We'll use the **UCI Adult Dataset**, which predicts whether an individual's income is above or below $50K based on demographics. This dataset is a common benchmark for exploring model fairness."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T00:04:11.161119Z",
     "start_time": "2025-03-21T00:04:10.094676Z"
    }
   },
   "source": [
    "resp = requests.get(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\")\n",
    "resp.raise_for_status()\n",
    "\n",
    "cols = [\n",
    "    \"age\",\"workclass\",\"fnlwgt\",\"education\",\"education_num\",\n",
    "    \"marital_status\",\"occupation\",\"relationship\",\"race\",\n",
    "    \"sex\",\"capital_gain\",\"capital_loss\",\"hours_per_week\",\n",
    "    \"native_country\",\"income\"\n",
    "]\n",
    "df = pd.read_csv(io.StringIO(resp.text), names=cols, header=None)\n",
    "\n",
    "# Encode target\n",
    "df[\"income\"] = LabelEncoder().fit_transform(df[\"income\"])  # 1 if >50K, else 0\n",
    "\n",
    "# One-hot encode everything except the target\n",
    "df = pd.get_dummies(df, drop_first=True, dtype=float)\n",
    "\n",
    "# Split into features/labels\n",
    "X = df.drop(\"income\", axis=1).astype(\"float32\").values\n",
    "y = df[\"income\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (26048, 100) Test shape: (6513, 100)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train a Simple TensorFlow Model\n",
    "\n",
    "Below is a straightforward neural network: two hidden layers plus a final sigmoid for binary classification. We'll train for a few epochs to demonstrate end-to-end usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:40.325759Z",
     "start_time": "2025-03-19T18:20:38.677897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m407/407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.6514 - loss: 425.1485\n",
      "Epoch 2/5\n",
      "\u001B[1m407/407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.6807 - loss: 45.0486\n",
      "Epoch 3/5\n",
      "\u001B[1m407/407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 811us/step - accuracy: 0.6847 - loss: 55.8134\n",
      "Epoch 4/5\n",
      "\u001B[1m407/407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 798us/step - accuracy: 0.6852 - loss: 31.7177\n",
      "Epoch 5/5\n",
      "\u001B[1m407/407\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 767us/step - accuracy: 0.6801 - loss: 45.6668\n",
      "Test Loss: 12.5695, Test Accuracy: 0.7857\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building a Patra Model Card\n",
    "\n",
    "### 4.1 Basic Model Card Setup\n",
    "We start with essential metadata like name, version, short description, and so on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:40.337383Z",
     "start_time": "2025-03-19T18:20:40.334625Z"
    }
   },
   "outputs": [],
   "source": [
    "mc = ModelCard(\n",
    "    name=\"UCI_Adult_Model\",\n",
    "    version=\"1.0\",\n",
    "    short_description=\"Predicting whether an individual's income is above $50K using TensorFlow.\",\n",
    "    full_description=(\n",
    "        \"This is a feed-forward neural network trained on the UCI Adult Dataset. \"\n",
    "        \"It demonstrates how Patra Toolkit can store model details, fairness scans, \"\n",
    "        \"and basic explainability data in a comprehensive Model Card.\"\n",
    "    ),\n",
    "    keywords=\"uci, adult, patra, fairness, xai, tensorflow\",\n",
    "    author=\"neelk\",\n",
    "    input_type=\"Tabular\",\n",
    "    category=\"classification\",\n",
    "    citation=\"Becker, B. & Kohavi, R. (1996). Adult [Dataset]. UCI.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Attach AI Model Information\n",
    "Here we describe the model's ownership, license, performance metrics, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:40.349649Z",
     "start_time": "2025-03-19T18:20:40.346860Z"
    }
   },
   "outputs": [],
   "source": [
    "ai_model = AIModel(\n",
    "    name=\"AdultTFModel\",\n",
    "    version=\"1.0\",\n",
    "    description=\"DNN on UCI Adult dataset for income prediction\",\n",
    "    owner=\"username\",\n",
    "    location=\"\", \n",
    "    license=\"BSD-3-Clause\",\n",
    "    framework=\"tensorflow\",\n",
    "    model_type=\"dnn\",\n",
    "    test_accuracy=accuracy\n",
    ")\n",
    "\n",
    "# Add additional performance or training metrics\n",
    "ai_model.add_metric(\"Epochs\", 5)\n",
    "ai_model.add_metric(\"BatchSize\", 64)\n",
    "ai_model.add_metric(\"Optimizer\", \"Adam\")\n",
    "\n",
    "mc.ai_model = ai_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fairness & Explainability\n",
    "\n",
    "### 5.1 Bias (Fairness) Analysis\n",
    "Patra Toolkit has a built-in `populate_bias` method to measure metrics like **demographic parity** or **equalized odds**. We'll focus on the protected attribute \"sex\" in the data.\n",
    "\n",
    "**Why check bias?** Real-world models often inadvertently penalize certain groups. By calling `mc.populate_bias(...)`, you get a quick sense of whether the model is systematically advantaging or disadvantaging certain subpopulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:40.553767Z",
     "start_time": "2025-03-19T18:20:40.363888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m204/204\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 308us/step\n",
      "Bias Analysis:\n",
      " {'demographic_parity_diff': 0.08162253952657954, 'equal_odds_difference': 0.08368136415250488}\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred >= 0.5).flatten()\n",
    "\n",
    "mc.populate_bias(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    \"gender\",           # Name you want displayed in the report\n",
    "    X_test[:, 58],      # The slice of data that corresponds to gender\n",
    "    model\n",
    ")\n",
    "\n",
    "print(\"Bias Analysis:\\n\", mc.bias_analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Explainability (XAI)\n",
    "\n",
    "If we want to understand model decisions, we can generate interpretability metrics (like feature importance) using Patra’s internal SHAP-based approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:43.668417Z",
     "start_time": "2025-03-19T18:20:40.564575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explainability Analysis:\n",
      " {'capital_gain': 0.4196902715030088, 'fnlwgt': 0.0010686394701219777, 'relationship__Wife': 0.0004169165563382081, 'occupation__Exec_managerial': 0.00037468428402272127, 'hours_per_week': 0.00030803950899628693, 'age': 0.0002882660328522926, 'education__HS_grad': 0.00017709857654685587, 'education__Masters': 0.00015673624516589788, 'occupation__Prof_specialty': 0.00012275671500096725, 'marital_status__Married_civ_spouse': 0.00010901905207295246}\n"
     ]
    }
   ],
   "source": [
    "# Rebuild the list of columns used in training\n",
    "x_columns = df.columns.tolist()\n",
    "x_columns.remove('income')  # Remove the target\n",
    "\n",
    "mc.populate_xai(\n",
    "    X_test[:10],\n",
    "    x_columns,\n",
    "    model\n",
    ")\n",
    "\n",
    "print(\"Explainability Analysis:\\n\", mc.xai_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Add Requirements and Validate\n",
    "We let Patra auto-detect Python package dependencies to ensure reproducibility and then validate the card for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:43.686195Z",
     "start_time": "2025-03-19T18:20:43.678194Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Card is valid and ready to submit!\n"
     ]
    }
   ],
   "source": [
    "mc.populate_requirements()\n",
    "if mc.validate():\n",
    "    print(\"Model Card is valid and ready to submit!\")\n",
    "else:\n",
    "    print(\"Validation failed. See logs for details.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Submission Options\n",
    "\n",
    "The `mc.submit(...)` method can do one or more of the following:\n",
    "1. **Submit only the card** (no model, no artifacts).\n",
    "2. **Include the trained model** (uploading to Hugging Face or GitHub).\n",
    "3. **Add artifacts** (like data files, inference labels, or any additional resources).\n",
    "\n",
    "Below, we demonstrate multiple usage patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Submit **Only** the Model Card\n",
    "\n",
    "No model, no inference label, no artifacts. Just the card is posted to your Patra server for cataloging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:43.758444Z",
     "start_time": "2025-03-19T18:20:43.700918Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: neelk-uci_adult_model-1.0\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.submit(patra_server_url=\"http://127.0.0.1:5002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Submit Model Card and Model\n",
    "\n",
    "We can specify `\"huggingface\"` or `\"github\"` for `model_store`. This will attempt to upload our trained model, while the card is posted to the Patra server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:43.788493Z",
     "start_time": "2025-03-19T18:20:43.772095Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "ERROR:root:Model submission failed during model ID creation: Model ID already exists. Please update the model version.\n"
     ]
    }
   ],
   "source": [
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\",  \n",
    "    model=model,                \n",
    "    file_format=\"h5\",\n",
    "    model_store=\"huggingface\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:43.877874Z",
     "start_time": "2025-03-19T18:20:43.862020Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: neelk-uci_adult_model-1.1\n",
      "INFO:root:Model serialized successfully.\n",
      "INFO:root:Package 'huggingface_hub' not found. Installing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n",
      "neelk-uci_adult_model-1.1.h5: 100%|██████████| 130k/130k [00:00<00:00, 432kB/s]\n",
      "INFO:root:Model uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.1/blob/main/neelk-uci_adult_model-1.1.h5\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.version = \"1.1\"\n",
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\",  \n",
    "    model=model,                \n",
    "    file_format=\"h5\",\n",
    "    model_store=\"huggingface\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Submit Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:45.574591Z",
     "start_time": "2025-03-19T18:20:43.979182Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "WARNING:root:Model ID exists, but no model is being uploaded; continuing with existing ID.\n",
      "INFO:root:Model ID retrieved: neelk-uci_adult_model-1.1\n",
      "INFO:root:Artifact 'data/adult/adult.data' uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.1/blob/main/adult.data\n",
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.1/blob/main/adult.names\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.1/blob/main/adult.names\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\", \n",
    "    model_store=\"huggingface\",\n",
    "    artifacts=[\"data/adult/adult.data\", \n",
    "               \"data/adult/adult.names\",\n",
    "               \"data/adult/adult.names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Submit Model Card, Model, and Artifacts\n",
    "\n",
    "This scenario might include a special label file plus multiple dataset artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:45.658798Z",
     "start_time": "2025-03-19T18:20:45.631065Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "ERROR:root:Model submission failed during model ID creation: Model ID already exists. Please update the model version.\n"
     ]
    }
   ],
   "source": [
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\", \n",
    "    model=model,\n",
    "    file_format=\"h5\",\n",
    "    model_store=\"huggingface\",\n",
    "    inference_label=\"data/labels.txt\",\n",
    "    artifacts=[\"data/adult/adult.data\", \n",
    "               \"data/adult/adult.names\",\n",
    "               \"data/adult/adult.names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:20:49.901423Z",
     "start_time": "2025-03-19T18:20:45.675690Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: neelk-uci_adult_model-1.2\n",
      "INFO:root:Model serialized successfully.\n",
      "neelk-uci_adult_model-1.2.h5: 100%|██████████| 130k/130k [00:00<00:00, 1.08MB/s]\n",
      "INFO:root:Model uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.2/blob/main/neelk-uci_adult_model-1.2.h5\n",
      "INFO:root:Inference label uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.2/blob/main/labels.txt\n",
      "INFO:root:Artifact 'data/adult/adult.data' uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.2/blob/main/adult.data\n",
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.2/blob/main/adult.names\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.2/blob/main/adult.names\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.version = \"1.2\"\n",
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\", \n",
    "    model=model,\n",
    "    file_format=\"h5\",\n",
    "    model_store=\"huggingface\",\n",
    "    inference_label=\"data/labels.txt\",\n",
    "    artifacts=[\"data/adult/adult.data\", \n",
    "               \"data/adult/adult.names\",\n",
    "               \"data/adult/adult.names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Pushing to GitHub\n",
    "\n",
    "By switching `\"huggingface\"` to `\"github\"`, you can store your model in a GitHub repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T18:21:01.263306Z",
     "start_time": "2025-03-19T18:20:49.919833Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: neelk-uci_adult_model-1.3\n",
      "INFO:root:Model serialized successfully.\n",
      "INFO:root:Package 'PyGithub' not found. Installing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'neelk-uci_adult_model-1.3' already exists. Using existing repository.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model uploaded at: https://github.com/nee1k/neelk-uci_adult_model-1.3/blob/main/neelk-uci_adult_model-1.3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'neelk-uci_adult_model-1.3' already exists. Using existing repository.\n",
      "No changes to commit, skipping commit step.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Inference label uploaded at: https://github.com/nee1k/neelk-uci_adult_model-1.3/blob/main/labels.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'neelk-uci_adult_model-1.3' already exists. Using existing repository.\n",
      "No changes to commit, skipping commit step.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Artifact 'data/adult/adult.data' uploaded at: https://github.com/nee1k/neelk-uci_adult_model-1.3/blob/main/adult.data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'neelk-uci_adult_model-1.3' already exists. Using existing repository.\n",
      "No changes to commit, skipping commit step.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://github.com/nee1k/neelk-uci_adult_model-1.3/blob/main/adult.names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'neelk-uci_adult_model-1.3' already exists. Using existing repository.\n",
      "No changes to commit, skipping commit step.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://github.com/nee1k/neelk-uci_adult_model-1.3/blob/main/adult.names\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.version = \"1.3\"\n",
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\", \n",
    "    model=model,\n",
    "    file_format=\"h5\",\n",
    "    model_store=\"github\",\n",
    "    inference_label=\"data/labels.txt\",\n",
    "    artifacts=[\"data/adult/adult.data\", \n",
    "               \"data/adult/adult.names\",\n",
    "               \"data/adult/adult.names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following this notebook, you have:\n",
    "\n",
    "\t1.\tLoaded and preprocessed the UCI Adult Dataset\n",
    "\t2.\tTrained a TensorFlow model to predict income\n",
    "\t3.\tBuilt a Patra Model Card describing the model’s purpose, performance, and environment\n",
    "\t4.\t(Optionally) scanned for fairness and explainability metrics\n",
    "\t5.\tSubmitted the card to a Patra server along with the model or artifacts to a chosen store (Hugging Face or GitHub)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
