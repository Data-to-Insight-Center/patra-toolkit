{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# Getting Started with Patra Model Card Toolkit\n",
    "\n",
    "<div align=\"center\">\n",
    "    \n",
    "[![Documentation Status](https://img.shields.io/badge/docs-latest-blue.svg)](https://patra-toolkit.readthedocs.io/en/latest/) [![Build Status](https://github.com/Data-to-Insight-Center/patra-toolkit/actions/workflows/ci.yml/badge.svg)](https://github.com/Data-to-Insight-Center/patra-toolkit/actions)  [![PyPI version](https://badge.fury.io/py/patra-toolkit.svg)](https://pypi.org/project/patra-toolkit/)  [![License](https://img.shields.io/badge/License-BSD%203--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)  [![Example Notebook](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Data-to-Insight-Center/patra-toolkit/blob/main/examples/notebooks/GettingStarted.ipynb)\n",
    "\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "**Patra Toolkit** offers a structured, semi-automated way to create and document AI/ML models via **Model Cards**. These cards:\n",
    "\n",
    "- Capture essential model metadata: purpose, usage, performance.\n",
    "- Include optional but **highly recommended** *Fairness* (bias) and *Explainability* (XAI) analyses.\n",
    "- Support environment scanning for reproducibility.\n",
    "- Can be stored or retrieved from popular backends (Hugging Face, GitHub).\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Loading & Preprocessing** the UCI Adult Dataset  \n",
    "2. **Training** a simple TensorFlow model  \n",
    "3. **Creating a Model Card** with optional Fairness and XAI scans  \n",
    "4. **Submitting** the Model Card (and optionally the model, inference label, and artifacts) to:\n",
    "   - **Patra server** (for model card storage)  \n",
    "   - **Backend** (Hugging Face or GitHub) for model storage\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T16:05:38.111122Z"
    },
    "jupyter": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: patra_toolkit in /Users/neeleshkarthikeyan/d2i/patra-toolkit (0.1.2)\n",
      "Requirement already satisfied: jsonschema>4.18.5 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (4.18.6)\n",
      "Requirement already satisfied: fairlearn~=0.11.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (0.11.0)\n",
      "Requirement already satisfied: shap~=0.46.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (0.46.0)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (2.2.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (1.26.4)\n",
      "Requirement already satisfied: requests>2.32.2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from patra_toolkit) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn>=1.2.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from fairlearn~=0.11.0->patra_toolkit) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.9.3 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from fairlearn~=0.11.0->patra_toolkit) (1.13.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from jsonschema>4.18.5->patra_toolkit) (0.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from pandas>=2.0.0->patra_toolkit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from pandas>=2.0.0->patra_toolkit) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from pandas>=2.0.0->patra_toolkit) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests>2.32.2->patra_toolkit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests>2.32.2->patra_toolkit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests>2.32.2->patra_toolkit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from requests>2.32.2->patra_toolkit) (2025.1.31)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (24.2)\n",
      "Requirement already satisfied: slicer==0.0.8 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (0.0.8)\n",
      "Requirement already satisfied: numba in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (0.61.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from shap~=0.46.0->patra_toolkit) (3.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->patra_toolkit) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from referencing>=0.28.4->jsonschema>4.18.5->patra_toolkit) (4.12.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from scikit-learn>=1.2.1->fairlearn~=0.11.0->patra_toolkit) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from scikit-learn>=1.2.1->fairlearn~=0.11.0->patra_toolkit) (3.5.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /Users/neeleshkarthikeyan/d2i/patra-toolkit/venv/lib/python3.11/site-packages (from numba->shap~=0.46.0->patra_toolkit) (0.44.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 1. ENVIRONMENT SETUP\n",
    "!pip install patra_toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T16:02:13.682558Z",
     "start_time": "2025-03-19T16:02:13.678071Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"absl\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import requests, io\n",
    "\n",
    "from patra_toolkit import ModelCard, AIModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Pre-process the Data\n",
    "\n",
    "We'll use the **UCI Adult Dataset**, which predicts whether an individual's income is above or below $50K based on demographics. This dataset is a common benchmark for exploring model fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T16:02:23.641990Z",
     "start_time": "2025-03-19T16:02:22.796437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (26048, 100) Test shape: (6513, 100)\n"
     ]
    }
   ],
   "source": [
    "data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "resp = requests.get(data_url)\n",
    "resp.raise_for_status()\n",
    "\n",
    "cols = [\n",
    "    \"age\",\"workclass\",\"fnlwgt\",\"education\",\"education_num\",\n",
    "    \"marital_status\",\"occupation\",\"relationship\",\"race\",\n",
    "    \"sex\",\"capital_gain\",\"capital_loss\",\"hours_per_week\",\n",
    "    \"native_country\",\"income\"\n",
    "]\n",
    "df = pd.read_csv(io.StringIO(resp.text), names=cols, header=None)\n",
    "\n",
    "# Encode target\n",
    "df[\"income\"] = LabelEncoder().fit_transform(df[\"income\"])  # 1 if >50K, else 0\n",
    "\n",
    "# One-hot encode everything except the target\n",
    "df = pd.get_dummies(df, drop_first=True, dtype=float)\n",
    "\n",
    "# Split into features/labels\n",
    "X = df.drop(\"income\", axis=1).astype(\"float32\").values\n",
    "y = df[\"income\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train a Simple TensorFlow Model\n",
    "\n",
    "Below is a straightforward neural network: two hidden layers plus a final sigmoid for binary classification. We'll train for a few epochs to demonstrate end-to-end usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T16:02:43.940835Z",
     "start_time": "2025-03-19T16:02:43.795749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 465us/step - accuracy: 0.6495 - loss: 1371.9069   \n",
      "Epoch 2/5\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.6836 - loss: 188.4090\n",
      "Epoch 3/5\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.6798 - loss: 185.3150\n",
      "Epoch 4/5\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.6836 - loss: 145.5680\n",
      "Epoch 5/5\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.6699 - loss: 185.8244\n",
      "Test Loss: 142.9663, Test Accuracy: 0.7895\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building a Patra Model Card\n",
    "\n",
    "### 4.1 Basic Model Card Setup\n",
    "We start with essential metadata like name, version, short description, and so on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T16:03:04.895466Z",
     "start_time": "2025-03-19T16:03:04.882641Z"
    }
   },
   "outputs": [],
   "source": [
    "mc = ModelCard(\n",
    "    name=\"UCI_Adult_Model\",\n",
    "    version=\"1.0\",\n",
    "    short_description=\"Predicting whether an individual's income is above $50K using TensorFlow.\",\n",
    "    full_description=(\n",
    "        \"This is a feed-forward neural network trained on the UCI Adult Dataset. \"\n",
    "        \"It demonstrates how Patra Toolkit can store model details, fairness scans, \"\n",
    "        \"and basic explainability data in a comprehensive Model Card.\"\n",
    "    ),\n",
    "    keywords=\"uci, adult, patra, fairness, xai, tensorflow\",\n",
    "    author=\"YourName\",\n",
    "    input_type=\"Tabular\",\n",
    "    category=\"classification\",\n",
    "    citation=\"Becker, B. & Kohavi, R. (1996). Adult [Dataset]. UCI.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Attach AI Model Information\n",
    "Here we describe the model's ownership, license, performance metrics, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T16:03:18.411441Z",
     "start_time": "2025-03-19T16:03:18.302339Z"
    }
   },
   "outputs": [],
   "source": [
    "ai_model = AIModel(\n",
    "    name=\"AdultTFModel\",\n",
    "    version=\"1.0\",\n",
    "    description=\"DNN on UCI Adult dataset for income prediction\",\n",
    "    owner=\"username\",\n",
    "    location=\"\", \n",
    "    license=\"BSD-3-Clause\",\n",
    "    framework=\"tensorflow\",\n",
    "    model_type=\"dnn\",\n",
    "    test_accuracy=accuracy\n",
    ")\n",
    "\n",
    "# Add additional performance or training metrics\n",
    "ai_model.add_metric(\"Epochs\", 5)\n",
    "ai_model.add_metric(\"BatchSize\", 64)\n",
    "ai_model.add_metric(\"Optimizer\", \"Adam\")\n",
    "\n",
    "mc.ai_model = ai_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fairness & Explainability\n",
    "\n",
    "### 5.1 Bias (Fairness) Analysis\n",
    "Patra Toolkit has a built-in `populate_bias` method to measure metrics like **demographic parity** or **equalized odds**. We'll focus on the protected attribute \"sex\" in the data.\n",
    "\n",
    "**Why check bias?** Real-world models often inadvertently penalize certain groups. By calling `mc.populate_bias(...)`, you get a quick sense of whether the model is systematically advantaging or disadvantaging certain subpopulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step\n",
      "Bias Analysis Results: {'demographic_parity_diff': 0.033167888276767435, 'equal_odds_difference': 0.030822379183587073}\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test) >= 0.5).astype(int).flatten()\n",
    "\n",
    "# Let's assume the \"sex_ Male\" column is at index i (we find it by searching df.columns)\n",
    "import numpy as np\n",
    "col_list = df.drop(\"income\", axis=1).columns.tolist()\n",
    "sex_col_index = col_list.index(\"sex_ Male\")  # example\n",
    "sex_data = X_test[:, sex_col_index]  # This is the 'sex_ Male' feature in numeric form\n",
    "\n",
    "mc.populate_bias(\n",
    "    dataset=X_test,\n",
    "    true_labels=y_test,\n",
    "    predicted_labels=y_pred,\n",
    "    sensitive_feature_name=\"sex\",\n",
    "    sensitive_feature_data=sex_data,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "print(\"Bias Analysis Results:\", mc.bias_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Explainability (XAI)\n",
    "\n",
    "If we want to understand model decisions, we can generate interpretability metrics (like feature importance) using Patra’s internal SHAP-based approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explainability (SHAP-based) info: {'capital_gain': 0.25, 'fnlwgt': 0.09, 'native_country__Cuba': 0.0, 'native_country__Holand_Netherlands': 0.0, 'native_country__Haiti': 0.0, 'native_country__Guatemala': 0.0, 'native_country__Greece': 0.0, 'native_country__Germany': 0.0, 'native_country__France': 0.0, 'native_country__England': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# We'll define a subset for demonstration\n",
    "x_columns = df.drop(\"income\", axis=1).columns.tolist()\n",
    "\n",
    "mc.populate_xai(\n",
    "    train_dataset=X_test[:10],  # or any sample you want\n",
    "    column_names=x_columns,\n",
    "    model=model,\n",
    "    n_features=10  # top 10 features\n",
    ")\n",
    "\n",
    "print(\"Explainability (SHAP-based) info:\", mc.xai_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Add Requirements and Validate\n",
    "We let Patra auto-detect Python package dependencies to ensure reproducibility and then validate the card for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Card is valid and ready to submit!\n"
     ]
    }
   ],
   "source": [
    "mc.populate_requirements()\n",
    "if mc.validate():\n",
    "    print(\"Model Card is valid and ready to submit!\")\n",
    "else:\n",
    "    print(\"Validation failed. See logs for details.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Submission Options\n",
    "\n",
    "The `mc.submit(...)` method can do one or more of the following:\n",
    "1. **Submit only the card** (no model, no artifacts).\n",
    "2. **Include the trained model** (uploading to Hugging Face or GitHub).\n",
    "3. **Add artifacts** (like data files, inference labels, or any additional resources).\n",
    "\n",
    "Below, we demonstrate multiple usage patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Submit **Only** the Model Card\n",
    "\n",
    "No model, no inference label, no artifacts. Just the card is posted to your Patra server for cataloging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: yourname-uci_adult_model-1.0\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\", # example\n",
    "    model=None,\n",
    "    file_format=None,\n",
    "    model_store=None,\n",
    "    inference_label=None,\n",
    "    artifacts=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Submit Model Card and Model\n",
    "\n",
    "We can specify `\"huggingface\"` or `\"github\"` for `model_store`. This will attempt to upload our trained model, while the card is posted to the Patra server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: yourname-uci_adult_model-1.0\n",
      "INFO:root:Model serialized successfully.\n",
      "yourname-uci_adult_model-1.0.h5: 100%|██████████| 130k/130k [00:00<00:00, 549kB/s]\n",
      "INFO:root:Model uploaded at: https://huggingface.co/patra-iu/yourname-uci_adult_model-1.0/blob/main/yourname-uci_adult_model-1.0.h5\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\",  \n",
    "    model=model,                \n",
    "    file_format=\"h5\",\n",
    "    model_store=\"huggingface\",  \n",
    "    inference_label=None,\n",
    "    artifacts=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Submit Model Card, Model, and Artifacts\n",
    "\n",
    "This scenario might include a special label file plus multiple dataset artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: yourname-uci_adult_model-1.0\n",
      "INFO:root:Model serialized successfully.\n",
      "INFO:root:Model uploaded at: https://huggingface.co/patra-iu/yourname-uci_adult_model-1.0/blob/main/yourname-uci_adult_model-1.0.h5\n",
      "INFO:root:Inference label uploaded at: https://huggingface.co/patra-iu/yourname-uci_adult_model-1.0/blob/main/labels.txt\n",
      "INFO:root:Artifact 'data/adult/adult.data' uploaded at: https://huggingface.co/patra-iu/yourname-uci_adult_model-1.0/blob/main/adult.data\n",
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/yourname-uci_adult_model-1.0/blob/main/adult.names\n",
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/yourname-uci_adult_model-1.0/blob/main/adult.names\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\", \n",
    "    model=model,\n",
    "    file_format=\"h5\",\n",
    "    model_store=\"huggingface\",\n",
    "    inference_label=\"data/labels.txt\",\n",
    "    artifacts=[\"data/adult/adult.data\", \n",
    "               \"data/adult/adult.names\",\n",
    "               \"data/adult/adult.names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Pushing to GitHub\n",
    "\n",
    "By switching `\"huggingface\"` to `\"github\"`, you can store your model in a GitHub repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: yourname-uci_adult_model-1.0\n",
      "INFO:root:Model serialized successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'yourname-uci_adult_model-1.0' created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model uploaded at: https://github.com/nee1k/yourname-uci_adult_model-1.0/blob/main/yourname-uci_adult_model-1.0.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'yourname-uci_adult_model-1.0' already exists. Using existing repository.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Inference label uploaded at: https://github.com/nee1k/yourname-uci_adult_model-1.0/blob/main/labels.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'yourname-uci_adult_model-1.0' already exists. Using existing repository.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Artifact 'data/adult/adult.data' uploaded at: https://github.com/nee1k/yourname-uci_adult_model-1.0/blob/main/adult.data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'yourname-uci_adult_model-1.0' already exists. Using existing repository.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://github.com/nee1k/yourname-uci_adult_model-1.0/blob/main/adult.names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'yourname-uci_adult_model-1.0' already exists. Using existing repository.\n",
      "No changes to commit, skipping commit step.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://github.com/nee1k/yourname-uci_adult_model-1.0/blob/main/adult.names\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\", \n",
    "    model=model,\n",
    "    file_format=\"h5\",\n",
    "    model_store=\"github\",\n",
    "    inference_label=\"data/labels.txt\",\n",
    "    artifacts=[\"data/adult/adult.data\", \n",
    "               \"data/adult/adult.names\",\n",
    "               \"data/adult/adult.names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following this notebook, you have:\n",
    "\n",
    "\t1.\tLoaded and preprocessed the UCI Adult Dataset\n",
    "\t2.\tTrained a TensorFlow model to predict income\n",
    "\t3.\tBuilt a Patra Model Card describing the model’s purpose, performance, and environment\n",
    "\t4.\t(Optionally) scanned for fairness and explainability metrics\n",
    "\t5.\tSubmitted the card to a Patra server along with the model or artifacts to a chosen store (Hugging Face or GitHub)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
