{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# Getting Started with Patra Model Card Toolkit\n",
    "\n",
    "</div>\n",
    "\n",
    "The **Patra Toolkit** simplifies creating and documenting AI/ML models through a structured schema, encouraging best practices and enhanced transparency. It captures essential metadata—model purpose, development process, performance metrics, fairness, and explainability analyses—and packages them into **Model Cards** that can be integrated into the [Patra Knowledge Base](https://github.com/Data-to-Insight-Center/patra-kg).\n",
    "\n",
    "## Features\n",
    "- **Structured Schema** – Helps provide critical model information, including usage, development, and performance.\n",
    "- **Semi-Automated Descriptive Fields** – Automated scanners capture fairness, explainability, and environment dependencies:\n",
    "  - *Fairness Scanner* – Evaluates predictions across different groups.  \n",
    "  - *Explainability Scanner* – Provides interpretability metrics.  \n",
    "  - *Model Requirements Scanner* – Records Python packages and versions.\n",
    "- **Validation and JSON Generation** – Ensures completeness and correctness before generating the Model Card as JSON.\n",
    "- **Backend Storage Support** – Pluggable model store backends enable uploading and retrieving models/artifacts from:\n",
    "  - *Hugging Face* – Integrates with Hugging Face Hub for model storage.  \n",
    "  - *GitHub* – Leverages GitHub repositories to store serialized models.  \n",
    "- **Integration with Patra Knowledge Base:** The Model Cards created using the Patra Toolkit are designed to be added to the [Patra Knowledge Base](https://github.com/Data-to-Insight-Center/patra-kg), which is a graph database that stores and manages these cards.\n",
    "\n",
    "The Patra Toolkit plays a crucial role in promoting transparency and accountability in AI/ML development by making it easier for developers to create comprehensive and informative Model Cards. By automating certain aspects of the documentation process and providing a structured schema, the Toolkit reduces the barriers to entry for creating high-quality model documentation.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Loading & Preprocessing** the UCI Adult Dataset  \n",
    "2. **Training** a simple TensorFlow model  \n",
    "3. **Creating a Model Card** with optional Fairness and XAI scans  \n",
    "4. **Submitting** the Model Card (and optionally the model, inference label, and artifacts) to:\n",
    "   - **Patra server** (for model card storage)  \n",
    "   - **Backend** (Hugging Face or GitHub) for model storage\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T16:05:38.111122Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: patra_toolkit in /Users/neeleshkarthikeyan/d2i/patra-toolkit (0.1.2)\n",
      "Collecting jsonschema>4.18.5 (from patra_toolkit)\n",
      "  Obtaining dependency information for jsonschema>4.18.5 from https://files.pythonhosted.org/packages/69/4a/4f9dbeb84e8850557c02365a0eee0649abe5eb1d84af92a25731c6c0f922/jsonschema-4.23.0-py3-none-any.whl.metadata\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting fairlearn~=0.11.0 (from patra_toolkit)\n",
      "  Obtaining dependency information for fairlearn~=0.11.0 from https://files.pythonhosted.org/packages/ec/10/7142b64f0835958920672410c0002b3575d668db979000266e81b19eb4ac/fairlearn-0.11.0-py3-none-any.whl.metadata\n",
      "  Downloading fairlearn-0.11.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting shap~=0.46.0 (from patra_toolkit)\n",
      "  Obtaining dependency information for shap~=0.46.0 from https://files.pythonhosted.org/packages/5f/9e/dce41d5ec9e79add65faf4381d8d4492247b29daaa6cc7d7fd0298abc1e2/shap-0.46.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading shap-0.46.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (24 kB)\n",
      "Collecting pandas>=2.0.0 (from patra_toolkit)\n",
      "  Obtaining dependency information for pandas>=2.0.0 from https://files.pythonhosted.org/packages/52/11/9eac327a38834f162b8250aab32a6781339c69afe7574368fffe46387edf/pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting numpy<2.0.0,>=1.23.5 (from patra_toolkit)\n",
      "  Obtaining dependency information for numpy<2.0.0,>=1.23.5 from https://files.pythonhosted.org/packages/1a/2e/151484f49fd03944c4a3ad9c418ed193cfd02724e138ac8a9505d056c582/numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Collecting requests>2.32.2 (from patra_toolkit)\n",
      "  Obtaining dependency information for requests>2.32.2 from https://files.pythonhosted.org/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl.metadata\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting scikit-learn>=1.2.1 (from fairlearn~=0.11.0->patra_toolkit)\n",
      "  Obtaining dependency information for scikit-learn>=1.2.1 from https://files.pythonhosted.org/packages/25/92/ee1d7a00bb6b8c55755d4984fd82608603a3cc59959245068ce32e7fb808/scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting scipy>=1.9.3 (from fairlearn~=0.11.0->patra_toolkit)\n",
      "  Obtaining dependency information for scipy>=1.9.3 from https://files.pythonhosted.org/packages/61/d8/84da3fffefb6c7d5a16968fe5b9f24c98606b165bb801bb0b8bc3985200f/scipy-1.15.2-cp311-cp311-macosx_14_0_arm64.whl.metadata\n",
      "  Downloading scipy-1.15.2-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting attrs>=22.2.0 (from jsonschema>4.18.5->patra_toolkit)\n",
      "  Obtaining dependency information for attrs>=22.2.0 from https://files.pythonhosted.org/packages/77/06/bb80f5f86020c4551da315d78b3ab75e8228f89f0162f2c3a819e407941a/attrs-25.3.0-py3-none-any.whl.metadata\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>4.18.5->patra_toolkit)\n",
      "  Obtaining dependency information for jsonschema-specifications>=2023.03.6 from https://files.pythonhosted.org/packages/d1/0f/8910b19ac0670a0f80ce1008e5e751c4a57e14d2c4c13a482aa6079fa9d6/jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>4.18.5->patra_toolkit)\n",
      "  Obtaining dependency information for referencing>=0.28.4 from https://files.pythonhosted.org/packages/c1/b1/3baf80dc6d2b7bc27a95a67752d0208e410351e3feb4eb78de5f77454d8d/referencing-0.36.2-py3-none-any.whl.metadata\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>4.18.5->patra_toolkit)\n",
      "  Obtaining dependency information for rpds-py>=0.7.1 from https://files.pythonhosted.org/packages/a7/0a/3dedb2daee8e783622427f5064e2d112751d8276ee73aa5409f000a132f4/rpds_py-0.23.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading rpds_py-0.23.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas>=2.0.0->patra_toolkit)\n",
      "  Obtaining dependency information for python-dateutil>=2.8.2 from https://files.pythonhosted.org/packages/ec/57/56b9bcc3c9c6a792fcbaf139543cee77261f3651ca9da0c93f5c1221264b/python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=2.0.0->patra_toolkit)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/eb/38/ac33370d784287baa1c3d538978b5e2ea064d4c1b93ffbd12826c190dd10/pytz-2025.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=2.0.0->patra_toolkit)\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/0f/dd/84f10e23edd882c6f968c21c2434fe67bd4a528967067515feca9e611e5e/tzdata-2025.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>2.32.2->patra_toolkit)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/72/80/41ef5d5a7935d2d3a773e3eaebf0a9350542f2cab4eac59a7a4741fbbbbe/charset_normalizer-3.4.1-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>2.32.2->patra_toolkit)\n",
      "  Obtaining dependency information for idna<4,>=2.5 from https://files.pythonhosted.org/packages/76/c6/c88e154df9c4e1a2a66ccf0005a88dfb2650c1dffb6f5ce603dfbd452ce3/idna-3.10-py3-none-any.whl.metadata\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>2.32.2->patra_toolkit)\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/c8/19/4ec628951a74043532ca2cf5d97b7b14863931476d117c471e8e2b1eb39f/urllib3-2.3.0-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>2.32.2->patra_toolkit)\n",
      "  Obtaining dependency information for certifi>=2017.4.17 from https://files.pythonhosted.org/packages/38/fc/bce832fd4fd99766c04d1ee0eead6b0ec6486fb100ae5e74c1d91292b982/certifi-2025.1.31-py3-none-any.whl.metadata\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting tqdm>=4.27.0 (from shap~=0.46.0->patra_toolkit)\n",
      "  Obtaining dependency information for tqdm>=4.27.0 from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting packaging>20.9 (from shap~=0.46.0->patra_toolkit)\n",
      "  Obtaining dependency information for packaging>20.9 from https://files.pythonhosted.org/packages/88/ef/eb23f262cca3c0c4eb7ab1933c3b1f03d021f2c48f54763065b6f0e321be/packaging-24.2-py3-none-any.whl.metadata\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting slicer==0.0.8 (from shap~=0.46.0->patra_toolkit)\n",
      "  Obtaining dependency information for slicer==0.0.8 from https://files.pythonhosted.org/packages/63/81/9ef641ff4e12cbcca30e54e72fb0951a2ba195d0cda0ba4100e532d929db/slicer-0.0.8-py3-none-any.whl.metadata\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting numba (from shap~=0.46.0->patra_toolkit)\n",
      "  Obtaining dependency information for numba from https://files.pythonhosted.org/packages/be/1b/c33dc847d475d5b647b4ad5aefc38df7a72283763f4cda47745050375a81/numba-0.61.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading numba-0.61.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting cloudpickle (from shap~=0.46.0->patra_toolkit)\n",
      "  Obtaining dependency information for cloudpickle from https://files.pythonhosted.org/packages/7e/e8/64c37fadfc2816a7701fa8a6ed8d87327c7d54eacfbfb6edab14a2f2be75/cloudpickle-3.1.1-py3-none-any.whl.metadata\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas>=2.0.0->patra_toolkit)\n",
      "  Obtaining dependency information for six>=1.5 from https://files.pythonhosted.org/packages/b7/ce/149a00dd41f10bc29e5921b496af8b574d8413afcd5e30dfa0ed46c2cc5e/six-1.17.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting typing-extensions>=4.4.0 (from referencing>=0.28.4->jsonschema>4.18.5->patra_toolkit)\n",
      "  Obtaining dependency information for typing-extensions>=4.4.0 from https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=1.2.1->fairlearn~=0.11.0->patra_toolkit)\n",
      "  Obtaining dependency information for joblib>=1.2.0 from https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.2.1->fairlearn~=0.11.0->patra_toolkit)\n",
      "  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/32/d5/f9a850d79b0851d1d4ef6456097579a9005b31fea68726a4ae5f2d82ddd9/threadpoolctl-3.6.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba->shap~=0.46.0->patra_toolkit)\n",
      "  Obtaining dependency information for llvmlite<0.45,>=0.44.0dev0 from https://files.pythonhosted.org/packages/ff/ec/506902dc6870249fbe2466d9cf66d531265d0f3a1157213c8f986250c033/llvmlite-0.44.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading llvmlite-0.44.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Downloading fairlearn-0.11.0-py3-none-any.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.3/232.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Downloading pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading shap-0.46.0-cp311-cp311-macosx_11_0_arm64.whl (455 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.8/455.8 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading charset_normalizer-3.4.1-cp311-cp311-macosx_10_9_universal2.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.0/195.0 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.9/507.9 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.23.1-cp311-cp311-macosx_11_0_arm64.whl (356 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m356.9/356.9 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.2-cp311-cp311-macosx_14_0_arm64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading numba-0.61.0-cp311-cp311-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading llvmlite-0.44.0-cp311-cp311-macosx_11_0_arm64.whl (26.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.2/26.2 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: pytz, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, slicer, six, rpds-py, packaging, numpy, llvmlite, joblib, idna, cloudpickle, charset-normalizer, certifi, attrs, scipy, requests, referencing, python-dateutil, numba, scikit-learn, pandas, jsonschema-specifications, shap, jsonschema, fairlearn\n",
      "Successfully installed attrs-25.3.0 certifi-2025.1.31 charset-normalizer-3.4.1 cloudpickle-3.1.1 fairlearn-0.11.0 idna-3.10 joblib-1.4.2 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 llvmlite-0.44.0 numba-0.61.0 numpy-1.26.4 packaging-24.2 pandas-2.2.3 python-dateutil-2.9.0.post0 pytz-2025.1 referencing-0.36.2 requests-2.32.3 rpds-py-0.23.1 scikit-learn-1.6.1 scipy-1.15.2 shap-0.46.0 six-1.17.0 slicer-0.0.8 threadpoolctl-3.6.0 tqdm-4.67.1 typing-extensions-4.12.2 tzdata-2025.1 urllib3-2.3.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install patra_toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-19T17:20:01.430313Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"absl\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"PyGithub\").setLevel(logging.ERROR)\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import requests, io\n",
    "\n",
    "from patra_toolkit import ModelCard, AIModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Pre-process the Data\n",
    "\n",
    "We'll use the **UCI Adult Dataset**, which predicts whether an individual's income is above or below $50K based on demographics. This dataset is a common benchmark for exploring model fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T16:02:23.641990Z",
     "start_time": "2025-03-19T16:02:22.796437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (26048, 100) Test shape: (6513, 100)\n"
     ]
    }
   ],
   "source": [
    "data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "resp = requests.get(data_url)\n",
    "resp.raise_for_status()\n",
    "\n",
    "cols = [\n",
    "    \"age\",\"workclass\",\"fnlwgt\",\"education\",\"education_num\",\n",
    "    \"marital_status\",\"occupation\",\"relationship\",\"race\",\n",
    "    \"sex\",\"capital_gain\",\"capital_loss\",\"hours_per_week\",\n",
    "    \"native_country\",\"income\"\n",
    "]\n",
    "df = pd.read_csv(io.StringIO(resp.text), names=cols, header=None)\n",
    "\n",
    "# Encode target\n",
    "df[\"income\"] = LabelEncoder().fit_transform(df[\"income\"])  # 1 if >50K, else 0\n",
    "\n",
    "# One-hot encode everything except the target\n",
    "df = pd.get_dummies(df, drop_first=True, dtype=float)\n",
    "\n",
    "# Split into features/labels\n",
    "X = df.drop(\"income\", axis=1).astype(\"float32\").values\n",
    "y = df[\"income\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train a Simple TensorFlow Model\n",
    "\n",
    "Below is a straightforward neural network: two hidden layers plus a final sigmoid for binary classification. We'll train for a few epochs to demonstrate end-to-end usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T16:02:43.940835Z",
     "start_time": "2025-03-19T16:02:43.795749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - accuracy: 0.6729 - loss: 903.4367\n",
      "Epoch 2/5\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.6763 - loss: 218.0626\n",
      "Epoch 3/5\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6886 - loss: 162.0765\n",
      "Epoch 4/5\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6828 - loss: 194.1631\n",
      "Epoch 5/5\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6830 - loss: 176.9442\n",
      "Test Loss: 258.3792, Test Accuracy: 0.2412\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building a Patra Model Card\n",
    "\n",
    "### 4.1 Basic Model Card Setup\n",
    "We start with essential metadata like name, version, short description, and so on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T16:03:04.895466Z",
     "start_time": "2025-03-19T16:03:04.882641Z"
    }
   },
   "outputs": [],
   "source": [
    "mc = ModelCard(\n",
    "    name=\"UCI_Adult_Model\",\n",
    "    version=\"1.0\",\n",
    "    short_description=\"Predicting whether an individual's income is above $50K using TensorFlow.\",\n",
    "    full_description=(\n",
    "        \"This is a feed-forward neural network trained on the UCI Adult Dataset. \"\n",
    "        \"It demonstrates how Patra Toolkit can store model details, fairness scans, \"\n",
    "        \"and basic explainability data in a comprehensive Model Card.\"\n",
    "    ),\n",
    "    keywords=\"uci, adult, patra, fairness, xai, tensorflow\",\n",
    "    author=\"neelk\",\n",
    "    input_type=\"Tabular\",\n",
    "    category=\"classification\",\n",
    "    citation=\"Becker, B. & Kohavi, R. (1996). Adult [Dataset]. UCI.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Attach AI Model Information\n",
    "Here we describe the model's ownership, license, performance metrics, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T16:03:18.411441Z",
     "start_time": "2025-03-19T16:03:18.302339Z"
    }
   },
   "outputs": [],
   "source": [
    "ai_model = AIModel(\n",
    "    name=\"AdultTFModel\",\n",
    "    version=\"1.0\",\n",
    "    description=\"DNN on UCI Adult dataset for income prediction\",\n",
    "    owner=\"username\",\n",
    "    location=\"\", \n",
    "    license=\"BSD-3-Clause\",\n",
    "    framework=\"tensorflow\",\n",
    "    model_type=\"dnn\",\n",
    "    test_accuracy=accuracy\n",
    ")\n",
    "\n",
    "# Add additional performance or training metrics\n",
    "ai_model.add_metric(\"Epochs\", 5)\n",
    "ai_model.add_metric(\"BatchSize\", 64)\n",
    "ai_model.add_metric(\"Optimizer\", \"Adam\")\n",
    "\n",
    "mc.ai_model = ai_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fairness & Explainability\n",
    "\n",
    "### 5.1 Bias (Fairness) Analysis\n",
    "Patra Toolkit has a built-in `populate_bias` method to measure metrics like **demographic parity** or **equalized odds**. We'll focus on the protected attribute \"sex\" in the data.\n",
    "\n",
    "**Why check bias?** Real-world models often inadvertently penalize certain groups. By calling `mc.populate_bias(...)`, you get a quick sense of whether the model is systematically advantaging or disadvantaging certain subpopulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step\n",
      "Bias Analysis:\n",
      " {'demographic_parity_diff': np.float64(0.0), 'equal_odds_difference': 0.0}\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred >= 0.5).flatten()\n",
    "\n",
    "mc.populate_bias(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    \"gender\",           # Name you want displayed in the report\n",
    "    X_test[:, 58],      # The slice of data that corresponds to gender\n",
    "    model\n",
    ")\n",
    "\n",
    "print(\"Bias Analysis:\\n\", mc.bias_analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Explainability (XAI)\n",
    "\n",
    "If we want to understand model decisions, we can generate interpretability metrics (like feature importance) using Patra’s internal SHAP-based approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explainability Analysis:\n",
      " {'age': 0.0, 'native_country__Cuba': 0.0, 'native_country__Holand_Netherlands': 0.0, 'native_country__Haiti': 0.0, 'native_country__Guatemala': 0.0, 'native_country__Greece': 0.0, 'native_country__Germany': 0.0, 'native_country__France': 0.0, 'native_country__England': 0.0, 'native_country__El_Salvador': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Rebuild the list of columns used in training\n",
    "x_columns = df.columns.tolist()\n",
    "x_columns.remove('income')  # Remove the target\n",
    "\n",
    "mc.populate_xai(\n",
    "    X_test[:10],\n",
    "    x_columns,\n",
    "    model\n",
    ")\n",
    "\n",
    "print(\"Explainability Analysis:\\n\", mc.xai_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Add Requirements and Validate\n",
    "We let Patra auto-detect Python package dependencies to ensure reproducibility and then validate the card for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Card is valid and ready to submit!\n"
     ]
    }
   ],
   "source": [
    "mc.populate_requirements()\n",
    "if mc.validate():\n",
    "    print(\"Model Card is valid and ready to submit!\")\n",
    "else:\n",
    "    print(\"Validation failed. See logs for details.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Submission Options\n",
    "\n",
    "The `mc.submit(...)` method can do one or more of the following:\n",
    "1. **Submit only the card** (no model, no artifacts).\n",
    "2. **Include the trained model** (uploading to Hugging Face or GitHub).\n",
    "3. **Add artifacts** (like data files, inference labels, or any additional resources).\n",
    "\n",
    "Below, we demonstrate multiple usage patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Submit **Only** the Model Card\n",
    "\n",
    "No model, no inference label, no artifacts. Just the card is posted to your Patra server for cataloging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: neelk-uci_adult_model-1.0\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.submit(patra_server_url=\"http://127.0.0.1:5002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Submit Model Card and Model\n",
    "\n",
    "We can specify `\"huggingface\"` or `\"github\"` for `model_store`. This will attempt to upload our trained model, while the card is posted to the Patra server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "ERROR:root:Model submission failed during model ID creation: Model ID already exists. Please update your model version or choose a new name.\n"
     ]
    }
   ],
   "source": [
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\",  \n",
    "    model=model,                \n",
    "    file_format=\"h5\",\n",
    "    model_store=\"huggingface\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: neelk-uci_adult_model-1.1\n",
      "ERROR:root:Model submission failed during model serialization: module 'torch' has no attribute 'nn'\n"
     ]
    }
   ],
   "source": [
    "mc.version = \"1.1\"\n",
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\",  \n",
    "    model=model,                \n",
    "    file_format=\"h5\",\n",
    "    model_store=\"huggingface\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Submit Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "WARNING:root:Model ID exists, but no model is being uploaded; continuing.\n",
      "INFO:root:Model ID retrieved: unknown-id\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "INFO:root:Artifact 'data/adult/adult.data' uploaded at: https://huggingface.co/patra-iu/unknown-id/blob/main/adult.data\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/unknown-id/blob/main/adult.names\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/unknown-id/blob/main/adult.names\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\", \n",
    "    model_store=\"huggingface\",\n",
    "    artifacts=[\"data/adult/adult.data\", \n",
    "               \"data/adult/adult.names\",\n",
    "               \"data/adult/adult.names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Submit Model Card, Model, and Artifacts\n",
    "\n",
    "This scenario might include a special label file plus multiple dataset artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "ERROR:root:Model submission failed during model ID creation: Model ID already exists. Please update your model version or choose a new name.\n"
     ]
    }
   ],
   "source": [
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\", \n",
    "    model=model,\n",
    "    file_format=\"h5\",\n",
    "    model_store=\"huggingface\",\n",
    "    inference_label=\"data/labels.txt\",\n",
    "    artifacts=[\"data/adult/adult.data\", \n",
    "               \"data/adult/adult.names\",\n",
    "               \"data/adult/adult.names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: neelk-uci_adult_model-1.2\n",
      "INFO:root:Model serialized successfully.\n",
      "neelk-uci_adult_model-1.2.h5: 100%|██████████| 130k/130k [00:00<00:00, 1.56MB/s]\n",
      "INFO:root:Model uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.2/blob/main/neelk-uci_adult_model-1.2.h5\n",
      "INFO:root:Inference label uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.2/blob/main/labels.txt\n",
      "INFO:root:Artifact 'data/adult/adult.data' uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.2/blob/main/adult.data\n",
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.2/blob/main/adult.names\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://huggingface.co/patra-iu/neelk-uci_adult_model-1.2/blob/main/adult.names\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.version = \"1.2\"\n",
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\", \n",
    "    model=model,\n",
    "    file_format=\"h5\",\n",
    "    model_store=\"huggingface\",\n",
    "    inference_label=\"data/labels.txt\",\n",
    "    artifacts=[\"data/adult/adult.data\", \n",
    "               \"data/adult/adult.names\",\n",
    "               \"data/adult/adult.names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Pushing to GitHub\n",
    "\n",
    "By switching `\"huggingface\"` to `\"github\"`, you can store your model in a GitHub repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model card validated successfully.\n",
      "INFO:root:Model ID retrieved: neelk-uci_adult_model-1.3\n",
      "INFO:root:Model serialized successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'neelk-uci_adult_model-1.3' created successfully.\n",
      "Initialized empty Git repository in /private/var/folders/d7/zwq9fkgs65xdfbrv7v00g8dc0000gn/T/neelk-uci_adult_model-1.36xwscxda/.git/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/nee1k/neelk-uci_adult_model-1.3.git\n",
      " * [new branch]      main -> mainINFO:root:Model uploaded at: https://github.com/nee1k/neelk-uci_adult_model-1.3/blob/main/neelk-uci_adult_model-1.3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'neelk-uci_adult_model-1.3' already exists. Using existing repository.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Inference label uploaded at: https://github.com/nee1k/neelk-uci_adult_model-1.3/blob/main/labels.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'neelk-uci_adult_model-1.3' already exists. Using existing repository.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Artifact 'data/adult/adult.data' uploaded at: https://github.com/nee1k/neelk-uci_adult_model-1.3/blob/main/adult.data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'neelk-uci_adult_model-1.3' already exists. Using existing repository.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://github.com/nee1k/neelk-uci_adult_model-1.3/blob/main/adult.names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'neelk-uci_adult_model-1.3' already exists. Using existing repository.\n",
      "No changes to commit, skipping commit step.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Artifact 'data/adult/adult.names' uploaded at: https://github.com/nee1k/neelk-uci_adult_model-1.3/blob/main/adult.names\n",
      "INFO:root:Model Card submitted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.version = \"1.3\"\n",
    "mc.submit(\n",
    "    patra_server_url=\"http://127.0.0.1:5002\", \n",
    "    model=model,\n",
    "    file_format=\"h5\",\n",
    "    model_store=\"github\",\n",
    "    inference_label=\"data/labels.txt\",\n",
    "    artifacts=[\"data/adult/adult.data\", \n",
    "               \"data/adult/adult.names\",\n",
    "               \"data/adult/adult.names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following this notebook, you have:\n",
    "\n",
    "\t1.\tLoaded and preprocessed the UCI Adult Dataset\n",
    "\t2.\tTrained a TensorFlow model to predict income\n",
    "\t3.\tBuilt a Patra Model Card describing the model’s purpose, performance, and environment\n",
    "\t4.\t(Optionally) scanned for fairness and explainability metrics\n",
    "\t5.\tSubmitted the card to a Patra server along with the model or artifacts to a chosen store (Hugging Face or GitHub)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
