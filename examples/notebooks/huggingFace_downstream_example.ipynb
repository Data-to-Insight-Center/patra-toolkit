{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### This notebook demonstrates the generation of model cards for downstream models trained on existing Hugging Face models.",
   "id": "5e81e5d0e3b2794c"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:03.786556Z",
     "start_time": "2024-10-18T02:27:58.008606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification,AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agamage/Desktop/Env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:03.798276Z",
     "start_time": "2024-10-18T02:28:03.796450Z"
    }
   },
   "cell_type": "code",
   "source": "# pip install transformers",
   "id": "899e1b560d9de6dc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:05.372203Z",
     "start_time": "2024-10-18T02:28:04.087837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ],
   "id": "fe33d2651362e577",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:07.664662Z",
     "start_time": "2024-10-18T02:28:05.410963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "text = \"I really dislike this item.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Move inputs to the correct device\n",
    "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "# Get model predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ],
   "id": "d36f78416f11353e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:07.689468Z",
     "start_time": "2024-10-18T02:28:07.686800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the predicted class (0 for negative, 1 for positive)\n",
    "logits = outputs.logits\n",
    "predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "# Display the result\n",
    "sentiment = \"positive\" if predicted_class == 1 else \"negative\"\n",
    "print(f\"The sentiment is: {sentiment}\")"
   ],
   "id": "7dd7768c60936f14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment is: negative\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:07.712480Z",
     "start_time": "2024-10-18T02:28:07.708757Z"
    }
   },
   "cell_type": "code",
   "source": "model.framework",
   "id": "408e52eb9368a58f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:12.481232Z",
     "start_time": "2024-10-18T02:28:07.733608Z"
    }
   },
   "cell_type": "code",
   "source": "from patra_toolkit import ModelCard, AIModel, BiasAnalysis, ExplainabilityAnalysis",
   "id": "93b5be03c39e286f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:12.493958Z",
     "start_time": "2024-10-18T02:28:12.491803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mc = ModelCard(\n",
    "    name=\"Sentiment Analysis Model using Hugging Face\",\n",
    "    version=\"0.1\",\n",
    "    short_description=\"Sentiment analysis model based on Hugging Face's DistilBERT fine-tuned on SST-2 dataset.\",\n",
    "    full_description=\"This model utilizes the Hugging Face Transformers framework with the DistilBERT model, fine-tuned for sentiment analysis on the SST-2 dataset. It is capable of classifying text as either positive or negative sentiment.\",\n",
    "    keywords=\"sentiment analysis, hugging face, transformers, distilbert, patra\",\n",
    "    author=\"Isuru Gamage\",\n",
    "    input_type=\"Text\",\n",
    "    category=\"classification\",\n",
    "    foundational_model=\"None\",\n",
    ")\n",
    "\n",
    "mc.input_data = 'https://huggingface.co/datasets/sst2'\n",
    "mc.output_data = 'https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english'"
   ],
   "id": "ec0d878fd10502d9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:12.507251Z",
     "start_time": "2024-10-18T02:28:12.504840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ai_model = AIModel(\n",
    "    name=\"Sentiment Analysis Hugging Face Model\",\n",
    "    version=\"1.0\",\n",
    "    description=\"Sentiment analysis model using Hugging Face Transformers pre-trained DistilBERT model for positive and negative sentiment classification.\",\n",
    "    owner=\"Isuru Gamage\",\n",
    "    location=\"https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\", \n",
    "    license=\"Apache-2.0\", \n",
    "    framework=\"pytorch\",\n",
    "    model_type=\"other\",  \n",
    "    test_accuracy=0.5\n",
    ")\n",
    "\n",
    "\n",
    "ai_model.populate_model_structure(model)"
   ],
   "id": "a96b7513229a865b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:12.518665Z",
     "start_time": "2024-10-18T02:28:12.517053Z"
    }
   },
   "cell_type": "code",
   "source": "mc.ai_model = ai_model",
   "id": "ff7f09284e85cb19",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:12.530207Z",
     "start_time": "2024-10-18T02:28:12.528374Z"
    }
   },
   "cell_type": "code",
   "source": "mc.populate_requirements()",
   "id": "f6df79dd435304e3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:12.542473Z",
     "start_time": "2024-10-18T02:28:12.540552Z"
    }
   },
   "cell_type": "code",
   "source": "print(mc)",
   "id": "6eb29741d2b5f2db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"Sentiment Analysis Model using Hugging Face\",\n",
      "    \"version\": \"0.1\",\n",
      "    \"short_description\": \"Sentiment analysis model based on Hugging Face's DistilBERT fine-tuned on SST-2 dataset.\",\n",
      "    \"full_description\": \"This model utilizes the Hugging Face Transformers framework with the DistilBERT model, fine-tuned for sentiment analysis on the SST-2 dataset. It is capable of classifying text as either positive or negative sentiment.\",\n",
      "    \"keywords\": \"sentiment analysis, hugging face, transformers, distilbert, patra\",\n",
      "    \"author\": \"Isuru Gamage\",\n",
      "    \"input_type\": \"Text\",\n",
      "    \"category\": \"classification\",\n",
      "    \"input_data\": \"https://huggingface.co/datasets/sst2\",\n",
      "    \"output_data\": \"https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "    \"foundational_model\": \"None\",\n",
      "    \"ai_model\": {\n",
      "        \"name\": \"Sentiment Analysis Hugging Face Model\",\n",
      "        \"version\": \"1.0\",\n",
      "        \"description\": \"Sentiment analysis model using Hugging Face Transformers pre-trained DistilBERT model for positive and negative sentiment classification.\",\n",
      "        \"owner\": \"Isuru Gamage\",\n",
      "        \"location\": \"https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "        \"license\": \"Apache-2.0\",\n",
      "        \"framework\": \"pytorch\",\n",
      "        \"model_type\": \"other\",\n",
      "        \"test_accuracy\": 0,\n",
      "        \"model_structure\": {},\n",
      "        \"metrics\": {}\n",
      "    },\n",
      "    \"bias_analysis\": null,\n",
      "    \"xai_analysis\": null,\n",
      "    \"model_requirements\": [\n",
      "        \"absl-py==2.1.0\",\n",
      "        \"accelerate==1.0.1\",\n",
      "        \"aiohappyeyeballs==2.4.3\",\n",
      "        \"aiohttp==3.10.10\",\n",
      "        \"aiosignal==1.3.1\",\n",
      "        \"aniso8601==9.0.1\",\n",
      "        \"annotated-types==0.7.0\",\n",
      "        \"anyio==4.6.0\",\n",
      "        \"appnope==0.1.4\",\n",
      "        \"argon2-cffi-bindings==21.2.0\",\n",
      "        \"argon2-cffi==23.1.0\",\n",
      "        \"arrow==1.3.0\",\n",
      "        \"asttokens==2.4.1\",\n",
      "        \"astunparse==1.6.3\",\n",
      "        \"async-lru==2.0.4\",\n",
      "        \"attrs==23.1.0\",\n",
      "        \"babel==2.16.0\",\n",
      "        \"beautifulsoup4==4.12.3\",\n",
      "        \"bleach==6.1.0\",\n",
      "        \"blinker==1.8.2\",\n",
      "        \"cachetools==5.5.0\",\n",
      "        \"certifi==2024.8.30\",\n",
      "        \"cffi==1.17.1\",\n",
      "        \"charset-normalizer==3.3.2\",\n",
      "        \"click==8.1.7\",\n",
      "        \"cloudpickle==3.0.0\",\n",
      "        \"colorama==0.4.6\",\n",
      "        \"comm==0.2.2\",\n",
      "        \"dataclasses-json==0.6.7\",\n",
      "        \"debugpy==1.8.6\",\n",
      "        \"decorator==5.1.1\",\n",
      "        \"defusedxml==0.7.1\",\n",
      "        \"distro==1.9.0\",\n",
      "        \"executing==2.1.0\",\n",
      "        \"fastjsonschema==2.20.0\",\n",
      "        \"filelock==3.16.1\",\n",
      "        \"flask-restx==1.3.0\",\n",
      "        \"flask==3.0.3\",\n",
      "        \"flatbuffers==24.3.25\",\n",
      "        \"fqdn==1.5.1\",\n",
      "        \"frozenlist==1.4.1\",\n",
      "        \"fsspec==2024.9.0\",\n",
      "        \"gast==0.6.0\",\n",
      "        \"gensim==4.3.3\",\n",
      "        \"google-ai-generativelanguage==0.6.10\",\n",
      "        \"google-api-core==2.21.0\",\n",
      "        \"google-api-python-client==2.149.0\",\n",
      "        \"google-auth-httplib2==0.2.0\",\n",
      "        \"google-auth==2.35.0\",\n",
      "        \"google-generativeai==0.8.3\",\n",
      "        \"google-pasta==0.2.0\",\n",
      "        \"google-search-results==2.4.2\",\n",
      "        \"googleapis-common-protos==1.65.0\",\n",
      "        \"grpcio-status==1.67.0\",\n",
      "        \"grpcio==1.67.0\",\n",
      "        \"h11==0.14.0\",\n",
      "        \"h5py==3.12.1\",\n",
      "        \"httpcore==1.0.6\",\n",
      "        \"httplib2==0.22.0\",\n",
      "        \"httpx==0.27.2\",\n",
      "        \"huggingface-hub==0.25.1\",\n",
      "        \"idna==3.10\",\n",
      "        \"importlib-resources==6.4.5\",\n",
      "        \"ipykernel==6.29.5\",\n",
      "        \"ipython==8.28.0\",\n",
      "        \"isoduration==20.11.0\",\n",
      "        \"itsdangerous==2.2.0\",\n",
      "        \"jedi==0.19.1\",\n",
      "        \"jinja2==3.1.4\",\n",
      "        \"jiter==0.6.1\",\n",
      "        \"joblib==1.4.2\",\n",
      "        \"json5==0.9.25\",\n",
      "        \"jsonpatch==1.33\",\n",
      "        \"jsonpointer==3.0.0\",\n",
      "        \"jsonschema-specifications==2023.12.1\",\n",
      "        \"jsonschema==4.18.6\",\n",
      "        \"jupyter-client==8.6.3\",\n",
      "        \"jupyter-core==5.7.2\",\n",
      "        \"jupyter-events==0.10.0\",\n",
      "        \"jupyter-lsp==2.2.5\",\n",
      "        \"jupyter-server-terminals==0.5.3\",\n",
      "        \"jupyter-server==2.14.2\",\n",
      "        \"jupyterlab-pygments==0.3.0\",\n",
      "        \"jupyterlab-server==2.27.3\",\n",
      "        \"jupyterlab==4.2.5\",\n",
      "        \"keras==3.6.0\",\n",
      "        \"langchain-community==0.3.2\",\n",
      "        \"langchain-core==0.3.12\",\n",
      "        \"langchain-google-genai==2.0.1\",\n",
      "        \"langchain-openai==0.2.2\",\n",
      "        \"langchain-text-splitters==0.3.0\",\n",
      "        \"langchain==0.3.3\",\n",
      "        \"langsmith==0.1.135\",\n",
      "        \"libclang==18.1.1\",\n",
      "        \"llvmlite==0.43.0\",\n",
      "        \"lxml==5.3.0\",\n",
      "        \"markdown-it-py==3.0.0\",\n",
      "        \"markdown==3.7\",\n",
      "        \"markupsafe==2.1.5\",\n",
      "        \"marshmallow==3.22.0\",\n",
      "        \"matplotlib-inline==0.1.7\",\n",
      "        \"mdurl==0.1.2\",\n",
      "        \"mistune==3.0.2\",\n",
      "        \"ml-dtypes==0.4.1\",\n",
      "        \"mpmath==1.3.0\",\n",
      "        \"multidict==6.1.0\",\n",
      "        \"mypy-extensions==1.0.0\",\n",
      "        \"namex==0.0.8\",\n",
      "        \"nbclient==0.10.0\",\n",
      "        \"nbconvert==7.16.4\",\n",
      "        \"nbformat==5.10.4\",\n",
      "        \"neo4j==5.25.0\",\n",
      "        \"nest-asyncio==1.6.0\",\n",
      "        \"networkx==2.8.8\",\n",
      "        \"nltk==3.9.1\",\n",
      "        \"node2vec==0.4.6\",\n",
      "        \"notebook-shim==0.2.4\",\n",
      "        \"notebook==7.2.2\",\n",
      "        \"numba==0.60.0\",\n",
      "        \"numpy==1.26.4\",\n",
      "        \"openai==1.52.0\",\n",
      "        \"opt-einsum==3.4.0\",\n",
      "        \"optree==0.13.0\",\n",
      "        \"orjson==3.10.7\",\n",
      "        \"overrides==7.7.0\",\n",
      "        \"packaging==24.1\",\n",
      "        \"pandas==2.2.3\",\n",
      "        \"pandocfilters==1.5.1\",\n",
      "        \"parso==0.8.4\",\n",
      "        \"pexpect==4.9.0\",\n",
      "        \"pip==24.2\",\n",
      "        \"platformdirs==4.3.6\",\n",
      "        \"portalocker==2.10.1\",\n",
      "        \"prometheus-client==0.21.0\",\n",
      "        \"prompt-toolkit==3.0.48\",\n",
      "        \"propcache==0.2.0\",\n",
      "        \"proto-plus==1.24.0\",\n",
      "        \"protobuf==5.28.2\",\n",
      "        \"psutil==6.0.0\",\n",
      "        \"ptyprocess==0.7.0\",\n",
      "        \"pure-eval==0.2.3\",\n",
      "        \"pyasn1-modules==0.4.1\",\n",
      "        \"pyasn1==0.6.1\",\n",
      "        \"pycparser==2.22\",\n",
      "        \"pydantic-core==2.23.4\",\n",
      "        \"pydantic-settings==2.5.2\",\n",
      "        \"pydantic==2.9.2\",\n",
      "        \"pygments==2.18.0\",\n",
      "        \"pyparsing==3.2.0\",\n",
      "        \"pyrsistent==0.19.3\",\n",
      "        \"python-dateutil==2.9.0.post0\",\n",
      "        \"python-dotenv==1.0.1\",\n",
      "        \"python-json-logger==2.0.7\",\n",
      "        \"pytz==2024.2\",\n",
      "        \"pyyaml==6.0.2\",\n",
      "        \"pyzmq==26.2.0\",\n",
      "        \"referencing==0.35.1\",\n",
      "        \"regex==2024.9.11\",\n",
      "        \"requests-toolbelt==1.0.0\",\n",
      "        \"requests==2.32.3\",\n",
      "        \"rfc3339-validator==0.1.4\",\n",
      "        \"rfc3986-validator==0.1.1\",\n",
      "        \"rich==13.9.2\",\n",
      "        \"rogue==0.0.2\",\n",
      "        \"rouge==1.0.1\",\n",
      "        \"rpds-py==0.20.0\",\n",
      "        \"rsa==4.9\",\n",
      "        \"sacrebleu==2.4.3\",\n",
      "        \"safetensors==0.4.5\",\n",
      "        \"scikit-learn==1.5.2\",\n",
      "        \"scipy==1.12.0\",\n",
      "        \"send2trash==1.8.3\",\n",
      "        \"setuptools==68.2.0\",\n",
      "        \"six==1.16.0\",\n",
      "        \"slicer==0.0.8\",\n",
      "        \"smart-open==7.0.5\",\n",
      "        \"sniffio==1.3.1\",\n",
      "        \"soupsieve==2.6\",\n",
      "        \"sqlalchemy==2.0.36\",\n",
      "        \"stack-data==0.6.3\",\n",
      "        \"sympy==1.13.3\",\n",
      "        \"tabulate==0.9.0\",\n",
      "        \"tenacity==8.5.0\",\n",
      "        \"tensorboard-data-server==0.7.2\",\n",
      "        \"tensorboard==2.17.1\",\n",
      "        \"tensorflow-io-gcs-filesystem==0.37.1\",\n",
      "        \"tensorflow==2.17.0\",\n",
      "        \"termcolor==2.5.0\",\n",
      "        \"terminado==0.18.1\",\n",
      "        \"threadpoolctl==3.5.0\",\n",
      "        \"tiktoken==0.8.0\",\n",
      "        \"tinycss2==1.3.0\",\n",
      "        \"tokenizers==0.20.1\",\n",
      "        \"torch==2.2.2\",\n",
      "        \"tornado==6.4.1\",\n",
      "        \"tqdm==4.66.5\",\n",
      "        \"traitlets==5.14.3\",\n",
      "        \"transformers==4.45.2\",\n",
      "        \"types-python-dateutil==2.9.0.20241003\",\n",
      "        \"typing-extensions==4.12.2\",\n",
      "        \"typing-inspect==0.9.0\",\n",
      "        \"tzdata==2024.2\",\n",
      "        \"uri-template==1.3.0\",\n",
      "        \"uritemplate==4.1.1\",\n",
      "        \"urllib3==2.2.3\",\n",
      "        \"wcwidth==0.2.13\",\n",
      "        \"webcolors==24.8.0\",\n",
      "        \"webencodings==0.5.1\",\n",
      "        \"websocket-client==1.8.0\",\n",
      "        \"werkzeug==3.0.4\",\n",
      "        \"wheel==0.41.2\",\n",
      "        \"wrapt==1.16.0\",\n",
      "        \"yarl==1.15.3\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:12.644797Z",
     "start_time": "2024-10-18T02:28:12.635440Z"
    }
   },
   "cell_type": "code",
   "source": "mc.validate()",
   "id": "d6eff20b438c5701",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:12.728543Z",
     "start_time": "2024-10-18T02:28:12.676910Z"
    }
   },
   "cell_type": "code",
   "source": "mc.submit_model(\"http://127.0.0.1:5002/upload_mc\")",
   "id": "b26244e8b7e8348c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Model card already exists',\n",
       " 'model_card_id': '3042e494-07f3-4d53-a517-35c9a860f00d'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:12.835797Z",
     "start_time": "2024-10-18T02:28:12.795826Z"
    }
   },
   "cell_type": "code",
   "source": "response = mc.submit_model(\"http://127.0.0.1:5002/upload_mc\")",
   "id": "4714621ac1c1d559",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:12.851172Z",
     "start_time": "2024-10-18T02:28:12.849203Z"
    }
   },
   "cell_type": "code",
   "source": "model_card_id = response['model_card_id']",
   "id": "fd6b3149dc05973a",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:12.864272Z",
     "start_time": "2024-10-18T02:28:12.862313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_card_id = model_card_id.strip(\"'\")\n",
    "\n",
    "print(model_card_id)"
   ],
   "id": "caad6e988cb8d03c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3042e494-07f3-4d53-a517-35c9a860f00d\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:29:16.625428Z",
     "start_time": "2024-10-18T02:29:10.764155Z"
    }
   },
   "cell_type": "code",
   "source": "# pip install tf-keras",
   "id": "1dcf07a1d514ed8f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\r\n",
      "  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: tensorflow<2.18,>=2.17 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tf-keras) (2.17.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.1.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.12.1)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (18.1.1)\r\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.4.1)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (24.1)\r\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow<2.18,>=2.17->tf-keras)\r\n",
      "  Using cached protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (68.2.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.16.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.67.0)\r\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.17.1)\r\n",
      "Requirement already satisfied: keras>=3.2.0 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.6.0)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.37.1)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.26.4)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17->tf-keras) (0.41.2)\r\n",
      "Requirement already satisfied: rich in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (13.9.2)\r\n",
      "Requirement already satisfied: namex in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.13.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (2024.8.30)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.7)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.0.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (2.1.5)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (2.18.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/agamage/Desktop/Env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.1.2)\r\n",
      "Downloading tf_keras-2.17.0-py3-none-any.whl (1.7 MB)\r\n",
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m3.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\r\n",
      "Installing collected packages: protobuf, tf-keras\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 5.28.2\r\n",
      "    Uninstalling protobuf-5.28.2:\r\n",
      "      Successfully uninstalled protobuf-5.28.2\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "grpcio-status 1.67.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.5 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed protobuf-4.25.5 tf-keras-2.17.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Retrain the HaggingFace Model",
   "id": "b5dec641de43110"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:29:20.969009Z",
     "start_time": "2024-10-18T02:29:19.846002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ],
   "id": "db850e2ed817afbc",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:29:22.559363Z",
     "start_time": "2024-10-18T02:29:22.509731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "df = pd.read_csv(\"/Users/agamage/Desktop/D2I/Codes/fork/patra-toolkit/examples/notebooks/data/sentiment/news_sentiment_analysis.csv\")  # Adjust the path as necessary\n",
    "\n",
    "df = df.drop(columns=['URL', 'Source','Author'])\n",
    "# Combine title and description as features\n",
    "df['Text'] = df['Title'] + \" \" + df['Description']\n",
    "\n",
    "label_encoder_type = LabelEncoder()\n",
    "label_encoder_date = LabelEncoder()\n",
    "\n",
    "df['Type'] = label_encoder_type.fit_transform(df['Type'])\n",
    "\n",
    "df['Published_day'] = pd.to_datetime(df['Published At']).dt.day_name()\n",
    "df['Published At'] = label_encoder_date.fit_transform(df['Published_day'])\n",
    "\n",
    "df = df.drop(columns=['Title', 'Description', 'Published_day'])\n",
    "\n",
    "# Map sentiment labels from -1 (negative) to 0, and keep 1 as positive\n",
    "df['Sentiment'] = df['Sentiment'].apply(lambda x: 1 if x == \"positive\" else 0)\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df.drop(columns=['Sentiment'])\n",
    "y = df['Sentiment'] # Target label"
   ],
   "id": "2f5bd2eaabf746c8",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:29:27.989800Z",
     "start_time": "2024-10-18T02:29:25.821122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, ignore_mismatched_sizes=True)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\") if torch.has_mps else (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "model.to(device)\n",
    "\n",
    "# Tokenize the training and test data\n",
    "train_encodings = tokenizer(X_train['Text'].tolist(), truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "test_encodings = tokenizer(X_test['Text'].tolist(), truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "# Move input tensors to the correct device\n",
    "train_encodings = {key: val.to(device) for key, val in train_encodings.items()}\n",
    "test_encodings = {key: val.to(device) for key, val in test_encodings.items()}\n",
    "\n",
    "# Convert labels to tensors\n",
    "y_train_tensor = torch.tensor(y_train.tolist()).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.tolist()).to(device)\n"
   ],
   "id": "cf22a11cfb43224b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hz/704s19kd1zg3phgs0khv5df00000gp/T/ipykernel_97619/2222344923.py:9: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  device = torch.device(\"mps\") if torch.has_mps else (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:35:33.693741Z",
     "start_time": "2024-10-18T02:29:29.948952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a custom Dataset class\n",
    "\n",
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = ReviewsDataset(train_encodings, y_train_tensor)\n",
    "test_dataset = ReviewsDataset(test_encodings, y_test_tensor)\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Output directory\n",
    "    num_train_epochs=3,              # Number of training epochs\n",
    "    per_device_train_batch_size=16,  # Batch size for training\n",
    "    evaluation_strategy=\"epoch\",      # Evaluate at the end of each epoch\n",
    "    logging_dir='./logs',            # Directory for storing logs\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "evaluation_results = trainer.evaluate() \n",
    "\n",
    "print(evaluation_results)\n",
    "\n",
    "model.eval()"
   ],
   "id": "150c0cfd492dc31d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agamage/Desktop/Env/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 05:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.410094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.427357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.501400</td>\n",
       "      <td>0.459216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='88' max='88' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [88/88 00:07]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45921558141708374, 'eval_runtime': 7.6455, 'eval_samples_per_second': 91.557, 'eval_steps_per_second': 11.51, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:22.690997Z",
     "start_time": "2024-10-15T00:03:03.371966Z"
    }
   },
   "cell_type": "code",
   "source": "# pip install 'accelerate>={ACCELERATE_MIN_VERSION}'",
   "id": "9f271987017dc39a",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:35:45.985124Z",
     "start_time": "2024-10-18T02:35:34.389235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    test_outputs = model(**test_encodings)"
   ],
   "id": "af0408d414964a42",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:36:13.443424Z",
     "start_time": "2024-10-18T02:36:13.168586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "device = torch.device(\"mps\") if torch.has_mps else torch.device(\"cpu\")\n",
    "\n",
    "new_reviews = [\"This product is amazing!\", \"I really dislike this item.\"]\n",
    "\n",
    "# Tokenize the new reviews\n",
    "encodings = tokenizer(new_reviews, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "encodings = {key: val.to(device) for key, val in encodings.items()}\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# predictions\n",
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    outputs = model(**encodings)\n",
    "\n",
    "# predicted class (0 for negative, 1 for positive)\n",
    "predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "for review, prediction in zip(new_reviews, predictions):\n",
    "    sentiment = \"Positive\" if prediction == 1 else \"Negative\"\n",
    "    print(f\"Review: {review}\\nPredicted Sentiment: {sentiment}\\n\")"
   ],
   "id": "718a126c373b8fbb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hz/704s19kd1zg3phgs0khv5df00000gp/T/ipykernel_97619/4040034712.py:1: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  device = torch.device(\"mps\") if torch.has_mps else torch.device(\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This product is amazing!\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Review: I really dislike this item.\n",
      "Predicted Sentiment: Negative\n",
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:36:13.937369Z",
     "start_time": "2024-10-18T02:36:13.930858Z"
    }
   },
   "cell_type": "code",
   "source": "from patra_toolkit.patra_model_card import ModelCard, AIModel, BiasAnalysis, ExplainabilityAnalysis",
   "id": "33103fb42f73bdd5",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:36:13.960147Z",
     "start_time": "2024-10-18T02:36:13.956455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mct = ModelCard(\n",
    "    name=\"Retrain Sentiment Analysis Model using Hugging Face and News dataset\",\n",
    "    version=\"0.1\",\n",
    "    short_description=\"Retrain Sentiment analysis model based on Hugging Face's DistilBERT fine-tuned on News dataset.\",\n",
    "    full_description=\"This model utilizes the Hugging Face Transformers framework with the DistilBERT model, fine-tuned for sentiment analysis on the News dataset. It is capable of classifying text as either positive or negative sentiment.\",\n",
    "    keywords=\"sentiment analysis, hugging face, transformers, distilbert, patra, retrain\",\n",
    "    author=\"Isuru Gamage\",\n",
    "    input_type=\"Text\",\n",
    "    category=\"classification\",\n",
    "    foundational_model=model_card_id,\n",
    ")\n",
    "\n",
    "# Link to input and output data (in the context of Hugging Face's pre-trained model and dataset)\n",
    "mct.input_data = 'https://huggingface.co/datasets/news'\n",
    "mct.output_data = 'https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english'"
   ],
   "id": "b2493772ee238449",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:36:14.151159Z",
     "start_time": "2024-10-18T02:36:14.144947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ai_model = AIModel(\n",
    "    name=\"Retrain Sentiment Analysis Hugging Face Model\",\n",
    "    version=\"1.0\",\n",
    "    description=\"Retrain Sentiment analysis model using Hugging Face Transformers pre-trained DistilBERT model for positive and negative sentiment classification.\",\n",
    "    owner=\"Isuru Gamage\",\n",
    "    location=\"https://huggingface.co/distilbert-base-uncased-finetuned-news-english/train\", \n",
    "    license=\"Apache-2.0\", \n",
    "    framework=\"pytorch\",\n",
    "    model_type=\"other\",  \n",
    "    test_accuracy=0  \n",
    ")\n",
    "\n",
    "\n",
    "ai_model.populate_model_structure(model)"
   ],
   "id": "f1b0efe935e79549",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:36:14.315827Z",
     "start_time": "2024-10-18T02:36:14.312656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ai_model.add_metric(\"Test loss\", 0.22)\n",
    "ai_model.add_metric(\"Epochs\", 100)\n",
    "ai_model.add_metric(\"Batch Size\", 32)\n",
    "ai_model.add_metric(\"Optimizer\", \"Adam\")\n",
    "ai_model.add_metric(\"Learning Rate\", 0.0001)\n",
    "ai_model.add_metric(\"Input Shape\", \"(26048, 100)\")"
   ],
   "id": "d05037cb781a74c6",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:36:14.486172Z",
     "start_time": "2024-10-18T02:36:14.484588Z"
    }
   },
   "cell_type": "code",
   "source": "mct.ai_model = ai_model",
   "id": "35952e0c030d38af",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:36:14.800100Z",
     "start_time": "2024-10-18T02:36:14.794596Z"
    }
   },
   "cell_type": "code",
   "source": "mct.populate_requirements()",
   "id": "6016403874321ba2",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:36:15.002990Z",
     "start_time": "2024-10-18T02:36:14.973392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn.functional import softmax\n",
    "import numpy as np\n",
    "\n",
    "y_pred_prob = softmax(test_outputs.logits, dim=1).cpu().numpy()\n",
    "\n",
    "print(f\"Probabilities for the first 5 samples: \\n{y_pred_prob[:5]}\")\n",
    "\n",
    "# If you want to convert these probabilities into binary predictions:\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)"
   ],
   "id": "161d0b116e7f0729",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for the first 5 samples: \n",
      "[[0.00149967 0.99850035]\n",
      " [0.00265727 0.99734277]\n",
      " [0.9969002  0.00309979]\n",
      " [0.00168173 0.9983183 ]\n",
      " [0.00421658 0.99578345]]\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:36:15.269974Z",
     "start_time": "2024-10-18T02:36:15.266660Z"
    }
   },
   "cell_type": "code",
   "source": "print(mct)",
   "id": "1b40a532c75ab9c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"Retrain Sentiment Analysis Model using Hugging Face and News dataset\",\n",
      "    \"version\": \"0.1\",\n",
      "    \"short_description\": \"Retrain Sentiment analysis model based on Hugging Face's DistilBERT fine-tuned on News dataset.\",\n",
      "    \"full_description\": \"This model utilizes the Hugging Face Transformers framework with the DistilBERT model, fine-tuned for sentiment analysis on the News dataset. It is capable of classifying text as either positive or negative sentiment.\",\n",
      "    \"keywords\": \"sentiment analysis, hugging face, transformers, distilbert, patra, retrain\",\n",
      "    \"author\": \"Isuru Gamage\",\n",
      "    \"input_type\": \"Text\",\n",
      "    \"category\": \"classification\",\n",
      "    \"input_data\": \"https://huggingface.co/datasets/news\",\n",
      "    \"output_data\": \"https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "    \"foundational_model\": \"3042e494-07f3-4d53-a517-35c9a860f00d\",\n",
      "    \"ai_model\": {\n",
      "        \"name\": \"Retrain Sentiment Analysis Hugging Face Model\",\n",
      "        \"version\": \"1.0\",\n",
      "        \"description\": \"Retrain Sentiment analysis model using Hugging Face Transformers pre-trained DistilBERT model for positive and negative sentiment classification.\",\n",
      "        \"owner\": \"Isuru Gamage\",\n",
      "        \"location\": \"https://huggingface.co/distilbert-base-uncased-finetuned-news-english/train\",\n",
      "        \"license\": \"Apache-2.0\",\n",
      "        \"framework\": \"pytorch\",\n",
      "        \"model_type\": \"other\",\n",
      "        \"test_accuracy\": 0,\n",
      "        \"model_structure\": {},\n",
      "        \"metrics\": {\n",
      "            \"Test loss\": 0.22,\n",
      "            \"Epochs\": 100,\n",
      "            \"Batch Size\": 32,\n",
      "            \"Optimizer\": \"Adam\",\n",
      "            \"Learning Rate\": 0.0001,\n",
      "            \"Input Shape\": \"(26048, 100)\"\n",
      "        }\n",
      "    },\n",
      "    \"bias_analysis\": null,\n",
      "    \"xai_analysis\": null,\n",
      "    \"model_requirements\": [\n",
      "        \"absl-py==2.1.0\",\n",
      "        \"accelerate==1.0.1\",\n",
      "        \"aiohappyeyeballs==2.4.3\",\n",
      "        \"aiohttp==3.10.10\",\n",
      "        \"aiosignal==1.3.1\",\n",
      "        \"aniso8601==9.0.1\",\n",
      "        \"annotated-types==0.7.0\",\n",
      "        \"anyio==4.6.0\",\n",
      "        \"appnope==0.1.4\",\n",
      "        \"argon2-cffi-bindings==21.2.0\",\n",
      "        \"argon2-cffi==23.1.0\",\n",
      "        \"arrow==1.3.0\",\n",
      "        \"asttokens==2.4.1\",\n",
      "        \"astunparse==1.6.3\",\n",
      "        \"async-lru==2.0.4\",\n",
      "        \"attrs==23.1.0\",\n",
      "        \"babel==2.16.0\",\n",
      "        \"beautifulsoup4==4.12.3\",\n",
      "        \"bleach==6.1.0\",\n",
      "        \"blinker==1.8.2\",\n",
      "        \"cachetools==5.5.0\",\n",
      "        \"certifi==2024.8.30\",\n",
      "        \"cffi==1.17.1\",\n",
      "        \"charset-normalizer==3.3.2\",\n",
      "        \"click==8.1.7\",\n",
      "        \"cloudpickle==3.0.0\",\n",
      "        \"colorama==0.4.6\",\n",
      "        \"comm==0.2.2\",\n",
      "        \"dataclasses-json==0.6.7\",\n",
      "        \"debugpy==1.8.6\",\n",
      "        \"decorator==5.1.1\",\n",
      "        \"defusedxml==0.7.1\",\n",
      "        \"distro==1.9.0\",\n",
      "        \"executing==2.1.0\",\n",
      "        \"fastjsonschema==2.20.0\",\n",
      "        \"filelock==3.16.1\",\n",
      "        \"flask-restx==1.3.0\",\n",
      "        \"flask==3.0.3\",\n",
      "        \"flatbuffers==24.3.25\",\n",
      "        \"fqdn==1.5.1\",\n",
      "        \"frozenlist==1.4.1\",\n",
      "        \"fsspec==2024.9.0\",\n",
      "        \"gast==0.6.0\",\n",
      "        \"gensim==4.3.3\",\n",
      "        \"google-ai-generativelanguage==0.6.10\",\n",
      "        \"google-api-core==2.21.0\",\n",
      "        \"google-api-python-client==2.149.0\",\n",
      "        \"google-auth-httplib2==0.2.0\",\n",
      "        \"google-auth==2.35.0\",\n",
      "        \"google-generativeai==0.8.3\",\n",
      "        \"google-pasta==0.2.0\",\n",
      "        \"google-search-results==2.4.2\",\n",
      "        \"googleapis-common-protos==1.65.0\",\n",
      "        \"grpcio-status==1.67.0\",\n",
      "        \"grpcio==1.67.0\",\n",
      "        \"h11==0.14.0\",\n",
      "        \"h5py==3.12.1\",\n",
      "        \"httpcore==1.0.6\",\n",
      "        \"httplib2==0.22.0\",\n",
      "        \"httpx==0.27.2\",\n",
      "        \"huggingface-hub==0.25.1\",\n",
      "        \"idna==3.10\",\n",
      "        \"importlib-resources==6.4.5\",\n",
      "        \"ipykernel==6.29.5\",\n",
      "        \"ipython==8.28.0\",\n",
      "        \"isoduration==20.11.0\",\n",
      "        \"itsdangerous==2.2.0\",\n",
      "        \"jedi==0.19.1\",\n",
      "        \"jinja2==3.1.4\",\n",
      "        \"jiter==0.6.1\",\n",
      "        \"joblib==1.4.2\",\n",
      "        \"json5==0.9.25\",\n",
      "        \"jsonpatch==1.33\",\n",
      "        \"jsonpointer==3.0.0\",\n",
      "        \"jsonschema-specifications==2023.12.1\",\n",
      "        \"jsonschema==4.18.6\",\n",
      "        \"jupyter-client==8.6.3\",\n",
      "        \"jupyter-core==5.7.2\",\n",
      "        \"jupyter-events==0.10.0\",\n",
      "        \"jupyter-lsp==2.2.5\",\n",
      "        \"jupyter-server-terminals==0.5.3\",\n",
      "        \"jupyter-server==2.14.2\",\n",
      "        \"jupyterlab-pygments==0.3.0\",\n",
      "        \"jupyterlab-server==2.27.3\",\n",
      "        \"jupyterlab==4.2.5\",\n",
      "        \"keras==3.6.0\",\n",
      "        \"langchain-community==0.3.2\",\n",
      "        \"langchain-core==0.3.12\",\n",
      "        \"langchain-google-genai==2.0.1\",\n",
      "        \"langchain-openai==0.2.2\",\n",
      "        \"langchain-text-splitters==0.3.0\",\n",
      "        \"langchain==0.3.3\",\n",
      "        \"langsmith==0.1.135\",\n",
      "        \"libclang==18.1.1\",\n",
      "        \"llvmlite==0.43.0\",\n",
      "        \"lxml==5.3.0\",\n",
      "        \"markdown-it-py==3.0.0\",\n",
      "        \"markdown==3.7\",\n",
      "        \"markupsafe==2.1.5\",\n",
      "        \"marshmallow==3.22.0\",\n",
      "        \"matplotlib-inline==0.1.7\",\n",
      "        \"mdurl==0.1.2\",\n",
      "        \"mistune==3.0.2\",\n",
      "        \"ml-dtypes==0.4.1\",\n",
      "        \"mpmath==1.3.0\",\n",
      "        \"multidict==6.1.0\",\n",
      "        \"mypy-extensions==1.0.0\",\n",
      "        \"namex==0.0.8\",\n",
      "        \"nbclient==0.10.0\",\n",
      "        \"nbconvert==7.16.4\",\n",
      "        \"nbformat==5.10.4\",\n",
      "        \"neo4j==5.25.0\",\n",
      "        \"nest-asyncio==1.6.0\",\n",
      "        \"networkx==2.8.8\",\n",
      "        \"nltk==3.9.1\",\n",
      "        \"node2vec==0.4.6\",\n",
      "        \"notebook-shim==0.2.4\",\n",
      "        \"notebook==7.2.2\",\n",
      "        \"numba==0.60.0\",\n",
      "        \"numpy==1.26.4\",\n",
      "        \"openai==1.52.0\",\n",
      "        \"opt-einsum==3.4.0\",\n",
      "        \"optree==0.13.0\",\n",
      "        \"orjson==3.10.7\",\n",
      "        \"overrides==7.7.0\",\n",
      "        \"packaging==24.1\",\n",
      "        \"pandas==2.2.3\",\n",
      "        \"pandocfilters==1.5.1\",\n",
      "        \"parso==0.8.4\",\n",
      "        \"pexpect==4.9.0\",\n",
      "        \"pip==24.2\",\n",
      "        \"platformdirs==4.3.6\",\n",
      "        \"portalocker==2.10.1\",\n",
      "        \"prometheus-client==0.21.0\",\n",
      "        \"prompt-toolkit==3.0.48\",\n",
      "        \"propcache==0.2.0\",\n",
      "        \"proto-plus==1.24.0\",\n",
      "        \"protobuf==5.28.2\",\n",
      "        \"psutil==6.0.0\",\n",
      "        \"ptyprocess==0.7.0\",\n",
      "        \"pure-eval==0.2.3\",\n",
      "        \"pyasn1-modules==0.4.1\",\n",
      "        \"pyasn1==0.6.1\",\n",
      "        \"pycparser==2.22\",\n",
      "        \"pydantic-core==2.23.4\",\n",
      "        \"pydantic-settings==2.5.2\",\n",
      "        \"pydantic==2.9.2\",\n",
      "        \"pygments==2.18.0\",\n",
      "        \"pyparsing==3.2.0\",\n",
      "        \"pyrsistent==0.19.3\",\n",
      "        \"python-dateutil==2.9.0.post0\",\n",
      "        \"python-dotenv==1.0.1\",\n",
      "        \"python-json-logger==2.0.7\",\n",
      "        \"pytz==2024.2\",\n",
      "        \"pyyaml==6.0.2\",\n",
      "        \"pyzmq==26.2.0\",\n",
      "        \"referencing==0.35.1\",\n",
      "        \"regex==2024.9.11\",\n",
      "        \"requests-toolbelt==1.0.0\",\n",
      "        \"requests==2.32.3\",\n",
      "        \"rfc3339-validator==0.1.4\",\n",
      "        \"rfc3986-validator==0.1.1\",\n",
      "        \"rich==13.9.2\",\n",
      "        \"rogue==0.0.2\",\n",
      "        \"rouge==1.0.1\",\n",
      "        \"rpds-py==0.20.0\",\n",
      "        \"rsa==4.9\",\n",
      "        \"sacrebleu==2.4.3\",\n",
      "        \"safetensors==0.4.5\",\n",
      "        \"scikit-learn==1.5.2\",\n",
      "        \"scipy==1.12.0\",\n",
      "        \"send2trash==1.8.3\",\n",
      "        \"setuptools==68.2.0\",\n",
      "        \"six==1.16.0\",\n",
      "        \"slicer==0.0.8\",\n",
      "        \"smart-open==7.0.5\",\n",
      "        \"sniffio==1.3.1\",\n",
      "        \"soupsieve==2.6\",\n",
      "        \"sqlalchemy==2.0.36\",\n",
      "        \"stack-data==0.6.3\",\n",
      "        \"sympy==1.13.3\",\n",
      "        \"tabulate==0.9.0\",\n",
      "        \"tenacity==8.5.0\",\n",
      "        \"tensorboard-data-server==0.7.2\",\n",
      "        \"tensorboard==2.17.1\",\n",
      "        \"tensorflow-io-gcs-filesystem==0.37.1\",\n",
      "        \"tensorflow==2.17.0\",\n",
      "        \"termcolor==2.5.0\",\n",
      "        \"terminado==0.18.1\",\n",
      "        \"threadpoolctl==3.5.0\",\n",
      "        \"tiktoken==0.8.0\",\n",
      "        \"tinycss2==1.3.0\",\n",
      "        \"tokenizers==0.20.1\",\n",
      "        \"torch==2.2.2\",\n",
      "        \"tornado==6.4.1\",\n",
      "        \"tqdm==4.66.5\",\n",
      "        \"traitlets==5.14.3\",\n",
      "        \"transformers==4.45.2\",\n",
      "        \"types-python-dateutil==2.9.0.20241003\",\n",
      "        \"typing-extensions==4.12.2\",\n",
      "        \"typing-inspect==0.9.0\",\n",
      "        \"tzdata==2024.2\",\n",
      "        \"uri-template==1.3.0\",\n",
      "        \"uritemplate==4.1.1\",\n",
      "        \"urllib3==2.2.3\",\n",
      "        \"wcwidth==0.2.13\",\n",
      "        \"webcolors==24.8.0\",\n",
      "        \"webencodings==0.5.1\",\n",
      "        \"websocket-client==1.8.0\",\n",
      "        \"werkzeug==3.0.4\",\n",
      "        \"wheel==0.41.2\",\n",
      "        \"wrapt==1.16.0\",\n",
      "        \"yarl==1.15.3\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:36:15.369107Z",
     "start_time": "2024-10-18T02:36:15.329152Z"
    }
   },
   "cell_type": "code",
   "source": "mct.validate()",
   "id": "718847b31fa722b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:36:18.964985Z",
     "start_time": "2024-10-18T02:36:15.526947Z"
    }
   },
   "cell_type": "code",
   "source": "mct.submit(\"http://127.0.0.1:5002\")",
   "id": "a1aa6df2d1fcd7b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Successfully uploaded the model card',\n",
       " 'model_card_id': 'bd9c3eec-cbfb-42f2-9962-e68ce5b95ad0'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
